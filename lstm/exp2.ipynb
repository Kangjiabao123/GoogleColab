{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "exp2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPwVkRiU+CB/Zpy82qmNdGO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YapingWu/GoogleColab/blob/main/lstm/exp2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ax3gVVUPu9jO"
      },
      "source": [
        "导入需要使用的类的函数"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBb3D3UnvDum"
      },
      "source": [
        "from numpy import array\r\n",
        "from keras.preprocessing.text import Tokenizer\r\n",
        "from keras.utils import to_categorical\r\n",
        "from keras.preprocessing.sequence import pad_sequences\r\n",
        "from keras.utils.vis_utils import plot_model\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense\r\n",
        "from keras.layers import LSTM\r\n",
        "from keras.layers import Embedding"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiUTzPG3uj1a"
      },
      "source": [
        "# 1 加载数据"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zr8SL-6NuoZo"
      },
      "source": [
        "## 1.1 从本地读取文件数据"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 76
        },
        "id": "IeFeXg4ntl_W",
        "outputId": "744b6cec-d011-4a44-8d51-4b2c49caff35"
      },
      "source": [
        "# 1. 上传本地文件\r\n",
        "from google.colab import files\r\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-399f404e-071b-483b-b386-e3db478cdadc\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-399f404e-071b-483b-b386-e3db478cdadc\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving myspace.txt to myspace.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbCUVwp8y7eR",
        "outputId": "36c013fa-738c-476e-dc68-5442d4f8c734"
      },
      "source": [
        "import pandas as pd\r\n",
        "import io\r\n",
        "raw_data = pd.read_csv(io.StringIO(uploaded['grammar.txt'].decode('utf-8')), \r\n",
        "                 sep='\\t', \r\n",
        "                 header=None,\r\n",
        "                 names=['grammar', 'count', 'prop'])\r\n",
        "print(raw_data.head(3))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  grammar  count      prop\n",
            "0  A6D1O1   2921  0.078640\n",
            "1  A7D1O1   2417  0.065071\n",
            "2  A6D2O1   2329  0.062702\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJZL96RgYpUn",
        "outputId": "58ba78ba-2bb7-48c2-b251-f13ef15fea72"
      },
      "source": [
        "import pandas as pd\r\n",
        "import io\r\n",
        "# 2. 将密码数据读取到dataframe中\r\n",
        "raw_data = pd.read_csv(io.StringIO(uploaded['myspace.txt'].decode('utf-8')),\r\n",
        "                 header=None,\r\n",
        "                 names=['pwd'])\r\n",
        "print(raw_data.shape)\r\n",
        "print(raw_data.head(3))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(37144, 1)\n",
            "         pwd\n",
            "0  password1\n",
            "1     abc123\n",
            "2    fuckyou\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_xYLjYuZBVF",
        "outputId": "945620bf-bb63-42b1-ff35-1bcc7750f846"
      },
      "source": [
        "# 3. 将数据编码成单元序列。e.g., $Password123 => S1 L8 N3‘\\n’\r\n",
        "import itertools\r\n",
        "LETTER = 'L'\r\n",
        "DIGIT = 'D'\r\n",
        "OTHER = 'S'\r\n",
        "\r\n",
        "\r\n",
        "def get_type(ch):\r\n",
        "    if ch.isalpha():\r\n",
        "        return LETTER\r\n",
        "    if ch.isdigit():\r\n",
        "        return DIGIT\r\n",
        "    return OTHER\r\n",
        "\r\n",
        "\r\n",
        "def encode_to_unit(data):\r\n",
        "  data = str(data)\r\n",
        "  tmp = ''\r\n",
        "  result = ''\r\n",
        "  for ch in data:\r\n",
        "      tmp += get_type(ch)\r\n",
        "\r\n",
        "  for k, g in itertools.groupby(tmp):\r\n",
        "      result += (k + str(len(list(g))) + ' ')\r\n",
        "    \r\n",
        "  return result\r\n",
        "\r\n",
        "raw_data['grammar'] = raw_data['pwd'].apply(encode_to_unit)\r\n",
        "print(raw_data.shape)\r\n",
        "print(raw_data.head(5))"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(37144, 2)\n",
            "         pwd grammar\n",
            "0  password1  L8 D1 \n",
            "1     abc123  L3 D3 \n",
            "2    fuckyou     L7 \n",
            "3    monkey1  L6 D1 \n",
            "4  iloveyou1  L8 D1 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CyNhbE73mna9",
        "outputId": "4aad15fb-2d81-422c-8c42-053ccf040b65"
      },
      "source": [
        "# 4. 统计每个grammar出现的概率\r\n",
        "new_data = pd.DataFrame()\r\n",
        "new_data['grammar'] = raw_data['grammar']\r\n",
        "new_data['cnt'] = 1\r\n",
        "new_data = new_data.groupby(['grammar'])['cnt'].sum().reset_index() # 计算每个grammar出现的次数\r\n",
        "new_data['prop'] = new_data['cnt'] / raw_data.shape[0] # 计算概率\r\n",
        "new_data.sort_values('prop', inplace=True, ascending=False) # 按prop降序排列\r\n",
        "new_data.reset_index(inplace=True, drop=True) # 重置行索引\r\n",
        "print(new_data.shape)\r\n",
        "print(new_data.head(5))"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1720, 3)\n",
            "  grammar   cnt      prop\n",
            "0  L6 D1   2929  0.078855\n",
            "1  L7 D1   2418  0.065098\n",
            "2  L6 D2   2333  0.062810\n",
            "3  L8 D1   2034  0.054760\n",
            "4  L5 D2   1735  0.046710\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tGjaqBLbo6t"
      },
      "source": [
        "# 4. 处理后的数据保存到文件中\r\n",
        "raw_data.to_csv(\"myspace_encoded.csv\")"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qs6ncLxHzfGf"
      },
      "source": [
        "## 1.2 定义数据集"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ta2Zul31V7_"
      },
      "source": [
        "将原始数据划分为训练集和测试集"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJOxvoxezlF_",
        "outputId": "73e7610c-37c3-4a93-c767-c41eae99add4"
      },
      "source": [
        "import numpy as np\r\n",
        "def split_train_test(data,test_ratio):\r\n",
        "    #设置随机数种子，保证每次生成的结果都是一样的\r\n",
        "    np.random.seed(42)\r\n",
        "    #permutation随机生成0-len(data)随机序列\r\n",
        "    shuffled_indices = np.random.permutation(len(data))\r\n",
        "    #test_ratio为测试集所占的半分比\r\n",
        "    test_set_size = int(len(data) * test_ratio)\r\n",
        "    test_indices = shuffled_indices[:test_set_size]\r\n",
        "    train_indices = shuffled_indices[test_set_size:]\r\n",
        "    #iloc选择参数序列中所对应的行\r\n",
        "    return data.iloc[train_indices],data.iloc[test_indices]\r\n",
        " \r\n",
        "#测试\r\n",
        "train_set,test_set = split_train_test(raw_data, 0.2)\r\n",
        "print(train_set.shape, test_set.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1423, 3) (355, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5kKZluP1mO2"
      },
      "source": [
        "## 1.3 数据预处理"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzNB_6Rg1or6"
      },
      "source": [
        "对文本数据进行编码，将文本编码成整数。Tokenizer是一个将文本向量化，转换成序列的类。用来文本处理的分词、嵌入。  \r\n",
        "参考：\r\n",
        "1. [Keras分词器 Tokenizer](http://codewithzhangyi.com/2019/04/23/keras-tokenizer/)  \r\n",
        "2. [保存机器学习模型——pickle和joblib](https://www.zhangqibot.com/post/ml-dump-models/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KObbIC3-d5M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42ddd75b-47ce-4e09-e493-12f193443d66"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\r\n",
        "from keras.preprocessing.sequence import pad_sequences\r\n",
        "# 1. 创建分词器 Tokenizer 对象\r\n",
        "tokenizer = Tokenizer() # 参数可以自己根据实际情况更改\r\n",
        "\r\n",
        "# 2. 整理整体语料，中文需空格分词\r\n",
        "text = raw_data['grammar']\r\n",
        "\r\n",
        "# 3. 将Tokenizer拟合语料，生成字典，形成新的tokenizer\r\n",
        "tokenizer.fit_on_texts(text)\r\n",
        "\r\n",
        "# 4. 保存tokenizer，避免重复对同一语料进行拟合\r\n",
        "# import pickle\r\n",
        "# pkl_filename = \"myspace_tokenizer.pkl\"  \r\n",
        "# with open(pkl_filename, 'wb') as file:  \r\n",
        "#    pickle.dump(model, file)\r\n",
        "\r\n",
        "# 5. 整合需要做嵌入的文本，中文需要空格分词\r\n",
        "new_text = new_data['grammar']\r\n",
        "\r\n",
        "# 6. 将文本向量化\r\n",
        "list_tokenized = tokenizer.texts_to_sequences(new_text)\r\n",
        "print(list_tokenized[:10])"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[3, 1], [5, 1], [3, 2], [7, 1], [4, 2], [4, 1], [12, 1], [5, 2], [6, 2], [7, 2]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_oofg6H3fm-"
      },
      "source": [
        "创建整数序列"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RaMOc4c72YYC",
        "outputId": "14f54170-3786-492b-fd4c-44dec549a7f8"
      },
      "source": [
        "sequences = list()\r\n",
        "for line in new_text:\r\n",
        "  encoded = tokenizer.texts_to_sequences([line])[0] # 将文本向量化\r\n",
        "  for i in range(1, len(encoded)):\r\n",
        "    sequence = encoded[:i+1]\r\n",
        "    sequences.append(sequence)\r\n",
        "print('Total Sequences: %d' % len(sequences))\r\n",
        "print(sequences[:5])"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Sequences: 6248\n",
            "[[3, 1], [5, 1], [3, 2], [7, 1], [4, 2]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eenf2plk4LXJ"
      },
      "source": [
        "填充序列"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhmN_S2D2YKV",
        "outputId": "face0b2d-86af-42c7-e580-6832c5b18ce0"
      },
      "source": [
        "# 7. 生成训练数据的序列\r\n",
        "max_length = max([len(seq) for seq in sequences])\r\n",
        "sequences = pad_sequences(sequences, maxlen=max_length, padding='pre')\r\n",
        "print('Max Sequence Length: %d' % max_length)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max Sequence Length: 600\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTb7QZUR5BkT"
      },
      "source": [
        "创建输入输出"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQT-UGLl5BO7",
        "outputId": "f4f00351-e928-49a2-b59c-227c7c933522"
      },
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1\r\n",
        "print('Vocabulary Size: %d' % vocab_size)\r\n",
        "sequences = array(sequences)\r\n",
        "X, y = sequences[:,:-1],sequences[:,-1]\r\n",
        "y = to_categorical(y, num_classes=vocab_size)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary Size: 72\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ReuPiQtN6T4e"
      },
      "source": [
        "# define the model\r\n",
        "def define_model(vocab_size, max_length):\r\n",
        "  model = Sequential()\r\n",
        "  model.add(Embedding(vocab_size, 10, input_length=max_length-1))\r\n",
        "  model.add(LSTM(50))\r\n",
        "  model.add(Dense(vocab_size, activation='softmax'))\r\n",
        "  # compile network\r\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\r\n",
        "  # summarize defined model\r\n",
        "  model.summary()\r\n",
        "  plot_model(model, to_file='model.png', show_shapes=True)\r\n",
        "  return model"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiBjZb5I6dkm"
      },
      "source": [
        "# generate a sequence from a language model\r\n",
        "def generate_seq(model, tokenizer, max_length, seed_text, n_words):\r\n",
        "  in_text = seed_text\r\n",
        "  # generate a fixed number of words\r\n",
        "  for _ in range(n_words):\r\n",
        "    # encode the text as integer\r\n",
        "    encoded = tokenizer.texts_to_sequences([in_text])[0]\r\n",
        "    # pre-pad sequences to a fixed length\r\n",
        "    encoded = pad_sequences([encoded], maxlen=max_length, padding='pre')\r\n",
        "    # predict probabilities for each word\r\n",
        "    yhat = model.predict_classes(encoded, verbose=0)\r\n",
        "    # map predicted word index to word\r\n",
        "    out_word = ''\r\n",
        "    for word, index in tokenizer.word_index.items():\r\n",
        "      if index == yhat:\r\n",
        "        out_word = word\r\n",
        "      break\r\n",
        "    # append to input\r\n",
        "    in_text += ' ' + out_word\r\n",
        "  return in_text"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gYrVKKC7GGw",
        "outputId": "f5dfe5ed-6941-4ccc-9ff2-575fb29c66d0"
      },
      "source": [
        "# define model\r\n",
        "model = define_model(vocab_size, max_length)\r\n",
        "# fit network\r\n",
        "model.fit(X, y, epochs=3, verbose=2)\r\n",
        "# evaluate model\r\n",
        "print(generate_seq(model, tokenizer, max_length-1, '', 2))\r\n",
        "print(generate_seq(model, tokenizer, max_length-1, '', 2))"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 599, 10)           720       \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 50)                12200     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 72)                3672      \n",
            "=================================================================\n",
            "Total params: 16,592\n",
            "Trainable params: 16,592\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/3\n",
            "196/196 - 64s - loss: 2.7270 - accuracy: 0.2318\n",
            "Epoch 2/3\n",
            "196/196 - 62s - loss: 2.3444 - accuracy: 0.2694\n",
            "Epoch 3/3\n",
            "196/196 - 64s - loss: 2.0652 - accuracy: 0.3175\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  \n",
            "  \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}