{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "exp1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN1ZDHVJS9xNsLv6NQuvh5f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YapingWu/GoogleColab/blob/main/lstm/exp1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCDc80rNi4p2"
      },
      "source": [
        "参考资料：[通过keras例子理解LSTM 循环神经网络(RNN)](https://blog.csdn.net/zwqjoy/article/details/80493341)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Quu6cTMapKSa"
      },
      "source": [
        "学习字母表的一个简单的序列预测问题。也就是说，根据字母表的字母，可以预测字母表的下一个字母。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmzC8cXqr1Jr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1592c082-b71c-4d82-b0d2-b1bc20a8d14c"
      },
      "source": [
        "# 获取模块的版本号\r\n",
        "import platform \r\n",
        "import keras\r\n",
        "print(platform.python_version()) # 3.6.9\r\n",
        "print(keras.__version__) # 2.4.3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3.6.9\n",
            "2.4.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7OutPH4pP6u"
      },
      "source": [
        "导入需要使用的所用类和函数"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ehLV4Afpe2b"
      },
      "source": [
        "import numpy\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense\r\n",
        "from keras.layers import LSTM\r\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eUSnJUYpYMd"
      },
      "source": [
        "对随机数生成器选定随机数种子，以确保每次执行代码时结果都是相同的。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXvC6lDHpvWf"
      },
      "source": [
        "# fix random seed for reproducibility\r\n",
        "numpy.random.seed(7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T489A7Y4p2oL"
      },
      "source": [
        "## 1 定义数据集——字母表"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMAz66SIqAe6"
      },
      "source": [
        "# define the raw dataset\r\n",
        "alphabet = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\r\n",
        "# create mapping of characters to integers (0-25) and the reverse\r\n",
        "# 神经网络是对数字建模，因此我们需要将字母表中的字母映射到整数值（把字母映射为数字）\r\n",
        "char_to_int = dict((c, i) for i, c in enumerate(alphabet))\r\n",
        "# 创建一个反向查找，以便将预测转换回字符\r\n",
        "int_to_char = dict((i, c) for i, c in enumerate(alphabet))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqbdVM8SqWsV"
      },
      "source": [
        "## 2 数据预处理——创建输入输出\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvoqJaY0qrk5"
      },
      "source": [
        "# prepare the dataset of input to output pairs encoded as integers\r\n",
        "# 定义输入序列长度\r\n",
        "seq_length = 1\r\n",
        "dataX = []\r\n",
        "dataY = []\r\n",
        "for i in range(0, len(alphabet) - seq_length, 1):\r\n",
        "    seq_in = alphabet[i:i + seq_length]\r\n",
        "    seq_out = alphabet[i + seq_length]\r\n",
        "    dataX.append([char_to_int[char] for char in seq_in]) # 为什么？\r\n",
        "    dataY.append(char_to_int[seq_out])\r\n",
        "    print(seq_in, '->', seq_out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xv6Gbm8dtWTi"
      },
      "source": [
        "### 2.1 转换输入序列的格式\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZR3oiFklvASz"
      },
      "source": [
        "将NumPy数组重新构造为LSTM网络所期望的格式，即[samples示例, time steps时间步数, features特征]。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wg8CtsDJtb2u"
      },
      "source": [
        "# reshape X to be [samples, time steps, features]\r\n",
        "X = numpy.reshape(dataX, (len(dataX), seq_length, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CeSYn1Xu8CO"
      },
      "source": [
        "### 2.2 归一化"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksmRk_tovHZ4"
      },
      "source": [
        "整数值归一化到0～1的区间上，这是LSTM网络使用的s形激活函数（sigmoid）的范围。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6h6m3LCu50q"
      },
      "source": [
        "# normalize\r\n",
        "X = X / float(len(alphabet))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHy76f3lvUVB"
      },
      "source": [
        "### 2.3 对输出进行编码"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kiIuw0fCvYUB"
      },
      "source": [
        "可以把这个问题看作是一个序列分类任务，其中26个字母代表一个不同的类。因此，我们用keras的内置的to_categorical()函数把输出output(y)进行one－hot编码(one-hot指n维单位向量a=(0,…,0,1,0,…,0))作为输出层的结果。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Lj0s00wvkHT"
      },
      "source": [
        "# one hot encode the output variable\r\n",
        "y = np_utils.to_categorical(dataY)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33YRq7cgze0w"
      },
      "source": [
        "## 3 单字符——单字符映射的简单LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJStCq4mzmYo"
      },
      "source": [
        "设计一个简单的LSTM，学习如何根据一个字符的上下文来预测字母表中的下一个字符。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBtV_xVXzt_F"
      },
      "source": [
        "问题定义：一些单字母的随机集合作为输入，另一些单字母作为输出，由输入输出对组成。正如我们所看到的，这对于LSTM来说是一个很难用来学习的结构。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgrDR8cN2UMD"
      },
      "source": [
        "定义一个LSTM网络。  \r\n",
        "单元数：32个(the LSTM units are the “memory units” or you can just call them the neurons.)  \r\n",
        "输出层：激活函数：softmax  \r\n",
        "损失函数：使用Keras中的对数损失函数(称为“分类交叉熵”(categorical_crossentropy))  \r\n",
        "优化方法：Adam"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXDO9RHE2nqu"
      },
      "source": [
        "该模型以500批次(epochs)，每批次数据输入大小(batch)为1的形式训练"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zndGJAgJ2tJg"
      },
      "source": [
        "# create and fit the model\r\n",
        "model = Sequential()\r\n",
        "model.add(LSTM(32, input_shape=(X.shape[1], X.shape[2])))\r\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\r\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\r\n",
        "model.fit(X, y, epochs=500, batch_size=1, verbose=2)\r\n",
        "\r\n",
        "# verbose：日志显示\r\n",
        "# verbose = 0 为不在标准输出流输出日志信息\r\n",
        "# verbose = 1 为输出进度条记录\r\n",
        "# verbose = 2 为每个epoch输出一行记录\r\n",
        "# 注意： 默认为 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOu6RUTC3_RF"
      },
      "source": [
        "在我们训练模型之后，我们可以对整个训练集的性能进行评估和总结。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTrInmKR4Cpv",
        "outputId": "d442d026-d616-48f6-b18d-2a85987a8d54"
      },
      "source": [
        "# summarize performance of the model\r\n",
        "scores = model.evaluate(X, y, verbose=0)\r\n",
        "print(\"Model Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model Accuracy: 80.00%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDV0S5xN4Mks"
      },
      "source": [
        "然后，我们可以通过网络重新运行训练数据，并生成预测，将输入和输出对转换回原来的字符格式，以获得关于网络如何了解问题的视觉效果。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pu0Q8s2n4OIL"
      },
      "source": [
        "# demonstrate some model predictions\r\n",
        "for pattern in dataX:\r\n",
        "    x = numpy.reshape(pattern, (1, len(pattern), 1))\r\n",
        "    x = x / float(len(alphabet))\r\n",
        "    prediction = model.predict(x, verbose=0)\r\n",
        "    index = numpy.argmax(prediction) # 分类结果中概率最大的类别\r\n",
        "    result = int_to_char[index]\r\n",
        "    seq_in = [int_to_char[value] for value in pattern]\r\n",
        "    print(seq_in, \"->\", result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogvH3j-v5Ktt"
      },
      "source": [
        "我们可以看到，这个问题对于网络来说确实是很困难的。\r\n",
        "原因是可怜的lstm单元根本没有可以利用的上下文章信息。\r\n",
        "每个输入输出模式都以随机的顺序显示在网络中，并且网络的状态在每个模式之后被重置(每个批处理的每个批次包含一个模式)。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWpXbvUL5RG8"
      },
      "source": [
        "这是对LSTM网络架构的滥用，因为我们把它当作了一个标准的多层感知器。\r\n",
        "\r\n",
        "接下来，让我们尝试一个不同的问题框架，以便为网络提供更多的序列来学习。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlGze3Ji5Wxp"
      },
      "source": [
        "## 4 三字符特征——单字符的映射的简单LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFG_7zPW5lDn"
      },
      "source": [
        "在多层感知器中添加更多上下文最流行的方法是特征窗口方法(Feature Window method)。\r\n",
        "\r\n",
        "即序列中的前面步骤的输出被作为附加的输入特性提供给网络。我们可以用相同的技巧，为LSTM网络提供更多的上下文。\r\n",
        "\r\n",
        "在这里，我们将序列长度从1增加到3，例如:\r\n",
        "我们把输入从一个字符升到三个字符。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHiBXyfZ5ohn"
      },
      "source": [
        "# prepare the dataset of input to output pairs encoded as integers\r\n",
        "seq_length = 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nuov9Ha-5xmf"
      },
      "source": [
        "然后将序列中的每个元素作为网络的一个新输入特性提供给它。这需要修改输入序列在数据准备步骤中的reshape:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOtB_Nx95062",
        "outputId": "5fff8fbb-268e-4e97-d304-7f5e04ff27dd"
      },
      "source": [
        "# Naive LSTM to learn three-char window to one-char mapping\r\n",
        "import numpy\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense\r\n",
        "from keras.layers import LSTM\r\n",
        "from keras.utils import np_utils\r\n",
        "# fix random seed for reproducibility\r\n",
        "numpy.random.seed(7)\r\n",
        "# define the raw dataset\r\n",
        "alphabet = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\r\n",
        "# create mapping of characters to integers (0-25) and the reverse\r\n",
        "char_to_int = dict((c, i) for i, c in enumerate(alphabet))\r\n",
        "int_to_char = dict((i, c) for i, c in enumerate(alphabet))\r\n",
        "# prepare the dataset of input to output pairs encoded as integers\r\n",
        "seq_length = 3\r\n",
        "dataX = []\r\n",
        "dataY = []\r\n",
        "for i in range(0, len(alphabet) - seq_length, 1):\r\n",
        "    seq_in = alphabet[i:i + seq_length]\r\n",
        "    seq_out = alphabet[i + seq_length]\r\n",
        "    dataX.append([char_to_int[char] for char in seq_in])\r\n",
        "    dataY.append(char_to_int[seq_out])\r\n",
        "    # print(seq_in, \"->\", seq_out)\r\n",
        "# reshape X to be [samples, time steps, features]\r\n",
        "X = numpy.reshape(dataX, (len(dataX), 1, seq_length))\r\n",
        "# print(\"dataX:\", dataX, sep='\\n')\r\n",
        "# print(\"X:\", X, sep='\\n')\r\n",
        "# normalize\r\n",
        "X = X / float(len(alphabet))\r\n",
        "# one hot encode the output variable\r\n",
        "y = np_utils.to_categorical(dataY)\r\n",
        "# create and fit the model\r\n",
        "model = Sequential()\r\n",
        "model.add(LSTM(32, input_shape=(X.shape[1], X.shape[2])))\r\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\r\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\r\n",
        "model.fit(X, y, epochs=500, batch_size=1, verbose=0)\r\n",
        "# summarize performance of the model\r\n",
        "scores = model.evaluate(X, y, verbose=0)\r\n",
        "print(\"Model Accuracy: %.2f%%\" % (scores[1]*100))\r\n",
        "# demonstrate some model predictions\r\n",
        "for pattern in dataX:\r\n",
        "    x = numpy.reshape(pattern, (1, 1, len(pattern)))\r\n",
        "    x = x / float(len(alphabet))\r\n",
        "    prediction = model.predict(x, verbose=0)\r\n",
        "    index = numpy.argmax(prediction)\r\n",
        "    result = int_to_char[index]\r\n",
        "    seq_in = [int_to_char[value] for value in pattern]\r\n",
        "    print(seq_in, \"->\", result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7f7064529a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Model Accuracy: 82.61%\n",
            "['A', 'B', 'C'] -> D\n",
            "['B', 'C', 'D'] -> E\n",
            "['C', 'D', 'E'] -> F\n",
            "['D', 'E', 'F'] -> G\n",
            "['E', 'F', 'G'] -> H\n",
            "['F', 'G', 'H'] -> I\n",
            "['G', 'H', 'I'] -> J\n",
            "['H', 'I', 'J'] -> K\n",
            "['I', 'J', 'K'] -> L\n",
            "['J', 'K', 'L'] -> M\n",
            "['K', 'L', 'M'] -> N\n",
            "['L', 'M', 'N'] -> O\n",
            "['M', 'N', 'O'] -> P\n",
            "['N', 'O', 'P'] -> Q\n",
            "['O', 'P', 'Q'] -> Q\n",
            "['P', 'Q', 'R'] -> S\n",
            "['Q', 'R', 'S'] -> T\n",
            "['R', 'S', 'T'] -> U\n",
            "['S', 'T', 'U'] -> V\n",
            "['T', 'U', 'V'] -> X\n",
            "['U', 'V', 'W'] -> Z\n",
            "['V', 'W', 'X'] -> Z\n",
            "['W', 'X', 'Y'] -> Z\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DkkgoQ-p-oSO"
      },
      "source": [
        "## 5 keras实践循环的正确打开方式！"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2RD-yti-yOG"
      },
      "source": [
        "在keras中，利用lstm的关键是以时间序列(time steps)的方法来提供上下文，而不是像其他网络结构(CNN)一样，通过windowed features的方式。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfZ6uNrn-5vQ"
      },
      "source": [
        "我们这次唯一改变的地方是下面这里："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdkCKaiK-8AS"
      },
      "source": [
        "# reshape X to be [samples, time steps, features]\r\n",
        "X = numpy.reshape(dataX, (len(dataX), seq_length, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gx_VUoAg-_cq"
      },
      "source": [
        "time steps这个参数，我们设置了3，而不是前面的1。\r\n",
        "\r\n",
        "不同之处是，对输入数据的reshape是将输入序列作为一个特性的time step序列，而不是多个特性的单一time step。也就是说我们把ABC 看成独立的一个特征组成的多个时间序列，而不是把ABC看成一个多个特征组成一个时间序列。\r\n",
        "\r\n",
        "这就是keras中LSTM循环神经网络的正确打开的方式。我的理解是，这样在训练 ABC——D的时候，BCD，CDE，都可以发挥作用。而最开始那种使用方法，只是利用了ABC——D这样一个训练样本。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s86erqvq_jJI",
        "outputId": "e5d8b991-ebdd-4766-9615-7f4cbd374dba"
      },
      "source": [
        "# Naive LSTM to learn three-char time steps to one-char mapping\r\n",
        "import numpy\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense\r\n",
        "from keras.layers import LSTM\r\n",
        "from keras.utils import np_utils\r\n",
        "# fix random seed for reproducibility\r\n",
        "numpy.random.seed(7)\r\n",
        "# define the raw dataset\r\n",
        "alphabet = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\r\n",
        "# create mapping of characters to integers (0-25) and the reverse\r\n",
        "char_to_int = dict((c, i) for i, c in enumerate(alphabet))\r\n",
        "int_to_char = dict((i, c) for i, c in enumerate(alphabet))\r\n",
        "# prepare the dataset of input to output pairs encoded as integers\r\n",
        "seq_length = 3\r\n",
        "dataX = []\r\n",
        "dataY = []\r\n",
        "for i in range(0, len(alphabet) - seq_length, 1):\r\n",
        "    seq_in = alphabet[i:i + seq_length]\r\n",
        "    seq_out = alphabet[i + seq_length]\r\n",
        "    dataX.append([char_to_int[char] for char in seq_in])\r\n",
        "    dataY.append(char_to_int[seq_out])\r\n",
        "    # print(seq_in, '->', seq_out)\r\n",
        "# reshape X to be [samples, time steps, features]\r\n",
        "X = numpy.reshape(dataX, (len(dataX), seq_length, 1))\r\n",
        "# print(\"X:\", X, sep='\\n')\r\n",
        "# normalize\r\n",
        "X = X / float(len(alphabet))\r\n",
        "# one hot encode the output variable\r\n",
        "y = np_utils.to_categorical(dataY)\r\n",
        "# create and fit the model\r\n",
        "model = Sequential()\r\n",
        "model.add(LSTM(32, input_shape=(X.shape[1], X.shape[2])))\r\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\r\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\r\n",
        "model.fit(X, y, epochs=500, batch_size=1, verbose=0)\r\n",
        "# summarize performance of the model\r\n",
        "scores = model.evaluate(X, y, verbose=0)\r\n",
        "print(\"Model Accuracy: %.2f%%\" % (scores[1]*100))\r\n",
        "# demonstrate some model predictions\r\n",
        "for pattern in dataX:\r\n",
        "    x = numpy.reshape(pattern, (1, len(pattern), 1))\r\n",
        "    x = x / float(len(alphabet))\r\n",
        "    prediction = model.predict(x, verbose=0)\r\n",
        "    index = numpy.argmax(prediction)\r\n",
        "    result = int_to_char[index]\r\n",
        "    seq_in = [int_to_char[value] for value in pattern]\r\n",
        "    print(seq_in, \"->\", result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:8 out of the last 8 calls to <function Model.make_test_function.<locals>.test_function at 0x7f70613a8620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Model Accuracy: 100.00%\n",
            "['A', 'B', 'C'] -> D\n",
            "['B', 'C', 'D'] -> E\n",
            "['C', 'D', 'E'] -> F\n",
            "['D', 'E', 'F'] -> G\n",
            "['E', 'F', 'G'] -> H\n",
            "['F', 'G', 'H'] -> I\n",
            "['G', 'H', 'I'] -> J\n",
            "['H', 'I', 'J'] -> K\n",
            "['I', 'J', 'K'] -> L\n",
            "['J', 'K', 'L'] -> M\n",
            "['K', 'L', 'M'] -> N\n",
            "['L', 'M', 'N'] -> O\n",
            "['M', 'N', 'O'] -> P\n",
            "['N', 'O', 'P'] -> Q\n",
            "['O', 'P', 'Q'] -> R\n",
            "['P', 'Q', 'R'] -> S\n",
            "['Q', 'R', 'S'] -> T\n",
            "['R', 'S', 'T'] -> U\n",
            "['S', 'T', 'U'] -> V\n",
            "['T', 'U', 'V'] -> W\n",
            "['U', 'V', 'W'] -> X\n",
            "['V', 'W', 'X'] -> Y\n",
            "['W', 'X', 'Y'] -> Z\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CcWNT7bARGX"
      },
      "source": [
        "它已经学会了用字母表中的三个字母来预测下一个字母的顺序。它可以显示字母表中的任意三个字母的随机序列，并预测下一个字母。\r\n",
        "\r\n",
        "我们还没有展示出循环神经网络的强大之处，因为上面这个问题我们用多层感知器，足够多的神经元，足够多的迭代次数也可以很好的解决。（三层神经网络拟合任意可以表示的函数）\r\n",
        "\r\n",
        "LSTM网络是有状态的。它们应该能够学习整个字母表序列，但是在默认情况下，keras在每次训练之后重新设置网络状态。\r\n",
        "\r\n",
        "那么接下来就是展示循环神经网络的独到之处！！"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvRg01JPAX9d"
      },
      "source": [
        "## 6 一个批处理中的LSTM状态"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIphp0ZuAdxT"
      },
      "source": [
        "keras实现的LSTM在每一个batch以后，都重置了LSTM的状态。\r\n",
        "\r\n",
        "这表明，如果我们的批处理大小足够容纳所有输入模式，如果所有输入模式都按顺序排序，LSTM就可以使用序列中的序列上下文来更好地学习序列。\r\n",
        "\r\n",
        "通过修改第一个示例来学习一对一映射，并将批处理大小从1增加到训练数据集的大小，我们可以很容易地演示这一点。\r\n",
        "\r\n",
        "此外，在每个epoch前，keras都重置了训练数据集。为了确保训练数据模式保持顺序，我们可以禁用这种洗牌。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXSoZd1-AWu-"
      },
      "source": [
        "model.fit(X, y, epochs=5000, batch_size=len(dataX), verbose=2, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_AEvKQcA5NQ"
      },
      "source": [
        "该网络将使用within-batch批序列来学习字符的映射，但在进行预测时，这个上下文将无法用于网络。我们可以对网络进行评估，以确定网络在随机序列和顺序序列的预测能力。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Ej8Nov6BDSM",
        "outputId": "e982223a-5ea0-4890-ae5d-0a4af309221f"
      },
      "source": [
        "# Naive LSTM to learn one-char to one-char mapping with all data in each batch\r\n",
        "import numpy\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense\r\n",
        "from keras.layers import LSTM\r\n",
        "from keras.utils import np_utils\r\n",
        "from keras.preprocessing.sequence import pad_sequences\r\n",
        "# fix random seed for reproducibility\r\n",
        "numpy.random.seed(7)\r\n",
        "# define the raw dataset\r\n",
        "alphabet = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\r\n",
        "# create mapping of characters to integers (0-25) and the reverse\r\n",
        "char_to_int = dict((c, i) for i, c in enumerate(alphabet))\r\n",
        "int_to_char = dict((i, c) for i, c in enumerate(alphabet))\r\n",
        "# prepare the dataset of input to output pairs encoded as integers\r\n",
        "seq_length = 1\r\n",
        "dataX = []\r\n",
        "dataY = []\r\n",
        "for i in range(0, len(alphabet) - seq_length, 1):\r\n",
        "    seq_in = alphabet[i:i + seq_length]\r\n",
        "    seq_out = alphabet[i + seq_length]\r\n",
        "    dataX.append([char_to_int[char] for char in seq_in])\r\n",
        "    dataY.append(char_to_int[seq_out])\r\n",
        "    # print(seq_in, '->', seq_out)\r\n",
        "# convert list of lists to array and pad sequences if needed\r\n",
        "X = pad_sequences(dataX, maxlen=seq_length, dtype='float32')\r\n",
        "# reshape X to be [samples, time steps, features]\r\n",
        "X = numpy.reshape(dataX, (X.shape[0], seq_length, 1))\r\n",
        "# normalize\r\n",
        "X = X / float(len(alphabet))\r\n",
        "# one hot encode the output variable\r\n",
        "y = np_utils.to_categorical(dataY)\r\n",
        "# create and fit the model\r\n",
        "model = Sequential()\r\n",
        "model.add(LSTM(16, input_shape=(X.shape[1], X.shape[2])))\r\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\r\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\r\n",
        "model.fit(X, y, epochs=5000, batch_size=len(dataX), verbose=0, shuffle=False)\r\n",
        "# summarize performance of the model\r\n",
        "scores = model.evaluate(X, y, verbose=0)\r\n",
        "print(\"Model Accuracy: %.2f%%\" % (scores[1]*100))\r\n",
        "# demonstrate some model predictions\r\n",
        "for pattern in dataX:\r\n",
        "    x = numpy.reshape(pattern, (1, len(pattern), 1))\r\n",
        "    x = x / float(len(alphabet))\r\n",
        "    prediction = model.predict(x, verbose=0)\r\n",
        "    index = numpy.argmax(prediction)\r\n",
        "    result = int_to_char[index]\r\n",
        "    seq_in = [int_to_char[value] for value in pattern]\r\n",
        "    print(seq_in, \"->\", result)\r\n",
        "# demonstrate predicting random patterns\r\n",
        "print(\"Test a Random Pattern:\")\r\n",
        "for i in range(0,20):\r\n",
        "    pattern_index = numpy.random.randint(len(dataX))\r\n",
        "    pattern = dataX[pattern_index]\r\n",
        "    x = numpy.reshape(pattern, (1, len(pattern), 1))\r\n",
        "    x = x / float(len(alphabet))\r\n",
        "    prediction = model.predict(x, verbose=0)\r\n",
        "    index = numpy.argmax(prediction)\r\n",
        "    result = int_to_char[index]\r\n",
        "    seq_in = [int_to_char[value] for value in pattern]\r\n",
        "    print(seq_in, \"->\", result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model Accuracy: 100.00%\n",
            "['A'] -> B\n",
            "['B'] -> C\n",
            "['C'] -> D\n",
            "['D'] -> E\n",
            "['E'] -> F\n",
            "['F'] -> G\n",
            "['G'] -> H\n",
            "['H'] -> I\n",
            "['I'] -> J\n",
            "['J'] -> K\n",
            "['K'] -> L\n",
            "['L'] -> M\n",
            "['M'] -> N\n",
            "['N'] -> O\n",
            "['O'] -> P\n",
            "['P'] -> Q\n",
            "['Q'] -> R\n",
            "['R'] -> S\n",
            "['S'] -> T\n",
            "['T'] -> U\n",
            "['U'] -> V\n",
            "['V'] -> W\n",
            "['W'] -> X\n",
            "['X'] -> Y\n",
            "['Y'] -> Z\n",
            "Test a Random Pattern:\n",
            "['P'] -> Q\n",
            "['E'] -> F\n",
            "['W'] -> X\n",
            "['D'] -> E\n",
            "['T'] -> U\n",
            "['X'] -> Y\n",
            "['H'] -> I\n",
            "['O'] -> P\n",
            "['X'] -> Y\n",
            "['I'] -> J\n",
            "['O'] -> P\n",
            "['K'] -> L\n",
            "['I'] -> J\n",
            "['H'] -> I\n",
            "['G'] -> H\n",
            "['E'] -> F\n",
            "['Q'] -> R\n",
            "['H'] -> I\n",
            "['M'] -> N\n",
            "['A'] -> B\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}