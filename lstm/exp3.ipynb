{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "exp3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMYq7yX8MOH2oGe7l2+x47i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YapingWu/GoogleColab/blob/main/lstm/exp3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFaWmPlHQJ-_"
      },
      "source": [
        "使用lstm生成文本。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsAZFfptQZ6n"
      },
      "source": [
        "导入需要的包"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIPF3U9nQYZG"
      },
      "source": [
        "import numpy as np\r\n",
        "from keras.preprocessing.text import Tokenizer\r\n",
        "from keras.utils import to_categorical\r\n",
        "from keras.preprocessing.sequence import pad_sequences\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense\r\n",
        "from keras.layers import LSTM\r\n",
        "from keras.layers import Embedding"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnAi-b4pQwOn"
      },
      "source": [
        "# 1 加载数据"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcMu5ks6Pq2F"
      },
      "source": [
        "data = \"\"\" Jack and Jill went up the hill\\n\r\n",
        "To fetch a pail of water\\n\r\n",
        "Jack fell down and broke his crown\\n\r\n",
        "And Jill came tumbling after\\n \"\"\""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvvUxLWkTwCM"
      },
      "source": [
        "## 使用keras的Tokenizer将文本转换为整数序列。\r\n",
        "\r\n",
        "Tokenizer的原理是：按照词频对训练文本中的词降序排序，然后使用序号对词进行编码。例如：排名第一的词对应的整数值是1，排名第二的词对应的整数值是2。\r\n",
        "\r\n",
        "fit_on_texts后有两个有用的输出：  \r\n",
        "word_counts：词频统计结果  \r\n",
        "word_index：词和index的对应关系，也就是词和整数的对应的关系  \r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONsF_RGQRFfK",
        "outputId": "93e187b1-d25e-47f7-9290-be1e3320d17b"
      },
      "source": [
        "# prepare the tokenizer on the source text\r\n",
        "# 创建分词器 Tokenizer 对象\r\n",
        "tokenizer = Tokenizer()\r\n",
        "# 使用 data 训练分词器\r\n",
        "tokenizer.fit_on_texts([data])\r\n",
        "\r\n",
        "print(tokenizer.word_counts)\r\n",
        "print(tokenizer.word_docs)\r\n",
        "print(tokenizer.word_index) \r\n",
        "print(tokenizer.document_count)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OrderedDict([('jack', 2), ('and', 3), ('jill', 2), ('went', 1), ('up', 1), ('the', 1), ('hill', 1), ('to', 1), ('fetch', 1), ('a', 1), ('pail', 1), ('of', 1), ('water', 1), ('fell', 1), ('down', 1), ('broke', 1), ('his', 1), ('crown', 1), ('came', 1), ('tumbling', 1), ('after', 1)])\n",
            "defaultdict(<class 'int'>, {'to': 1, 'jill': 1, 'came': 1, 'water': 1, 'broke': 1, 'his': 1, 'of': 1, 'fell': 1, 'after': 1, 'jack': 1, 'tumbling': 1, 'went': 1, 'the': 1, 'down': 1, 'fetch': 1, 'hill': 1, 'a': 1, 'and': 1, 'crown': 1, 'pail': 1, 'up': 1})\n",
            "{'and': 1, 'jack': 2, 'jill': 3, 'went': 4, 'up': 5, 'the': 6, 'hill': 7, 'to': 8, 'fetch': 9, 'a': 10, 'pail': 11, 'of': 12, 'water': 13, 'fell': 14, 'down': 15, 'broke': 16, 'his': 17, 'crown': 18, 'came': 19, 'tumbling': 20, 'after': 21}\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiok1_uGWL9D"
      },
      "source": [
        "## 确定词汇量"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-dgczbIUY21",
        "outputId": "b37bd6bd-2f06-440a-bd8d-29830fe6f8cf"
      },
      "source": [
        "# 确定词汇量（原始文本中词去重后的数量）\r\n",
        "vocab_size = len(tokenizer.word_index) + 1\r\n",
        "print('Vocabulary Size: %d' % vocab_size)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary Size: 22\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHtgLbSsWfFO"
      },
      "source": [
        "## 基于行创建序列"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ObEBOUYOWrnD",
        "outputId": "42890aa2-da53-4be9-f635-10fc03d086d8"
      },
      "source": [
        "sequences = list()\r\n",
        "for line in data.split('\\n'):\r\n",
        "  # 将文本转换为（整数）序列\r\n",
        "  encoded = tokenizer.texts_to_sequences([line])[0]  # tokenizer.texts_to_sequences([line])的结果[[2, 1, 3, 4, 5, 6, 7]]\r\n",
        "  print(encoded)\r\n",
        "  for i in range(1, len(encoded)):\r\n",
        "    sequence = encoded[:i+1]\r\n",
        "    sequences.append(sequence)\r\n",
        "print('Total Sequences: %d' % len(sequences))\r\n",
        "print(sequences[:10])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2, 1, 3, 4, 5, 6, 7]\n",
            "[]\n",
            "[8, 9, 10, 11, 12, 13]\n",
            "[]\n",
            "[2, 14, 15, 1, 16, 17, 18]\n",
            "[]\n",
            "[1, 3, 19, 20, 21]\n",
            "[]\n",
            "Total Sequences: 21\n",
            "[[2, 1], [2, 1, 3], [2, 1, 3, 4], [2, 1, 3, 4, 5], [2, 1, 3, 4, 5, 6], [2, 1, 3, 4, 5, 6, 7], [8, 9], [8, 9, 10], [8, 9, 10, 11], [8, 9, 10, 11, 12]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgMlKItWZTZg"
      },
      "source": [
        "## 填充序列"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIEP6V7vZaCp",
        "outputId": "545764eb-0932-46a3-96a9-5281ab7dff9f"
      },
      "source": [
        "# pad input sequences\r\n",
        "max_length = max([len(seq) for seq in sequences])\r\n",
        "sequences = pad_sequences(sequences, maxlen=max_length, padding='pre') # 左边填充0\r\n",
        "print('Max Sequence Length: %d' % max_length)\r\n",
        "print(sequences[:10])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max Sequence Length: 7\n",
            "[[ 0  0  0  0  0  2  1]\n",
            " [ 0  0  0  0  2  1  3]\n",
            " [ 0  0  0  2  1  3  4]\n",
            " [ 0  0  2  1  3  4  5]\n",
            " [ 0  2  1  3  4  5  6]\n",
            " [ 2  1  3  4  5  6  7]\n",
            " [ 0  0  0  0  0  8  9]\n",
            " [ 0  0  0  0  8  9 10]\n",
            " [ 0  0  0  8  9 10 11]\n",
            " [ 0  0  8  9 10 11 12]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEUFFATQajho"
      },
      "source": [
        "# 创建输入输出"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wdff6Dwraog0",
        "outputId": "9886d1f7-87bf-4bb3-bffc-c57583953f07"
      },
      "source": [
        "sequences = np.array(sequences)\r\n",
        "X, y = sequences[:, :-1], sequences[:, -1]\r\n",
        "print(X[:5])\r\n",
        "print(y[:5])\r\n",
        "y = to_categorical(y, num_classes=vocab_size) # 对输出进行one-hot编码"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 0 0 0 0 2]\n",
            " [0 0 0 0 2 1]\n",
            " [0 0 0 2 1 3]\n",
            " [0 0 2 1 3 4]\n",
            " [0 2 1 3 4 5]]\n",
            "[1 3 4 5 6]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vMFxzgobIwH"
      },
      "source": [
        "# 定义模型"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8VJ2qq2cq3c"
      },
      "source": [
        "Embedding：  \r\n",
        "输入shape：形如（samples，sequence_length）的2D张量  \r\n",
        "输出shape：形如(samples, sequence_length, output_dim)的3D张量  \r\n",
        "嵌入层将正整数（下标）转换为具有固定大小的向量，如[[4],[20]]->[[0.25,0.1],[0.6,-0.2]]。[Embedding详解](https://blog.csdn.net/jiangpeng59/article/details/77533309) \r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "LSTM：  \r\n",
        "输入shape：(samples, time_steps, input_dim)  \r\n",
        "输出shape：(samples, output_dim)\r\n",
        "\r\n",
        "*samples表示样本数量*\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ywg8UO7zbWWz"
      },
      "source": [
        "def define_model(vocab_size, max_length):\r\n",
        "  model = Sequential()\r\n",
        "  model.add(Embedding(input_dim=vocab_size, output_dim=10, input_length=max_length-1))\r\n",
        "  model.add(LSTM(50))\r\n",
        "  model.add(Dense(vocab_size, activation='softmax'))\r\n",
        "  # compile network\r\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\r\n",
        "  # summarize defined model\r\n",
        "  model.summary()\r\n",
        "  # plot_model(model, to_file='model.png', show_shapes=True)\r\n",
        "  return model"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYKfHyMHbM4F",
        "outputId": "01b968dc-0a46-4ce5-88ee-11136dc0ff30"
      },
      "source": [
        "# define model\r\n",
        "model = define_model(vocab_size, max_length)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 6, 10)             220       \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 50)                12200     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 22)                1122      \n",
            "=================================================================\n",
            "Total params: 13,542\n",
            "Trainable params: 13,542\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0yC7OMmlI_d"
      },
      "source": [
        "# 训练模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "425k7WvKlLpg"
      },
      "source": [
        "# fit network\r\n",
        "model.fit(X, y, epochs=500, verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPwCD5SVlRgR"
      },
      "source": [
        "# 评估模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYOBBmbMlvvi"
      },
      "source": [
        "# generate a sequence from a language model\r\n",
        "# 给定一个词，生成其后的n_words个词\r\n",
        "def generate_seq(model, tokenizer, max_length, seed_text, n_words):\r\n",
        "  in_text = seed_text\r\n",
        "  # generate a fixed number of words\r\n",
        "  for _ in range(n_words):\r\n",
        "    # encode the text as integer\r\n",
        "    encoded = tokenizer.texts_to_sequences([in_text])[0]\r\n",
        "    # pre-pad sequences to a fixed length\r\n",
        "    encoded = pad_sequences([encoded], maxlen=max_length, padding='pre')\r\n",
        "    # predict probabilities for each word\r\n",
        "    # yhat = model.predict_classes(encoded, verbose=0)\r\n",
        "    yhat = np.argmax(model.predict(encoded))\r\n",
        "    # map predicted word index to word\r\n",
        "    out_word = ''\r\n",
        "    for word, index in tokenizer.word_index.items():\r\n",
        "      if index == yhat:\r\n",
        "        out_word = word\r\n",
        "        break\r\n",
        "    # append to input\r\n",
        "    in_text += ' ' + out_word\r\n",
        "  return in_text"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRrLySdUlUT1",
        "outputId": "fa514ced-d8c8-492d-8607-eca43ca944fe"
      },
      "source": [
        "# evaluate model\r\n",
        "print(generate_seq(model, tokenizer, max_length-1, 'Jack', 4))\r\n",
        "print(generate_seq(model, tokenizer, max_length-1, 'Jill', 4))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Jack fell down and broke\n",
            "Jill jill came tumbling after\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}