{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "exp3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM6zZmcwuvnaC4QfBZqIAQj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YapingWu/GoogleColab/blob/main/lstm/exp3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFaWmPlHQJ-_"
      },
      "source": [
        "使用lstm生成文本。此示例使用的是many-to-one模型，输入多个词，输出一个词。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsAZFfptQZ6n"
      },
      "source": [
        "导入需要的包"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIPF3U9nQYZG"
      },
      "source": [
        "import numpy as np\r\n",
        "from keras.preprocessing.text import Tokenizer\r\n",
        "from keras.utils import to_categorical\r\n",
        "from keras.preprocessing.sequence import pad_sequences\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense\r\n",
        "from keras.layers import LSTM\r\n",
        "from keras.layers import Embedding"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnAi-b4pQwOn"
      },
      "source": [
        "# 1 加载数据"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcMu5ks6Pq2F"
      },
      "source": [
        "data = \"\"\" Jack and Jill went up the hill\\n\r\n",
        "To fetch a pail of water\\n\r\n",
        "Jack fell down and broke his crown\\n\r\n",
        "And Jill came tumbling after\\n \"\"\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvvUxLWkTwCM"
      },
      "source": [
        "## 使用keras的Tokenizer将文本转换为整数序列。\r\n",
        "\r\n",
        "Tokenizer的原理是：按照词频对训练文本中的词降序排序，然后使用序号对词进行编码。例如：排名第一的词对应的整数值是1，排名第二的词对应的整数值是2。\r\n",
        "\r\n",
        "fit_on_texts后有两个有用的输出：  \r\n",
        "word_counts：词频统计结果。例如：('jack', 2), ('and', 3), ('jill', 2), ('went', 1), ('up', 1)。  \r\n",
        "word_index：词和index的对应关系，也就是词和整数的对应的关系。先按照词频对训练文本中的词降序排序，然后从1开始取索引（index）值。例如：'and': 1, 'jack': 2, 'jill': 3, 'went': 4, 'up': 5。  \r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONsF_RGQRFfK"
      },
      "source": [
        "# prepare the tokenizer on the source text\r\n",
        "# 创建分词器 Tokenizer 对象\r\n",
        "tokenizer = Tokenizer()\r\n",
        "# 使用 data 训练分词器\r\n",
        "tokenizer.fit_on_texts([data])\r\n",
        "\r\n",
        "print(tokenizer.word_counts)\r\n",
        "print(tokenizer.word_docs)\r\n",
        "print(tokenizer.word_index) \r\n",
        "print(tokenizer.document_count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiok1_uGWL9D"
      },
      "source": [
        "## 确定词汇量"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELcZj5l0qyzt"
      },
      "source": [
        "作用：\r\n",
        "1. 后续定义模型时，词嵌入层需要用到。\r\n",
        "2. 使用one-hot编码编码输出的词。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-dgczbIUY21",
        "outputId": "c772d76f-36f4-4f24-c685-f7963cdac154"
      },
      "source": [
        "# 确定词汇量（原始文本中词去重后的数量）\r\n",
        "vocab_size = len(tokenizer.word_index) + 1\r\n",
        "print('Vocabulary Size: %d' % vocab_size)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary Size: 22\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHtgLbSsWfFO"
      },
      "source": [
        "## 基于行创建（整数）序列\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKVLEdHztW5Q"
      },
      "source": [
        "按照行创建序列，将原序列[2, 1, 3, 4, 5, 6, 7]转换成如下形式：  \r\n",
        "[2],   \r\n",
        "[2, 1],   \r\n",
        "[2, 1, 3],   \r\n",
        "[2, 1, 3, 4],   \r\n",
        "[2, 1, 3, 4, 5],   \r\n",
        "[2, 1, 3, 4, 5, 6],   \r\n",
        "[2, 1, 3, 4, 5, 6, 7]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObEBOUYOWrnD"
      },
      "source": [
        "sequences = list()\r\n",
        "for line in data.split('\\n'):\r\n",
        "  # 将文本转换为（整数）序列\r\n",
        "  encoded = tokenizer.texts_to_sequences([line])[0]  # tokenizer.texts_to_sequences([line])的结果[[2, 1, 3, 4, 5, 6, 7]]\r\n",
        "  print(encoded)\r\n",
        "  for i in range(1, len(encoded)+1):\r\n",
        "    sequence = encoded[:i]\r\n",
        "    sequences.append(sequence)\r\n",
        "print('Total Sequences: %d' % len(sequences))\r\n",
        "print(sequences[:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgMlKItWZTZg"
      },
      "source": [
        "## 填充序列"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qciTCYZqu1Mf"
      },
      "source": [
        "由于新序列的长度不一致，因此需要对序列进行填充使得所有序列长度相同。\r\n",
        "\r\n",
        "使用keras的pad_sequences来进行填充。\r\n",
        "\r\n",
        "填充结果：  \r\n",
        "[ 0  0  0  0  0  0  2]  \r\n",
        " [ 0  0  0  0  0  2  1]  \r\n",
        " [ 0  0  0  0  2  1  3]  \r\n",
        " [ 0  0  0  2  1  3  4]  \r\n",
        " [ 0  0  2  1  3  4  5]  \r\n",
        " [ 0  2  1  3  4  5  6]  \r\n",
        " [ 2  1  3  4  5  6  7]  \r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIEP6V7vZaCp"
      },
      "source": [
        "# pad input sequences\r\n",
        "max_length = max([len(seq) for seq in sequences])\r\n",
        "sequences = pad_sequences(sequences, maxlen=max_length, padding='pre') # 左边填充0\r\n",
        "print('Max Sequence Length: %d' % max_length)\r\n",
        "print(sequences[:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEUFFATQajho"
      },
      "source": [
        "# 创建输入输出"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHfSHPMsvwJn"
      },
      "source": [
        "从序列中数据分割出输入和输出数据。\r\n",
        "\r\n",
        "\r\n",
        "```\r\n",
        "    X       y  \r\n",
        "[0 0 0 0 0 0]  2  \r\n",
        "[0 0 0 0 0 2]  1  \r\n",
        "[0 0 0 0 2 1]  3  \r\n",
        "[0 0 0 2 1 3]  4  \r\n",
        "[0 0 2 1 3 4]  5 \r\n",
        "```\r\n",
        "\r\n",
        "\r\n",
        " \r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wdff6Dwraog0"
      },
      "source": [
        "sequences = np.array(sequences)\r\n",
        "X, y = sequences[:, :-1], sequences[:, -1]\r\n",
        "print(X[:5])\r\n",
        "print(y[:5])\r\n",
        "y = to_categorical(y, num_classes=vocab_size) # 对输出进行one-hot编码"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vMFxzgobIwH"
      },
      "source": [
        "# 定义模型"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8VJ2qq2cq3c"
      },
      "source": [
        "Embedding：  \r\n",
        "输入shape：形如（samples，sequence_length）的2D张量  \r\n",
        "输出shape：形如(samples, sequence_length, output_dim)的3D张量  \r\n",
        "嵌入层将正整数（下标）转换为具有固定大小的向量，如[[4],[20]]->[[0.25,0.1],[0.6,-0.2]]。[Embedding详解](https://blog.csdn.net/jiangpeng59/article/details/77533309) \r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "LSTM：  \r\n",
        "输入shape：(samples, time_steps, input_dim)  \r\n",
        "输出shape：(samples, output_dim)\r\n",
        "\r\n",
        "*samples表示样本数量*\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ywg8UO7zbWWz"
      },
      "source": [
        "def define_model(vocab_size, max_length):\r\n",
        "  model = Sequential()\r\n",
        "  model.add(Embedding(input_dim=vocab_size, output_dim=10, input_length=max_length-1))\r\n",
        "  model.add(LSTM(50))\r\n",
        "  model.add(Dense(vocab_size, activation='softmax'))\r\n",
        "  # compile network\r\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\r\n",
        "  # summarize defined model 输出模型各层的参数状况\r\n",
        "  model.summary()\r\n",
        "  # plot_model(model, to_file='model.png', show_shapes=True)\r\n",
        "  return model"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYKfHyMHbM4F",
        "outputId": "bced7c2a-ea9a-4497-8fe3-7b20510e247a"
      },
      "source": [
        "# define model\r\n",
        "model = define_model(vocab_size, max_length)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 6, 10)             220       \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 50)                12200     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 22)                1122      \n",
            "=================================================================\n",
            "Total params: 13,542\n",
            "Trainable params: 13,542\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0yC7OMmlI_d"
      },
      "source": [
        "# 训练模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "425k7WvKlLpg",
        "outputId": "9d558ada-9e68-42bc-ef8a-c2a5f4679796"
      },
      "source": [
        "# fit network 训练模型\r\n",
        "model.fit(X, y, epochs=500, verbose=0)\r\n",
        "# summarize performance of the model 总结模型性能\r\n",
        "scores = model.evaluate(X, y, verbose=0)\r\n",
        "print(\"Model Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model Accuracy: 88.00%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPwCD5SVlRgR"
      },
      "source": [
        "# 使用模型进行预测"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYOBBmbMlvvi"
      },
      "source": [
        "# generate a sequence from a language model\r\n",
        "# 给定一个词，生成其后的n_words个词\r\n",
        "def generate_seq(model, tokenizer, max_length, seed_text, n_words):\r\n",
        "  in_text = seed_text\r\n",
        "  # generate a fixed number of words\r\n",
        "  for _ in range(n_words):\r\n",
        "    # encode the text as integer\r\n",
        "    encoded = tokenizer.texts_to_sequences([in_text])[0]\r\n",
        "    # pre-pad sequences to a fixed length\r\n",
        "    encoded = pad_sequences([encoded], maxlen=max_length, padding='pre')\r\n",
        "    # predict probabilities for each word\r\n",
        "    # yhat = model.predict_classes(encoded, verbose=0)\r\n",
        "    yhat = np.argmax(model.predict(encoded))\r\n",
        "    # map predicted word index to word\r\n",
        "    out_word = ''\r\n",
        "    for word, index in tokenizer.word_index.items():\r\n",
        "      if index == yhat:\r\n",
        "        out_word = word\r\n",
        "        break\r\n",
        "    # append to input\r\n",
        "    in_text += ' ' + out_word\r\n",
        "  return in_text"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRrLySdUlUT1",
        "outputId": "a60b4d66-6878-43ba-dc63-b0024a9141f6"
      },
      "source": [
        "# evaluate model\r\n",
        "# 输入空，预测其后的4个词\r\n",
        "print(generate_seq(model, tokenizer, max_length-1, '', 4)) \r\n",
        "# 输入Jill，预测其后的4个词\r\n",
        "print(generate_seq(model, tokenizer, max_length-1, 'Jill', 4))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " jack and jill went\n",
            "Jill jill came tumbling after\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}