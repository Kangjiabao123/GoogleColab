{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "exp3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOymWp0d20w1n5sndJyiiVd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YapingWu/GoogleColab/blob/main/lstm/exp3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFaWmPlHQJ-_"
      },
      "source": [
        "使用lstm生成文本。此示例使用的是many-to-one模型，输入多个词，输出一个词。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsAZFfptQZ6n"
      },
      "source": [
        "导入需要的包"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIPF3U9nQYZG"
      },
      "source": [
        "import numpy as np\r\n",
        "from keras.preprocessing.text import Tokenizer\r\n",
        "from keras.utils import to_categorical\r\n",
        "from keras.preprocessing.sequence import pad_sequences\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense\r\n",
        "from keras.layers import LSTM\r\n",
        "from keras.layers import Embedding"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnAi-b4pQwOn"
      },
      "source": [
        "# 1 加载数据"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcMu5ks6Pq2F"
      },
      "source": [
        "data = \"\"\" Jack and Jill went up the hill\\n\r\n",
        "To fetch a pail of water\\n\r\n",
        "Jack fell down and broke his crown\\n\r\n",
        "And Jill came tumbling after\\n \"\"\""
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvvUxLWkTwCM"
      },
      "source": [
        "## 使用keras的Tokenizer将文本转换为整数序列。\r\n",
        "\r\n",
        "Tokenizer的原理是：按照词频对训练文本中的词降序排序，然后使用序号对词进行编码。例如：排名第一的词对应的整数值是1，排名第二的词对应的整数值是2。\r\n",
        "\r\n",
        "fit_on_texts后有两个有用的输出：  \r\n",
        "word_counts：词频统计结果。例如：('jack', 2), ('and', 3), ('jill', 2), ('went', 1), ('up', 1)。  \r\n",
        "word_index：词和index的对应关系，也就是词和整数的对应的关系。先按照词频对训练文本中的词降序排序，然后按照顺序给词分配索引（从1开始，0不会分配任何词）。例如：'and': 1, 'jack': 2, 'jill': 3, 'went': 4, 'up': 5。  \r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONsF_RGQRFfK",
        "outputId": "9d16d8ad-d52e-4e77-a242-b6a1149a51d3"
      },
      "source": [
        "# prepare the tokenizer on the source text\r\n",
        "# 创建分词器 Tokenizer 对象，添加结束符\r\n",
        "tokenizer = Tokenizer(oov_token='<END>')\r\n",
        "\r\n",
        "# 使用 data 训练分词器\r\n",
        "tokenizer.fit_on_texts([data])\r\n",
        "\r\n",
        "print(tokenizer.word_counts)\r\n",
        "print(tokenizer.word_docs)\r\n",
        "print(tokenizer.word_index) \r\n",
        "print(tokenizer.document_count)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OrderedDict([('jack', 2), ('and', 3), ('jill', 2), ('went', 1), ('up', 1), ('the', 1), ('hill', 1), ('to', 1), ('fetch', 1), ('a', 1), ('pail', 1), ('of', 1), ('water', 1), ('fell', 1), ('down', 1), ('broke', 1), ('his', 1), ('crown', 1), ('came', 1), ('tumbling', 1), ('after', 1)])\n",
            "defaultdict(<class 'int'>, {'pail': 1, 'broke': 1, 'fell': 1, 'his': 1, 'crown': 1, 'a': 1, 'after': 1, 'came': 1, 'fetch': 1, 'to': 1, 'of': 1, 'tumbling': 1, 'and': 1, 'jill': 1, 'went': 1, 'down': 1, 'hill': 1, 'jack': 1, 'water': 1, 'up': 1, 'the': 1})\n",
            "{'<END>': 1, 'and': 2, 'jack': 3, 'jill': 4, 'went': 5, 'up': 6, 'the': 7, 'hill': 8, 'to': 9, 'fetch': 10, 'a': 11, 'pail': 12, 'of': 13, 'water': 14, 'fell': 15, 'down': 16, 'broke': 17, 'his': 18, 'crown': 19, 'came': 20, 'tumbling': 21, 'after': 22}\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiok1_uGWL9D"
      },
      "source": [
        "## 确定词汇量"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELcZj5l0qyzt"
      },
      "source": [
        "作用：\r\n",
        "1. 后续定义模型时，词嵌入层需要用到。\r\n",
        "2. 使用one-hot编码编码输出的词。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-dgczbIUY21",
        "outputId": "68eb91ea-6f1b-4f65-ec07-38573b42a4d7"
      },
      "source": [
        "# 确定词汇量（原始文本中词去重后的数量）\r\n",
        "vocab_size = len(tokenizer.word_index) + 1\r\n",
        "print('Vocabulary Size: %d' % vocab_size)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary Size: 23\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHtgLbSsWfFO"
      },
      "source": [
        "## 基于行创建（整数）序列\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKVLEdHztW5Q"
      },
      "source": [
        "按照行创建序列，将原序列[2, 1, 3, 4, 5, 6, 7]转换成如下形式：  \r\n",
        "[2],   \r\n",
        "[2, 1],   \r\n",
        "[2, 1, 3],   \r\n",
        "[2, 1, 3, 4],   \r\n",
        "[2, 1, 3, 4, 5],   \r\n",
        "[2, 1, 3, 4, 5, 6],   \r\n",
        "[2, 1, 3, 4, 5, 6, 7]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ObEBOUYOWrnD",
        "outputId": "0fd4da10-9bbc-4eef-be2a-66ffbdb828f3"
      },
      "source": [
        "sequences = list()\r\n",
        "for line in data.split('\\n'):\r\n",
        "  if len(line.strip()) > 0:\r\n",
        "    line += ' <END>'\r\n",
        "    # 将文本转换为（整数）序列\r\n",
        "    encoded = tokenizer.texts_to_sequences([line])[0]  # tokenizer.texts_to_sequences([line])的结果[[2, 1, 3, 4, 5, 6, 7]]\r\n",
        "    print(encoded)\r\n",
        "    for i in range(1, len(encoded)+1):\r\n",
        "      sequence = encoded[:i]\r\n",
        "      sequences.append(sequence)\r\n",
        "print('Total Sequences: %d' % len(sequences))\r\n",
        "print(sequences[:10])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[3, 2, 4, 5, 6, 7, 8, 1]\n",
            "[9, 10, 11, 12, 13, 14, 1]\n",
            "[3, 15, 16, 2, 17, 18, 19, 1]\n",
            "[2, 4, 20, 21, 22, 1]\n",
            "Total Sequences: 29\n",
            "[[3], [3, 2], [3, 2, 4], [3, 2, 4, 5], [3, 2, 4, 5, 6], [3, 2, 4, 5, 6, 7], [3, 2, 4, 5, 6, 7, 8], [3, 2, 4, 5, 6, 7, 8, 1], [9], [9, 10]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgMlKItWZTZg"
      },
      "source": [
        "## 填充序列"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qciTCYZqu1Mf"
      },
      "source": [
        "由于新序列的长度不一致，因此需要对序列进行填充使得所有序列长度相同。\r\n",
        "\r\n",
        "使用keras的pad_sequences来进行填充。\r\n",
        "\r\n",
        "填充结果：  \r\n",
        "[ 0  0  0  0  0  0  2]  \r\n",
        " [ 0  0  0  0  0  2  1]  \r\n",
        " [ 0  0  0  0  2  1  3]  \r\n",
        " [ 0  0  0  2  1  3  4]  \r\n",
        " [ 0  0  2  1  3  4  5]  \r\n",
        " [ 0  2  1  3  4  5  6]  \r\n",
        " [ 2  1  3  4  5  6  7]  \r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIEP6V7vZaCp",
        "outputId": "c4ea696c-ffe4-4936-ffe3-1841462aa099"
      },
      "source": [
        "# pad input sequences\r\n",
        "max_length = max([len(seq) for seq in sequences])\r\n",
        "sequences = pad_sequences(sequences, maxlen=max_length, padding='pre') # 左边填充0\r\n",
        "print('Max Sequence Length: %d' % max_length)\r\n",
        "print(sequences[:10])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max Sequence Length: 8\n",
            "[[ 0  0  0  0  0  0  0  3]\n",
            " [ 0  0  0  0  0  0  3  2]\n",
            " [ 0  0  0  0  0  3  2  4]\n",
            " [ 0  0  0  0  3  2  4  5]\n",
            " [ 0  0  0  3  2  4  5  6]\n",
            " [ 0  0  3  2  4  5  6  7]\n",
            " [ 0  3  2  4  5  6  7  8]\n",
            " [ 3  2  4  5  6  7  8  1]\n",
            " [ 0  0  0  0  0  0  0  9]\n",
            " [ 0  0  0  0  0  0  9 10]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEUFFATQajho"
      },
      "source": [
        "# 创建输入输出"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHfSHPMsvwJn"
      },
      "source": [
        "从序列中数据分割出输入和输出数据。\r\n",
        "\r\n",
        "\r\n",
        "```\r\n",
        "    X       y  \r\n",
        "[0 0 0 0 0 0]  2  \r\n",
        "[0 0 0 0 0 2]  1  \r\n",
        "[0 0 0 0 2 1]  3  \r\n",
        "[0 0 0 2 1 3]  4  \r\n",
        "[0 0 2 1 3 4]  5 \r\n",
        "```\r\n",
        "\r\n",
        "\r\n",
        " \r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wdff6Dwraog0",
        "outputId": "a645bcf0-f169-4395-da42-12fc80634318"
      },
      "source": [
        "sequences = np.array(sequences)\r\n",
        "X, y = sequences[:, :-1], sequences[:, -1]\r\n",
        "print(X[:5])\r\n",
        "print(y[:5])\r\n",
        "y = to_categorical(y, num_classes=vocab_size) # 对输出进行one-hot编码"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 3]\n",
            " [0 0 0 0 0 3 2]\n",
            " [0 0 0 0 3 2 4]\n",
            " [0 0 0 3 2 4 5]]\n",
            "[3 2 4 5 6]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vMFxzgobIwH"
      },
      "source": [
        "# 定义模型"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8VJ2qq2cq3c"
      },
      "source": [
        "Embedding：  \r\n",
        "输入shape：形如（samples，sequence_length）的2D张量  \r\n",
        "输出shape：形如(samples, sequence_length, output_dim)的3D张量  \r\n",
        "嵌入层将正整数（下标）转换为具有固定大小的向量，如[[4],[20]]->[[0.25,0.1],[0.6,-0.2]]。[Embedding详解](https://blog.csdn.net/jiangpeng59/article/details/77533309) \r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "LSTM：  \r\n",
        "输入shape：(samples, time_steps, input_dim)  \r\n",
        "输出shape：(samples, output_dim)\r\n",
        "\r\n",
        "*samples表示样本数量*\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ywg8UO7zbWWz"
      },
      "source": [
        "def define_model(vocab_size, max_length):\r\n",
        "  model = Sequential()\r\n",
        "  model.add(Embedding(input_dim=vocab_size, output_dim=10, input_length=max_length-1))\r\n",
        "  model.add(LSTM(50))\r\n",
        "  model.add(Dense(vocab_size, activation='softmax'))\r\n",
        "  # compile network\r\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\r\n",
        "  # summarize defined model 输出模型各层的参数状况\r\n",
        "  model.summary()\r\n",
        "  # plot_model(model, to_file='model.png', show_shapes=True)\r\n",
        "  return model"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYKfHyMHbM4F",
        "outputId": "073c66ef-e156-4820-a09d-a85be710e0a6"
      },
      "source": [
        "# define model\r\n",
        "model = define_model(vocab_size, max_length)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 7, 10)             230       \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 50)                12200     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 23)                1173      \n",
            "=================================================================\n",
            "Total params: 13,603\n",
            "Trainable params: 13,603\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0yC7OMmlI_d"
      },
      "source": [
        "# 训练模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "425k7WvKlLpg",
        "outputId": "51c44675-06da-4f56-bc98-dffb1356b06a"
      },
      "source": [
        "# fit network 训练模型\r\n",
        "model.fit(X, y, epochs=500, verbose=0)\r\n",
        "# summarize performance of the model 总结模型性能\r\n",
        "scores = model.evaluate(X, y, verbose=0)\r\n",
        "print(\"Model Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model Accuracy: 89.66%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPwCD5SVlRgR"
      },
      "source": [
        "# 使用模型进行预测"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYOBBmbMlvvi"
      },
      "source": [
        "# generate a sequence from a language model\r\n",
        "# 给定一个词，生成其后的词，形成句子\r\n",
        "def generate_seq(model, tokenizer, max_length, seed_text, max_words):\r\n",
        "  in_text = seed_text\r\n",
        "  out_word = ''\r\n",
        "  num_words = 0\r\n",
        "  # generate a fixed number of words\r\n",
        "  while True:\r\n",
        "    if out_word == '<END>' or num_words >= max_words:\r\n",
        "      break\r\n",
        "    # encode the text as integer\r\n",
        "    encoded = tokenizer.texts_to_sequences([in_text])[0]\r\n",
        "    # pre-pad sequences to a fixed length\r\n",
        "    encoded = pad_sequences([encoded], maxlen=max_length, padding='pre')\r\n",
        "    # predict probabilities for each word\r\n",
        "    # yhat = model.predict_classes(encoded, verbose=0)\r\n",
        "    yhat = np.argmax(model.predict(encoded))\r\n",
        "    # map predicted word index to word\r\n",
        "    for word, index in tokenizer.word_index.items():\r\n",
        "      if index == yhat:\r\n",
        "        out_word = word\r\n",
        "        break\r\n",
        "    # append to input\r\n",
        "    in_text += ' ' + out_word\r\n",
        "    num_words += 1\r\n",
        "  return in_text"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRrLySdUlUT1",
        "outputId": "7d57454b-9f32-448b-afd1-e0fa8c9e0da9"
      },
      "source": [
        "# evaluate model\r\n",
        "# 输入空，预测其后的词，形成句子，句子最大长度为10\r\n",
        "print(generate_seq(model, tokenizer, max_length-1, '', 10)) \r\n",
        "# 输入Jill，预测其后的词，形成句子，句子最大长度为4\r\n",
        "print(generate_seq(model, tokenizer, max_length-1, 'Jill', 4))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " jack and jill went up the hill <END>\n",
            "Jill jack came tumbling after\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}