{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "genpass from github.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOMrHXcYYfLJtWr3V+xiLXX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YapingWu/GoogleColab/blob/main/genpass/genpass_from_github.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XG2uyd_S4tEf"
      },
      "source": [
        "# github代码复制到google colab\n",
        "\n",
        "参考资料：\n",
        "1. https://techsupportallbugs.wordpress.com/2018/06/05/using-git-with-colab-via-ssh/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKNtwhnL4zIX"
      },
      "source": [
        "## 配置SSH\n",
        "1. 上传压缩后的密钥对文件和配置文件\n",
        "1. 将密钥对文件和配置文件解压到/root/.ssh文件夹中\n",
        "2. 将私钥加载到本地ssh-agent中\n",
        "3. 设置git账户"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDBqGHhh9TV7",
        "outputId": "58c3711d-86ad-4172-e3f3-9d68f2ee2ad0"
      },
      "source": [
        "!rm -rf ~/.ssh\n",
        "!unzip '/content/ssh-colab.zip' -d ~/.ssh\n",
        "!chmod 700 ~/.ssh\n",
        "\n",
        "# add the ssh server as a hnown host\n",
        "!touch ~/.ssh/known_hosts\n",
        "!ssh-keyscan github.com >> ~/.ssh/known_hosts\n",
        "!chmod 644 ~/.ssh/known_hosts"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/ssh-colab.zip\n",
            "  inflating: /root/.ssh/config       \n",
            "  inflating: /root/.ssh/id_rsa_colab  \n",
            "  inflating: /root/.ssh/id_rsa_colab.pub  \n",
            "# github.com:22 SSH-2.0-babeld-383743ad\n",
            "# github.com:22 SSH-2.0-babeld-c2015ddc\n",
            "# github.com:22 SSH-2.0-babeld-383743ad\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMTGwhmh_6Xj",
        "outputId": "a64c70ea-df4f-4057-e436-90ad9a8c3d53"
      },
      "source": [
        "!ssh-agent /bin/bash \n",
        "\n",
        "# 以下命令在ssh-agent启动的shell中执行\n",
        "# chmod 600 ~/.ssh/id_rsa_colab  # 私钥需要设置仅自己可以访问，才能添加到代理\n",
        "# ssh-add ~/.ssh/id_rsa_colab\n",
        "# ssh-add -l"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bash: cannot set terminal process group (57): Inappropriate ioctl for device\n",
            "bash: no job control in this shell\n",
            "\u001b[01;34m/content/drive/My Drive/gen_pass\u001b[00m# chmod 600 ~/.ssh/id_rsa_colab\n",
            "\u001b[01;34m/content/drive/My Drive/gen_pass\u001b[00m# ssh-add ~/.ssh/id_rsa_colab\n",
            "Identity added: /root/.ssh/id_rsa_colab (/root/.ssh/id_rsa_colab)\n",
            "\u001b[01;34m/content/drive/My Drive/gen_pass\u001b[00m# EXIT\n",
            "bash: EXIT: command not found\n",
            "\u001b[01;34m/content/drive/My Drive/gen_pass\u001b[00m# exit\n",
            "exit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niqZxsQrDAz9"
      },
      "source": [
        "!git config --global user.name 'colab'\n",
        "!git config --global user.email 'vyapings@163.com'"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1redRBlVDRVu"
      },
      "source": [
        "## clone私有库\n",
        "1. 安装google云盘\n",
        "2. 将工作目录更改为云端硬盘内的文件夹\n",
        "3. 运行git clone。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgmO9CHC-9M5",
        "outputId": "e23ab9e3-9dc8-452a-ba01-de413619f130"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('./drive')\n",
        "\n",
        "import os\n",
        "os.chdir('/content/drive/MyDrive')\n",
        "\n",
        "!pwd\n",
        "!ls"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at ./drive\n",
            "/content/drive/MyDrive\n",
            "'Anyfile Notepad Files'  'Colab Notebooks'   gen_pass\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTxxiKQvA-5p",
        "outputId": "f7545d42-de06-408d-ab4c-9636a9f00617"
      },
      "source": [
        "# !rm -rf gen_pass\n",
        "# !git clone git@github.com:YapingWu/gen_pass.git\n",
        "\n",
        "import os\n",
        "os.chdir('/content/drive/MyDrive/gen_pass')\n",
        "# !git stash\n",
        "!git pull origin master"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "remote: Enumerating objects: 11, done.\u001b[K\n",
            "remote: Counting objects:   9% (1/11)\u001b[K\rremote: Counting objects:  18% (2/11)\u001b[K\rremote: Counting objects:  27% (3/11)\u001b[K\rremote: Counting objects:  36% (4/11)\u001b[K\rremote: Counting objects:  45% (5/11)\u001b[K\rremote: Counting objects:  54% (6/11)\u001b[K\rremote: Counting objects:  63% (7/11)\u001b[K\rremote: Counting objects:  72% (8/11)\u001b[K\rremote: Counting objects:  81% (9/11)\u001b[K\rremote: Counting objects:  90% (10/11)\u001b[K\rremote: Counting objects: 100% (11/11)\u001b[K\rremote: Counting objects: 100% (11/11), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1/1)\u001b[K\rremote: Compressing objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 6 (delta 5), reused 6 (delta 5), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (6/6), done.\n",
            "From github.com:YapingWu/gen_pass\n",
            " * branch            master     -> FETCH_HEAD\n",
            "   99d5e3e..6dceed7  master     -> origin/master\n",
            "Updating 99d5e3e..6dceed7\n",
            "Fast-forward\n",
            " main.py                     |  4 \u001b[32m+++\u001b[m\u001b[31m-\u001b[m\n",
            " src/utils/evaluate_model.py | 46 \u001b[32m++++++++++++++++++++++++++\u001b[m\u001b[31m-------------------\u001b[m\n",
            " 2 files changed, 30 insertions(+), 20 deletions(-)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WecgaSNAD6uE"
      },
      "source": [
        "# 运行genpass项目"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3U3OWhSAEU3V"
      },
      "source": [
        "上传并解压原始密码数据集"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXGvSwK9D4pa",
        "outputId": "bdacdb01-aa53-4ec6-8d17-ced6cc64509a"
      },
      "source": [
        "!unzip '/content/dataset.zip' -d '/content/drive/MyDrive/gen_pass/dataset'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/dataset.zip\n",
            "  inflating: /content/drive/MyDrive/gen_pass/dataset/phpbb.txt  \n",
            "  inflating: /content/drive/MyDrive/gen_pass/dataset/rockyou.txt  \n",
            "  inflating: /content/drive/MyDrive/gen_pass/dataset/myspace.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSeeKLLKEcMU",
        "outputId": "f181a948-9430-40ab-c9e1-f385ca07254e"
      },
      "source": [
        "import os\n",
        "print(os.getcwd())\n",
        "os.chdir('/content/drive/MyDrive/gen_pass')\n",
        "print(os.getcwd())"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "/content/drive/MyDrive/gen_pass\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vb2ln895Eyee"
      },
      "source": [
        "## 数据分析"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wz4USzDbFAYg",
        "outputId": "d26bcd10-77b0-47b2-e138-e23366fd286e"
      },
      "source": [
        "!python main.py \\\n",
        "  --stats-only \\\n",
        "  --infile dataset/phpbb.txt dataset/myspace.txt"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-03-25 04:40:35.212460: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[1;37m2021-03-25 04:40:38 [INFO] \n",
            "##########################################################################################################\n",
            "# GENPass\n",
            "# 1 PL模型预测。预测密码中的下一个单元（unit）。\n",
            "# 2 权重选择。按照权重选择从3个PL模型的结果中选择权重最高的unit，并根据wordlist随机选择一个密码进行替换。\n",
            "# 3 分类器。使用CNN模型预测上一步生成的密码属于3个数据集的概率。\n",
            "# 4 判定器。选择出在3个数据集概率相差不大的密码作为结果输出。\n",
            "#\n",
            "##########################################################################################################\n",
            "\u001b[0m\n",
            "\u001b[1;37m2021-03-25 04:40:39 [INFO] Start...\u001b[0m\n",
            "\u001b[1;37m2021-03-25 04:40:39 [INFO] dataset/phpbb.txt数据集中的密码数量：184379\u001b[0m\n",
            "\u001b[1;37m2021-03-25 04:40:39 [INFO] 密码长度不在[4, 20]区间的密码个数：1013，占总密码数量的百分比：0.55%\u001b[0m\n",
            "\u001b[1;37m2021-03-25 04:40:39 [INFO] dataset/myspace.txt数据集中的密码数量：37144\u001b[0m\n",
            "\u001b[1;37m2021-03-25 04:40:39 [INFO] 密码长度不在[4, 20]区间的密码个数：259，占总密码数量的百分比：0.70%\u001b[0m\n",
            "\u001b[1;37m2021-03-25 04:40:39 [INFO] 分析结果图保存到文件：result/figure/password.png\u001b[0m\n",
            "\u001b[1;37m2021-03-25 04:40:40 [INFO] End...\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIjqmF5_tyal"
      },
      "source": [
        "## 数据预处理"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYmyHJt2txki",
        "outputId": "e260c850-bb8d-491c-96d1-7e6ed8b99266"
      },
      "source": [
        "!python main.py \\\n",
        "  --pre-processing-only \\\n",
        "  --infile dataset/phpbb.txt dataset/myspace.txt"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-03-25 13:16:17.712334: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[1;37m2021-03-25 13:16:19 [INFO] \n",
            "##########################################################################################################\n",
            "# GENPass\n",
            "# 1 PL模型预测。预测密码中的下一个单元（unit）。\n",
            "# 2 权重选择。按照权重选择从3个PL模型的结果中选择权重最高的unit，并根据wordlist随机选择一个密码进行替换。\n",
            "# 3 分类器。使用CNN模型预测上一步生成的密码属于3个数据集的概率。\n",
            "# 4 判定器。选择出在3个数据集概率相差不大的密码作为结果输出。\n",
            "#\n",
            "##########################################################################################################\n",
            "\u001b[0m\n",
            "\u001b[1;37m2021-03-25 13:16:19 [INFO] Start...\u001b[0m\n",
            "\u001b[1;37m2021-03-25 13:16:19 [INFO] 原始密码集划分为测试集和训练集\u001b[0m\n",
            "\u001b[1;37m2021-03-25 13:16:20 [INFO] dataset/phpbb.txt：train shape：(147503, 1), test shape：(36876, 1)\u001b[0m\n",
            "\u001b[1;37m2021-03-25 13:16:21 [INFO] dataset/myspace.txt：train shape：(29715, 1), test shape：(7429, 1)\u001b[0m\n",
            "\u001b[1;37m2021-03-25 13:16:21 [INFO] 开始预处理\u001b[0m\n",
            "\u001b[1;37m2021-03-25 13:16:21 [INFO] 待处理的文件名称：dataset/phpbb.txt\u001b[0m\n",
            "\u001b[1;37m2021-03-25 13:16:21 [INFO] PCFG编码\u001b[0m\n",
            "\u001b[1;37m2021-03-25 13:16:22 [INFO] 去重后的编码序列个数：2873， 保存到文件：result/preprocessed/wordlist/phpbb.txt\u001b[0m\n",
            "\u001b[1;37m2021-03-25 13:16:22 [INFO] 生成两个概率表并保存到文件\u001b[0m\n",
            "\u001b[1;37m2021-03-25 13:16:22 [INFO] 每个unit出现的概率保存到文件：result/preprocessed/unit_freq/phpbb.txt\u001b[0m\n",
            "\u001b[1;37m2021-03-25 13:16:24 [INFO] unit中每个密码出现的概率保存到文件：result/preprocessed/pwd_freq/phpbb.txt\u001b[0m\n",
            "\u001b[1;37m2021-03-25 13:16:24 [INFO] 待处理的文件名称：dataset/myspace.txt\u001b[0m\n",
            "\u001b[1;37m2021-03-25 13:16:24 [INFO] PCFG编码\u001b[0m\n",
            "\u001b[1;37m2021-03-25 13:16:24 [INFO] 去重后的编码序列个数：1564， 保存到文件：result/preprocessed/wordlist/myspace.txt\u001b[0m\n",
            "\u001b[1;37m2021-03-25 13:16:24 [INFO] 生成两个概率表并保存到文件\u001b[0m\n",
            "\u001b[1;37m2021-03-25 13:16:24 [INFO] 每个unit出现的概率保存到文件：result/preprocessed/unit_freq/myspace.txt\u001b[0m\n",
            "\u001b[1;37m2021-03-25 13:16:24 [INFO] unit中每个密码出现的概率保存到文件：result/preprocessed/pwd_freq/myspace.txt\u001b[0m\n",
            "\u001b[1;37m2021-03-25 13:16:24 [INFO] 待处理的文件名称：result/preprocessed/phpbb_part.txt\u001b[0m\n",
            "\u001b[1;37m2021-03-25 13:16:24 [INFO] PCFG编码\u001b[0m\n",
            "\u001b[1;37m2021-03-25 13:16:25 [INFO] 去重后的编码序列个数：1959， 保存到文件：result/preprocessed/wordlist/phpbb_part.txt\u001b[0m\n",
            "\u001b[1;37m2021-03-25 13:16:25 [INFO] 生成两个概率表并保存到文件\u001b[0m\n",
            "\u001b[1;37m2021-03-25 13:16:25 [INFO] 每个unit出现的概率保存到文件：result/preprocessed/unit_freq/phpbb_part.txt\u001b[0m\n",
            "\u001b[1;37m2021-03-25 13:16:26 [INFO] unit中每个密码出现的概率保存到文件：result/preprocessed/pwd_freq/phpbb_part.txt\u001b[0m\n",
            "\u001b[1;37m2021-03-25 13:16:26 [INFO] 待处理的文件名称：result/preprocessed/myspace_part.txt\u001b[0m\n",
            "\u001b[1;37m2021-03-25 13:16:26 [INFO] PCFG编码\u001b[0m\n",
            "\u001b[1;37m2021-03-25 13:16:26 [INFO] 去重后的编码序列个数：1064， 保存到文件：result/preprocessed/wordlist/myspace_part.txt\u001b[0m\n",
            "\u001b[1;37m2021-03-25 13:16:26 [INFO] 生成两个概率表并保存到文件\u001b[0m\n",
            "\u001b[1;37m2021-03-25 13:16:26 [INFO] 每个unit出现的概率保存到文件：result/preprocessed/unit_freq/myspace_part.txt\u001b[0m\n",
            "\u001b[1;37m2021-03-25 13:16:27 [INFO] unit中每个密码出现的概率保存到文件：result/preprocessed/pwd_freq/myspace_part.txt\u001b[0m\n",
            "\u001b[1;37m2021-03-25 13:16:28 [INFO] End...\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXIMmvMduBct"
      },
      "source": [
        "## 训练word-level LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulFWdvZcEpRR"
      },
      "source": [
        "### 训练分词器"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qdT20rOuBBA",
        "outputId": "9c5d7ddd-d6e9-4eb1-e6df-d19c76ce14c1"
      },
      "source": [
        "!python main.py \\\n",
        "    --train --model tokenizer \\\n",
        "    --dnames myspace phpbb myspace_part phpbb_part"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-03-24 12:30:28.043468: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[1;37m2021-03-24 12:30:29 [INFO] \n",
            "##########################################################################################################\n",
            "# GENPass\n",
            "# 1 PL模型预测。预测密码中的下一个单元（unit）。\n",
            "# 2 权重选择。按照权重选择从3个PL模型的结果中选择权重最高的unit，并根据wordlist随机选择一个密码进行替换。\n",
            "# 3 分类器。使用CNN模型预测上一步生成的密码属于3个数据集的概率。\n",
            "# 4 判定器。选择出在3个数据集概率相差不大的密码作为结果输出。\n",
            "#\n",
            "##########################################################################################################\n",
            "\u001b[0m\n",
            "\u001b[1;37m2021-03-24 12:30:29 [INFO] Start...\u001b[0m\n",
            "\u001b[1;37m2021-03-24 12:30:29 [INFO] 加载编码后的密码数据，数据文件：result/preprocessed/wordlist/myspace.txt\u001b[0m\n",
            "\u001b[1;37m2021-03-24 12:30:29 [INFO] 开始训练tokenizer模型\u001b[0m\n",
            "\u001b[1;37m2021-03-24 12:30:29 [INFO] 将tokenizer模型保存到文件中：result/model/tokenizer/myspace.pkl\u001b[0m\n",
            "\u001b[1;37m2021-03-24 12:30:29 [INFO] 加载编码后的密码数据，数据文件：result/preprocessed/wordlist/phpbb.txt\u001b[0m\n",
            "\u001b[1;37m2021-03-24 12:30:29 [INFO] 开始训练tokenizer模型\u001b[0m\n",
            "\u001b[1;37m2021-03-24 12:30:29 [INFO] 将tokenizer模型保存到文件中：result/model/tokenizer/phpbb.pkl\u001b[0m\n",
            "\u001b[1;37m2021-03-24 12:30:29 [INFO] 加载编码后的密码数据，数据文件：result/preprocessed/wordlist/myspace_part.txt\u001b[0m\n",
            "\u001b[1;37m2021-03-24 12:30:29 [INFO] 开始训练tokenizer模型\u001b[0m\n",
            "\u001b[1;37m2021-03-24 12:30:29 [INFO] 将tokenizer模型保存到文件中：result/model/tokenizer/myspace_part.pkl\u001b[0m\n",
            "\u001b[1;37m2021-03-24 12:30:29 [INFO] 加载编码后的密码数据，数据文件：result/preprocessed/wordlist/phpbb_part.txt\u001b[0m\n",
            "\u001b[1;37m2021-03-24 12:30:29 [INFO] 开始训练tokenizer模型\u001b[0m\n",
            "\u001b[1;37m2021-03-24 12:30:30 [INFO] 将tokenizer模型保存到文件中：result/model/tokenizer/phpbb_part.pkl\u001b[0m\n",
            "\u001b[1;37m2021-03-24 12:30:30 [INFO] End...\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z38Jg6u7uvXt"
      },
      "source": [
        "### 使用pcfg编码结果训练LSTM模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilRlmgPIuupJ",
        "outputId": "01176ea5-a43e-4a48-f172-3bd10d8ddf37"
      },
      "source": [
        "!python main.py \\\n",
        "    -e pro \\\n",
        "    --train \\\n",
        "    --model lstm \\\n",
        "    --dnames myspace phpbb myspace_part phpbb_part"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-03-24 12:33:42.034927: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[1;37m2021-03-24 12:33:43 [INFO] \n",
            "##########################################################################################################\n",
            "# GENPass\n",
            "# 1 PL模型预测。预测密码中的下一个单元（unit）。\n",
            "# 2 权重选择。按照权重选择从3个PL模型的结果中选择权重最高的unit，并根据wordlist随机选择一个密码进行替换。\n",
            "# 3 分类器。使用CNN模型预测上一步生成的密码属于3个数据集的概率。\n",
            "# 4 判定器。选择出在3个数据集概率相差不大的密码作为结果输出。\n",
            "#\n",
            "##########################################################################################################\n",
            "\u001b[0m\n",
            "\u001b[1;37m2021-03-24 12:33:43 [INFO] Start...\u001b[0m\n",
            "\u001b[1;37m2021-03-24 12:33:43 [INFO] 开始加载编码后的密码数据：result/preprocessed/wordlist/myspace.txt\u001b[0m\n",
            "\u001b[1;37m2021-03-24 12:33:43 [INFO] 开始加载tokenizer模型：result/model/tokenizer/myspace.pkl\u001b[0m\n",
            "\u001b[1;37m2021-03-24 12:33:43 [INFO] 将编码后的密码转换为（整数）序列\u001b[0m\n",
            "\u001b[1;37m2021-03-24 12:33:43 [INFO] Total Sequences: 7586\u001b[0m\n",
            "\u001b[1;37m2021-03-24 12:33:43 [INFO] 创建LSTM模型的输入输出\u001b[0m\n",
            "\u001b[1;37m2021-03-24 12:33:43 [INFO] X Shape: (7586, 19), y Shape: (7586,)\u001b[0m\n",
            "\u001b[1;37m2021-03-24 12:33:43 [INFO] 划分训练集、验证集和测试集\u001b[0m\n",
            "\u001b[1;37m2021-03-24 12:33:43 [INFO] x_train Shape: (4551, 19), y_train Shape: (4551, 45)\u001b[0m\n",
            "\u001b[1;37m2021-03-24 12:33:43 [INFO] x_val Shape: (1517, 19), y_val Shape: (1517, 45)\u001b[0m\n",
            "\u001b[1;37m2021-03-24 12:33:43 [INFO] x_test Shape: (1518, 19), y_test Shape: (1518, 45)\u001b[0m\n",
            "\u001b[1;37m2021-03-24 12:33:43 [INFO] *************************************************创建LSTM模型*************************************************\u001b[0m\n",
            "2021-03-24 12:33:43.953205: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2021-03-24 12:33:43.954360: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
            "2021-03-24 12:33:43.972023: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2021-03-24 12:33:43.972093: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (f70d36e0f51d): /proc/driver/nvidia/version does not exist\n",
            "2021-03-24 12:33:43.972779: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 19, 10)            450       \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 19, 32)            5504      \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 19, 32)            8320      \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 32)                8320      \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 45)                1485      \n",
            "=================================================================\n",
            "Total params: 25,135\n",
            "Trainable params: 25,135\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\u001b[1;37m2021-03-24 12:33:44 [INFO] 训练日志文件：logs/lstm/myspace210324123344\u001b[0m\n",
            "2021-03-24 12:33:44.825144: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.\n",
            "2021-03-24 12:33:44.825201: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.\n",
            "2021-03-24 12:33:44.834745: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.\n",
            "\u001b[1;37m2021-03-24 12:33:44 [INFO] ************************************************开始训练LSTM模型************************************************\u001b[0m\n",
            "2021-03-24 12:33:44.879918: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
            "2021-03-24 12:33:44.880427: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2299995000 Hz\n",
            "Epoch 1/500\n",
            " 1/36 [..............................] - ETA: 2:38 - loss: 3.8069 - accuracy: 0.0000e+002021-03-24 12:33:49.605615: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.\n",
            "2021-03-24 12:33:49.605700: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.\n",
            " 2/36 [>.............................] - ETA: 7s - loss: 3.8062 - accuracy: 0.0195      2021-03-24 12:33:49.648219: I tensorflow/core/profiler/lib/profiler_session.cc:71] Profiler session collecting data.\n",
            "2021-03-24 12:33:49.687651: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.\n",
            "36/36 [==============================] - 8s 88ms/step - loss: 3.7062 - accuracy: 0.0892 - val_loss: 2.9319 - val_accuracy: 0.1154\n",
            "Epoch 2/500\n",
            "36/36 [==============================] - 1s 37ms/step - loss: 2.8585 - accuracy: 0.1459 - val_loss: 2.6001 - val_accuracy: 0.2327\n",
            "Epoch 3/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 2.6467 - accuracy: 0.1960 - val_loss: 2.5624 - val_accuracy: 0.2327\n",
            "Epoch 4/500\n",
            "36/36 [==============================] - 1s 37ms/step - loss: 2.6158 - accuracy: 0.2104 - val_loss: 2.5604 - val_accuracy: 0.2327\n",
            "Epoch 5/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 2.6181 - accuracy: 0.1982 - val_loss: 2.5507 - val_accuracy: 0.2327\n",
            "Epoch 6/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 2.6117 - accuracy: 0.2067 - val_loss: 2.5562 - val_accuracy: 0.2327\n",
            "Epoch 7/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 2.6025 - accuracy: 0.1952 - val_loss: 2.5480 - val_accuracy: 0.2327\n",
            "Epoch 8/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 2.6335 - accuracy: 0.2060 - val_loss: 2.5562 - val_accuracy: 0.2327\n",
            "Epoch 9/500\n",
            "36/36 [==============================] - 1s 37ms/step - loss: 2.5934 - accuracy: 0.2046 - val_loss: 2.5505 - val_accuracy: 0.2327\n",
            "Epoch 10/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 2.5935 - accuracy: 0.1996 - val_loss: 2.5486 - val_accuracy: 0.2327\n",
            "Epoch 11/500\n",
            "36/36 [==============================] - 1s 38ms/step - loss: 2.5823 - accuracy: 0.2170 - val_loss: 2.5533 - val_accuracy: 0.2327\n",
            "Epoch 12/500\n",
            "36/36 [==============================] - 1s 38ms/step - loss: 2.6086 - accuracy: 0.2001 - val_loss: 2.5488 - val_accuracy: 0.2327\n",
            "Epoch 13/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 2.5913 - accuracy: 0.2066 - val_loss: 2.5492 - val_accuracy: 0.2327\n",
            "Epoch 14/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 2.6034 - accuracy: 0.2071 - val_loss: 2.5540 - val_accuracy: 0.2327\n",
            "Epoch 15/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 2.6024 - accuracy: 0.1999 - val_loss: 2.5490 - val_accuracy: 0.2327\n",
            "Epoch 16/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 2.6096 - accuracy: 0.2025 - val_loss: 2.5531 - val_accuracy: 0.2327\n",
            "Epoch 17/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 2.5880 - accuracy: 0.2065 - val_loss: 2.5504 - val_accuracy: 0.2327\n",
            "Epoch 18/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 2.5972 - accuracy: 0.2057 - val_loss: 2.5502 - val_accuracy: 0.2327\n",
            "Epoch 19/500\n",
            "36/36 [==============================] - 1s 38ms/step - loss: 2.5923 - accuracy: 0.2013 - val_loss: 2.5558 - val_accuracy: 0.2327\n",
            "Epoch 20/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 2.5823 - accuracy: 0.2106 - val_loss: 2.5587 - val_accuracy: 0.2327\n",
            "Epoch 21/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 2.6028 - accuracy: 0.2009 - val_loss: 2.5527 - val_accuracy: 0.2327\n",
            "Epoch 22/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 2.5787 - accuracy: 0.2140 - val_loss: 2.5558 - val_accuracy: 0.2327\n",
            "Epoch 23/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 2.6023 - accuracy: 0.2069 - val_loss: 2.5564 - val_accuracy: 0.2327\n",
            "Epoch 24/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 2.6166 - accuracy: 0.1973 - val_loss: 2.5461 - val_accuracy: 0.2327\n",
            "Epoch 25/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 2.5979 - accuracy: 0.1966 - val_loss: 2.5335 - val_accuracy: 0.2327\n",
            "Epoch 26/500\n",
            "36/36 [==============================] - 1s 38ms/step - loss: 2.5691 - accuracy: 0.2009 - val_loss: 2.4693 - val_accuracy: 0.2327\n",
            "Epoch 27/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 2.5047 - accuracy: 0.2309 - val_loss: 2.4074 - val_accuracy: 0.2782\n",
            "Epoch 28/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 2.4620 - accuracy: 0.2596 - val_loss: 2.3614 - val_accuracy: 0.2795\n",
            "Epoch 29/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 2.4119 - accuracy: 0.2765 - val_loss: 2.3134 - val_accuracy: 0.3026\n",
            "Epoch 30/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 2.3767 - accuracy: 0.2736 - val_loss: 2.2936 - val_accuracy: 0.3078\n",
            "Epoch 31/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 2.3628 - accuracy: 0.2811 - val_loss: 2.2822 - val_accuracy: 0.3045\n",
            "Epoch 32/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 2.3517 - accuracy: 0.2867 - val_loss: 2.2739 - val_accuracy: 0.3045\n",
            "Epoch 33/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 2.3458 - accuracy: 0.2776 - val_loss: 2.2599 - val_accuracy: 0.3151\n",
            "Epoch 34/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 2.3798 - accuracy: 0.2706 - val_loss: 2.2682 - val_accuracy: 0.3256\n",
            "Epoch 35/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 2.3310 - accuracy: 0.2912 - val_loss: 2.2589 - val_accuracy: 0.3019\n",
            "Epoch 36/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 2.3277 - accuracy: 0.2886 - val_loss: 2.2533 - val_accuracy: 0.3296\n",
            "Epoch 37/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 2.3285 - accuracy: 0.3024 - val_loss: 2.2591 - val_accuracy: 0.3263\n",
            "Epoch 38/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 2.3232 - accuracy: 0.2926 - val_loss: 2.2422 - val_accuracy: 0.3283\n",
            "Epoch 39/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 2.3089 - accuracy: 0.3090 - val_loss: 2.2277 - val_accuracy: 0.3507\n",
            "Epoch 40/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 2.2638 - accuracy: 0.3254 - val_loss: 2.2020 - val_accuracy: 0.3553\n",
            "Epoch 41/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 2.2184 - accuracy: 0.3382 - val_loss: 2.1460 - val_accuracy: 0.3659\n",
            "Epoch 42/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 2.1418 - accuracy: 0.3430 - val_loss: 2.1132 - val_accuracy: 0.3626\n",
            "Epoch 43/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 2.1200 - accuracy: 0.3424 - val_loss: 2.0754 - val_accuracy: 0.3738\n",
            "Epoch 44/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 2.0974 - accuracy: 0.3448 - val_loss: 2.0651 - val_accuracy: 0.3751\n",
            "Epoch 45/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 2.0767 - accuracy: 0.3408 - val_loss: 2.0592 - val_accuracy: 0.3705\n",
            "Epoch 46/500\n",
            "36/36 [==============================] - 1s 38ms/step - loss: 2.0848 - accuracy: 0.3432 - val_loss: 2.0432 - val_accuracy: 0.3711\n",
            "Epoch 47/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 2.0829 - accuracy: 0.3368 - val_loss: 2.0327 - val_accuracy: 0.3751\n",
            "Epoch 48/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 2.0171 - accuracy: 0.3510 - val_loss: 2.0272 - val_accuracy: 0.3751\n",
            "Epoch 49/500\n",
            "36/36 [==============================] - 1s 38ms/step - loss: 2.0425 - accuracy: 0.3528 - val_loss: 2.0235 - val_accuracy: 0.3744\n",
            "Epoch 50/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 2.0262 - accuracy: 0.3541 - val_loss: 2.0241 - val_accuracy: 0.3738\n",
            "Epoch 51/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 2.0142 - accuracy: 0.3649 - val_loss: 2.0211 - val_accuracy: 0.3705\n",
            "Epoch 52/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 2.0406 - accuracy: 0.3499 - val_loss: 2.0139 - val_accuracy: 0.3718\n",
            "Epoch 53/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 2.0154 - accuracy: 0.3510 - val_loss: 2.0145 - val_accuracy: 0.3698\n",
            "Epoch 54/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 2.0769 - accuracy: 0.3390 - val_loss: 2.0086 - val_accuracy: 0.3771\n",
            "Epoch 55/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 2.0095 - accuracy: 0.3597 - val_loss: 2.0023 - val_accuracy: 0.3705\n",
            "Epoch 56/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 2.0387 - accuracy: 0.3479 - val_loss: 2.0039 - val_accuracy: 0.3777\n",
            "Epoch 57/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 2.0038 - accuracy: 0.3631 - val_loss: 2.0020 - val_accuracy: 0.3738\n",
            "Epoch 58/500\n",
            "36/36 [==============================] - 1s 41ms/step - loss: 1.9781 - accuracy: 0.3650 - val_loss: 1.9980 - val_accuracy: 0.3738\n",
            "Epoch 59/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 1.9973 - accuracy: 0.3602 - val_loss: 1.9978 - val_accuracy: 0.3751\n",
            "Epoch 60/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 1.9818 - accuracy: 0.3628 - val_loss: 2.0023 - val_accuracy: 0.3751\n",
            "Epoch 61/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 1.9890 - accuracy: 0.3602 - val_loss: 2.0063 - val_accuracy: 0.3771\n",
            "Epoch 62/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 2.0011 - accuracy: 0.3668 - val_loss: 1.9975 - val_accuracy: 0.3757\n",
            "Epoch 63/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 2.0130 - accuracy: 0.3615 - val_loss: 1.9949 - val_accuracy: 0.3837\n",
            "Epoch 64/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 2.0207 - accuracy: 0.3512 - val_loss: 2.0017 - val_accuracy: 0.3784\n",
            "Epoch 65/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 2.0000 - accuracy: 0.3664 - val_loss: 1.9926 - val_accuracy: 0.3771\n",
            "Epoch 66/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 1.9985 - accuracy: 0.3542 - val_loss: 1.9975 - val_accuracy: 0.3784\n",
            "Epoch 67/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 1.9702 - accuracy: 0.3676 - val_loss: 1.9962 - val_accuracy: 0.3718\n",
            "Epoch 68/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 1.9528 - accuracy: 0.3626 - val_loss: 1.9976 - val_accuracy: 0.3771\n",
            "Epoch 69/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 1.9792 - accuracy: 0.3519 - val_loss: 1.9933 - val_accuracy: 0.3790\n",
            "Epoch 70/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 1.9712 - accuracy: 0.3664 - val_loss: 1.9903 - val_accuracy: 0.3784\n",
            "Epoch 71/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 1.9976 - accuracy: 0.3556 - val_loss: 1.9900 - val_accuracy: 0.3764\n",
            "Epoch 72/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 1.9806 - accuracy: 0.3720 - val_loss: 1.9882 - val_accuracy: 0.3718\n",
            "Epoch 73/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 1.9390 - accuracy: 0.3732 - val_loss: 1.9874 - val_accuracy: 0.3784\n",
            "Epoch 74/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 1.9371 - accuracy: 0.3826 - val_loss: 1.9903 - val_accuracy: 0.3757\n",
            "Epoch 75/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 1.9865 - accuracy: 0.3675 - val_loss: 1.9912 - val_accuracy: 0.3751\n",
            "Epoch 76/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 1.9641 - accuracy: 0.3662 - val_loss: 1.9881 - val_accuracy: 0.3784\n",
            "Epoch 77/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 1.9343 - accuracy: 0.3750 - val_loss: 1.9824 - val_accuracy: 0.3790\n",
            "Epoch 78/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 1.9629 - accuracy: 0.3666 - val_loss: 1.9905 - val_accuracy: 0.3731\n",
            "Epoch 79/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 1.9703 - accuracy: 0.3619 - val_loss: 1.9903 - val_accuracy: 0.3784\n",
            "Epoch 80/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 1.9804 - accuracy: 0.3700 - val_loss: 1.9829 - val_accuracy: 0.3764\n",
            "Epoch 81/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 1.9847 - accuracy: 0.3654 - val_loss: 1.9879 - val_accuracy: 0.3757\n",
            "Epoch 82/500\n",
            "36/36 [==============================] - 2s 42ms/step - loss: 1.9716 - accuracy: 0.3603 - val_loss: 1.9890 - val_accuracy: 0.3777\n",
            "Epoch 83/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 1.9969 - accuracy: 0.3643 - val_loss: 2.0006 - val_accuracy: 0.3810\n",
            "Epoch 84/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 1.9920 - accuracy: 0.3655 - val_loss: 1.9839 - val_accuracy: 0.3810\n",
            "Epoch 85/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 1.9622 - accuracy: 0.3717 - val_loss: 1.9867 - val_accuracy: 0.3738\n",
            "Epoch 86/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 1.9425 - accuracy: 0.3798 - val_loss: 1.9847 - val_accuracy: 0.3757\n",
            "Epoch 87/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 1.9404 - accuracy: 0.3740 - val_loss: 1.9814 - val_accuracy: 0.3797\n",
            "Epoch 88/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 1.9911 - accuracy: 0.3617 - val_loss: 1.9890 - val_accuracy: 0.3823\n",
            "Epoch 89/500\n",
            "36/36 [==============================] - 1s 41ms/step - loss: 1.9497 - accuracy: 0.3789 - val_loss: 1.9859 - val_accuracy: 0.3837\n",
            "Epoch 90/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 1.9529 - accuracy: 0.3733 - val_loss: 1.9891 - val_accuracy: 0.3810\n",
            "Epoch 91/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 1.9705 - accuracy: 0.3619 - val_loss: 1.9858 - val_accuracy: 0.3771\n",
            "Epoch 92/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 1.9497 - accuracy: 0.3724 - val_loss: 1.9843 - val_accuracy: 0.3843\n",
            "Epoch 93/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 1.9471 - accuracy: 0.3702 - val_loss: 1.9914 - val_accuracy: 0.3817\n",
            "Epoch 94/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 1.9782 - accuracy: 0.3597 - val_loss: 1.9927 - val_accuracy: 0.3810\n",
            "Epoch 95/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 1.9609 - accuracy: 0.3680 - val_loss: 1.9939 - val_accuracy: 0.3804\n",
            "Epoch 96/500\n",
            "36/36 [==============================] - 1s 41ms/step - loss: 1.9524 - accuracy: 0.3775 - val_loss: 2.0006 - val_accuracy: 0.3764\n",
            "Epoch 97/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 1.9466 - accuracy: 0.3775 - val_loss: 1.9913 - val_accuracy: 0.3850\n",
            "Epoch 98/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 1.9243 - accuracy: 0.3841 - val_loss: 1.9949 - val_accuracy: 0.3797\n",
            "Epoch 99/500\n",
            "36/36 [==============================] - 2s 42ms/step - loss: 1.9397 - accuracy: 0.3847 - val_loss: 1.9888 - val_accuracy: 0.3850\n",
            "Epoch 100/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 1.9457 - accuracy: 0.3671 - val_loss: 1.9879 - val_accuracy: 0.3790\n",
            "Epoch 101/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 1.9365 - accuracy: 0.3727 - val_loss: 1.9926 - val_accuracy: 0.3817\n",
            "Epoch 102/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 1.9383 - accuracy: 0.3776 - val_loss: 1.9901 - val_accuracy: 0.3830\n",
            "Epoch 103/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 1.9371 - accuracy: 0.3717 - val_loss: 1.9903 - val_accuracy: 0.3863\n",
            "Epoch 104/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 1.9065 - accuracy: 0.3938 - val_loss: 1.9961 - val_accuracy: 0.3843\n",
            "Epoch 105/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 1.8999 - accuracy: 0.3941 - val_loss: 1.9968 - val_accuracy: 0.3751\n",
            "Epoch 106/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 1.9341 - accuracy: 0.3849 - val_loss: 1.9900 - val_accuracy: 0.3909\n",
            "Epoch 107/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 1.9430 - accuracy: 0.3796 - val_loss: 1.9934 - val_accuracy: 0.3909\n",
            "Epoch 108/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 1.9342 - accuracy: 0.3797 - val_loss: 1.9910 - val_accuracy: 0.3929\n",
            "Epoch 109/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 1.9117 - accuracy: 0.3904 - val_loss: 1.9873 - val_accuracy: 0.3896\n",
            "Epoch 110/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 1.9174 - accuracy: 0.3912 - val_loss: 1.9872 - val_accuracy: 0.3869\n",
            "Epoch 111/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 1.9436 - accuracy: 0.3788 - val_loss: 1.9830 - val_accuracy: 0.3916\n",
            "Epoch 112/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 1.8910 - accuracy: 0.3936 - val_loss: 1.9847 - val_accuracy: 0.3929\n",
            "Epoch 113/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 1.9268 - accuracy: 0.3858 - val_loss: 1.9893 - val_accuracy: 0.3935\n",
            "Epoch 114/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 1.9309 - accuracy: 0.3742 - val_loss: 1.9862 - val_accuracy: 0.3922\n",
            "Epoch 115/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 1.8805 - accuracy: 0.3961 - val_loss: 1.9857 - val_accuracy: 0.3843\n",
            "Epoch 116/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 1.9164 - accuracy: 0.3875 - val_loss: 1.9873 - val_accuracy: 0.3856\n",
            "Epoch 117/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 1.9168 - accuracy: 0.3935 - val_loss: 1.9922 - val_accuracy: 0.3869\n",
            "Epoch 118/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 1.8745 - accuracy: 0.3982 - val_loss: 1.9823 - val_accuracy: 0.3949\n",
            "Epoch 119/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 1.8943 - accuracy: 0.3970 - val_loss: 1.9875 - val_accuracy: 0.3869\n",
            "Epoch 120/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 1.8764 - accuracy: 0.4094 - val_loss: 1.9778 - val_accuracy: 0.4034\n",
            "Epoch 121/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 1.9144 - accuracy: 0.3989 - val_loss: 1.9806 - val_accuracy: 0.3982\n",
            "Epoch 122/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 1.8980 - accuracy: 0.3985 - val_loss: 1.9769 - val_accuracy: 0.3955\n",
            "Epoch 123/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 1.8892 - accuracy: 0.4028 - val_loss: 1.9821 - val_accuracy: 0.3955\n",
            "Epoch 124/500\n",
            "36/36 [==============================] - 1s 38ms/step - loss: 1.8940 - accuracy: 0.3991 - val_loss: 1.9818 - val_accuracy: 0.4008\n",
            "Epoch 125/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 1.9033 - accuracy: 0.3991 - val_loss: 1.9859 - val_accuracy: 0.3935\n",
            "Epoch 126/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 1.8820 - accuracy: 0.3879 - val_loss: 1.9962 - val_accuracy: 0.3843\n",
            "Epoch 127/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 1.8949 - accuracy: 0.3897 - val_loss: 1.9784 - val_accuracy: 0.3942\n",
            "Epoch 128/500\n",
            "36/36 [==============================] - 1s 41ms/step - loss: 1.9013 - accuracy: 0.4010 - val_loss: 1.9864 - val_accuracy: 0.3909\n",
            "Epoch 129/500\n",
            "36/36 [==============================] - 1s 41ms/step - loss: 1.9043 - accuracy: 0.3937 - val_loss: 1.9834 - val_accuracy: 0.3968\n",
            "Epoch 130/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 1.9116 - accuracy: 0.3906 - val_loss: 1.9759 - val_accuracy: 0.3982\n",
            "Epoch 131/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 1.8849 - accuracy: 0.4003 - val_loss: 1.9745 - val_accuracy: 0.4021\n",
            "Epoch 132/500\n",
            "36/36 [==============================] - 1s 41ms/step - loss: 1.8868 - accuracy: 0.3977 - val_loss: 1.9826 - val_accuracy: 0.3955\n",
            "Epoch 133/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 1.8755 - accuracy: 0.3996 - val_loss: 1.9789 - val_accuracy: 0.3935\n",
            "Epoch 134/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 1.8702 - accuracy: 0.4013 - val_loss: 1.9783 - val_accuracy: 0.3962\n",
            "Epoch 135/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 1.8447 - accuracy: 0.4051 - val_loss: 1.9722 - val_accuracy: 0.3988\n",
            "Epoch 136/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 1.8905 - accuracy: 0.3953 - val_loss: 1.9721 - val_accuracy: 0.3982\n",
            "Epoch 137/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 1.8952 - accuracy: 0.3849 - val_loss: 1.9840 - val_accuracy: 0.3889\n",
            "Epoch 138/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 1.8550 - accuracy: 0.3997 - val_loss: 1.9815 - val_accuracy: 0.3909\n",
            "Epoch 139/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 1.8770 - accuracy: 0.3984 - val_loss: 1.9833 - val_accuracy: 0.3949\n",
            "Epoch 140/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 1.8941 - accuracy: 0.3997 - val_loss: 1.9754 - val_accuracy: 0.3968\n",
            "Epoch 141/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 1.8643 - accuracy: 0.4004 - val_loss: 1.9789 - val_accuracy: 0.3955\n",
            "Epoch 142/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 1.8599 - accuracy: 0.4092 - val_loss: 1.9867 - val_accuracy: 0.4021\n",
            "Epoch 143/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 1.8706 - accuracy: 0.3994 - val_loss: 1.9900 - val_accuracy: 0.3869\n",
            "Epoch 144/500\n",
            "36/36 [==============================] - 1s 41ms/step - loss: 1.8562 - accuracy: 0.4089 - val_loss: 1.9934 - val_accuracy: 0.3843\n",
            "Epoch 145/500\n",
            "36/36 [==============================] - 1s 41ms/step - loss: 1.8630 - accuracy: 0.3998 - val_loss: 1.9697 - val_accuracy: 0.4021\n",
            "Epoch 146/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 1.8766 - accuracy: 0.3939 - val_loss: 1.9800 - val_accuracy: 0.3982\n",
            "Epoch 147/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 1.8452 - accuracy: 0.4028 - val_loss: 1.9749 - val_accuracy: 0.3982\n",
            "Epoch 148/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 1.8372 - accuracy: 0.4109 - val_loss: 1.9748 - val_accuracy: 0.4008\n",
            "Epoch 149/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 1.8556 - accuracy: 0.4051 - val_loss: 1.9814 - val_accuracy: 0.3929\n",
            "Epoch 150/500\n",
            "36/36 [==============================] - 1s 41ms/step - loss: 1.8328 - accuracy: 0.4081 - val_loss: 1.9864 - val_accuracy: 0.3968\n",
            "Epoch 151/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 1.8762 - accuracy: 0.4018 - val_loss: 1.9711 - val_accuracy: 0.4021\n",
            "Epoch 152/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 1.8437 - accuracy: 0.4146 - val_loss: 1.9720 - val_accuracy: 0.3949\n",
            "Epoch 153/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 1.8731 - accuracy: 0.4013 - val_loss: 1.9764 - val_accuracy: 0.3942\n",
            "Epoch 154/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 1.8910 - accuracy: 0.3996 - val_loss: 1.9718 - val_accuracy: 0.3949\n",
            "Epoch 155/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 1.8664 - accuracy: 0.4062 - val_loss: 1.9737 - val_accuracy: 0.3942\n",
            "Epoch 156/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 1.8426 - accuracy: 0.4075 - val_loss: 1.9674 - val_accuracy: 0.3949\n",
            "Epoch 157/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 1.8523 - accuracy: 0.4070 - val_loss: 1.9692 - val_accuracy: 0.3995\n",
            "Epoch 158/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 1.8394 - accuracy: 0.4144 - val_loss: 1.9683 - val_accuracy: 0.3975\n",
            "Epoch 159/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 1.8314 - accuracy: 0.4059 - val_loss: 1.9759 - val_accuracy: 0.3929\n",
            "Epoch 160/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 1.8495 - accuracy: 0.4033 - val_loss: 1.9705 - val_accuracy: 0.3988\n",
            "Epoch 161/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 1.8318 - accuracy: 0.4120 - val_loss: 1.9801 - val_accuracy: 0.3902\n",
            "Epoch 162/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 1.8401 - accuracy: 0.4079 - val_loss: 1.9738 - val_accuracy: 0.3995\n",
            "Epoch 163/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 1.8523 - accuracy: 0.4031 - val_loss: 1.9732 - val_accuracy: 0.3988\n",
            "Epoch 164/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 1.8386 - accuracy: 0.4071 - val_loss: 1.9704 - val_accuracy: 0.3916\n",
            "Epoch 165/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 1.8524 - accuracy: 0.4108 - val_loss: 1.9696 - val_accuracy: 0.3863\n",
            "Epoch 166/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 1.8477 - accuracy: 0.4061 - val_loss: 1.9693 - val_accuracy: 0.3968\n",
            "Epoch 167/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 1.8159 - accuracy: 0.4167 - val_loss: 1.9771 - val_accuracy: 0.3968\n",
            "Epoch 168/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 1.8211 - accuracy: 0.4094 - val_loss: 1.9805 - val_accuracy: 0.3909\n",
            "Epoch 169/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 1.8391 - accuracy: 0.4142 - val_loss: 1.9709 - val_accuracy: 0.4001\n",
            "Epoch 170/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 1.8298 - accuracy: 0.4130 - val_loss: 1.9813 - val_accuracy: 0.3942\n",
            "Epoch 171/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 1.8451 - accuracy: 0.4074 - val_loss: 1.9720 - val_accuracy: 0.3988\n",
            "Epoch 172/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 1.8184 - accuracy: 0.4131 - val_loss: 1.9712 - val_accuracy: 0.4001\n",
            "Epoch 173/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 1.8492 - accuracy: 0.4008 - val_loss: 1.9701 - val_accuracy: 0.4021\n",
            "Epoch 174/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 1.8360 - accuracy: 0.3999 - val_loss: 1.9718 - val_accuracy: 0.4021\n",
            "Epoch 175/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 1.8185 - accuracy: 0.4183 - val_loss: 1.9779 - val_accuracy: 0.4028\n",
            "Epoch 176/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 1.8382 - accuracy: 0.4144 - val_loss: 1.9850 - val_accuracy: 0.3863\n",
            "Epoch 177/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 1.8463 - accuracy: 0.4061 - val_loss: 1.9874 - val_accuracy: 0.3935\n",
            "Epoch 178/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 1.8218 - accuracy: 0.4069 - val_loss: 1.9875 - val_accuracy: 0.3850\n",
            "Epoch 179/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 1.8210 - accuracy: 0.4083 - val_loss: 1.9746 - val_accuracy: 0.3955\n",
            "Epoch 180/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 1.8379 - accuracy: 0.4094 - val_loss: 1.9856 - val_accuracy: 0.3869\n",
            "Epoch 181/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 1.8402 - accuracy: 0.4128 - val_loss: 1.9880 - val_accuracy: 0.3949\n",
            "Epoch 182/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 1.7991 - accuracy: 0.4174 - val_loss: 1.9882 - val_accuracy: 0.3902\n",
            "Epoch 183/500\n",
            "36/36 [==============================] - 1s 41ms/step - loss: 1.8595 - accuracy: 0.3975 - val_loss: 1.9959 - val_accuracy: 0.3837\n",
            "Epoch 184/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 1.8049 - accuracy: 0.4252 - val_loss: 1.9903 - val_accuracy: 0.3863\n",
            "Epoch 185/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 1.7943 - accuracy: 0.4220 - val_loss: 2.0061 - val_accuracy: 0.3751\n",
            "Epoch 186/500\n",
            "36/36 [==============================] - 1s 41ms/step - loss: 1.8390 - accuracy: 0.4029 - val_loss: 1.9833 - val_accuracy: 0.3949\n",
            "Epoch 187/500\n",
            "36/36 [==============================] - 1s 41ms/step - loss: 1.8311 - accuracy: 0.4053 - val_loss: 1.9748 - val_accuracy: 0.3982\n",
            "Epoch 188/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 1.8209 - accuracy: 0.4179 - val_loss: 1.9810 - val_accuracy: 0.3935\n",
            "Epoch 189/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 1.8279 - accuracy: 0.4081 - val_loss: 1.9805 - val_accuracy: 0.3922\n",
            "Epoch 190/500\n",
            "36/36 [==============================] - 1s 41ms/step - loss: 1.8062 - accuracy: 0.4086 - val_loss: 1.9744 - val_accuracy: 0.3962\n",
            "Epoch 191/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 1.8120 - accuracy: 0.4121 - val_loss: 1.9878 - val_accuracy: 0.3935\n",
            "Epoch 192/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 1.8333 - accuracy: 0.4144 - val_loss: 1.9818 - val_accuracy: 0.3902\n",
            "Epoch 193/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 1.8359 - accuracy: 0.4107 - val_loss: 1.9878 - val_accuracy: 0.3962\n",
            "Epoch 194/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 1.7943 - accuracy: 0.4259 - val_loss: 1.9897 - val_accuracy: 0.3896\n",
            "Epoch 195/500\n",
            "36/36 [==============================] - 1s 41ms/step - loss: 1.8156 - accuracy: 0.4081 - val_loss: 1.9971 - val_accuracy: 0.3797\n",
            "Epoch 196/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 1.8257 - accuracy: 0.4216 - val_loss: 1.9717 - val_accuracy: 0.3955\n",
            "Epoch 197/500\n",
            "36/36 [==============================] - 2s 42ms/step - loss: 1.8153 - accuracy: 0.4049 - val_loss: 1.9864 - val_accuracy: 0.3902\n",
            "Epoch 198/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 1.8192 - accuracy: 0.4054 - val_loss: 1.9991 - val_accuracy: 0.4001\n",
            "Epoch 199/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 1.8312 - accuracy: 0.4068 - val_loss: 1.9847 - val_accuracy: 0.3876\n",
            "Epoch 200/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 1.7935 - accuracy: 0.4247 - val_loss: 1.9784 - val_accuracy: 0.3883\n",
            "Epoch 201/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 1.8227 - accuracy: 0.4170 - val_loss: 1.9855 - val_accuracy: 0.3869\n",
            "Epoch 202/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 1.7732 - accuracy: 0.4326 - val_loss: 1.9825 - val_accuracy: 0.3922\n",
            "Epoch 203/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 1.7990 - accuracy: 0.4211 - val_loss: 1.9895 - val_accuracy: 0.3935\n",
            "Epoch 204/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 1.8162 - accuracy: 0.4114 - val_loss: 1.9905 - val_accuracy: 0.3843\n",
            "Epoch 205/500\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 1.8261 - accuracy: 0.4163 - val_loss: 1.9842 - val_accuracy: 0.3863\n",
            "Epoch 206/500\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 1.7782 - accuracy: 0.4174 - val_loss: 1.9953 - val_accuracy: 0.3850\n",
            "\u001b[1;37m2021-03-24 12:38:44 [INFO] Model Accuracy on test: 37.15%, Loss: 2.00\u001b[0m\n",
            "\u001b[1;37m2021-03-24 12:38:44 [INFO] 保存模型：result/model/lstm/myspace.h5\u001b[0m\n",
            "\u001b[1;37m2021-03-24 12:38:44 [INFO] TensorBoard 日志：logs/lstm/myspace210324123344\u001b[0m\n",
            "\u001b[1;37m2021-03-24 12:38:44 [INFO] ************************************************完成训练LSTM模型************************************************\u001b[0m\n",
            "\u001b[1;37m2021-03-24 12:38:44 [INFO] 开始加载编码后的密码数据：result/preprocessed/wordlist/phpbb.txt\u001b[0m\n",
            "\u001b[1;37m2021-03-24 12:38:44 [INFO] 开始加载tokenizer模型：result/model/tokenizer/phpbb.pkl\u001b[0m\n",
            "\u001b[1;37m2021-03-24 12:38:44 [INFO] 将编码后的密码转换为（整数）序列\u001b[0m\n",
            "\u001b[1;37m2021-03-24 12:38:44 [INFO] Total Sequences: 15108\u001b[0m\n",
            "\u001b[1;37m2021-03-24 12:38:45 [INFO] 创建LSTM模型的输入输出\u001b[0m\n",
            "\u001b[1;37m2021-03-24 12:38:45 [INFO] X Shape: (15108, 19), y Shape: (15108,)\u001b[0m\n",
            "\u001b[1;37m2021-03-24 12:38:45 [INFO] 划分训练集、验证集和测试集\u001b[0m\n",
            "\u001b[1;37m2021-03-24 12:38:45 [INFO] x_train Shape: (9064, 19), y_train Shape: (9064, 54)\u001b[0m\n",
            "\u001b[1;37m2021-03-24 12:38:45 [INFO] x_val Shape: (3022, 19), y_val Shape: (3022, 54)\u001b[0m\n",
            "\u001b[1;37m2021-03-24 12:38:45 [INFO] x_test Shape: (3022, 19), y_test Shape: (3022, 54)\u001b[0m\n",
            "\u001b[1;37m2021-03-24 12:38:45 [INFO] *************************************************创建LSTM模型*************************************************\u001b[0m\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 19, 10)            540       \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 19, 32)            5504      \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, 19, 32)            8320      \n",
            "_________________________________________________________________\n",
            "lstm_5 (LSTM)                (None, 32)                8320      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 54)                1782      \n",
            "=================================================================\n",
            "Total params: 25,522\n",
            "Trainable params: 25,522\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\u001b[1;37m2021-03-24 12:38:45 [INFO] 训练日志文件：logs/lstm/phpbb210324123845\u001b[0m\n",
            "2021-03-24 12:38:45.786161: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.\n",
            "2021-03-24 12:38:45.786226: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.\n",
            "2021-03-24 12:38:45.786286: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.\n",
            "\u001b[1;37m2021-03-24 12:38:45 [INFO] ************************************************开始训练LSTM模型************************************************\u001b[0m\n",
            "Epoch 1/500\n",
            " 1/71 [..............................] - ETA: 5:28 - loss: 3.9889 - accuracy: 0.0000e+002021-03-24 12:38:50.697202: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.\n",
            "2021-03-24 12:38:50.697422: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.\n",
            " 2/71 [..............................] - ETA: 13s - loss: 3.9873 - accuracy: 0.0469     2021-03-24 12:38:50.901699: I tensorflow/core/profiler/lib/profiler_session.cc:71] Profiler session collecting data.\n",
            "2021-03-24 12:38:50.939615: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.\n",
            "71/71 [==============================] - 9s 63ms/step - loss: 3.5607 - accuracy: 0.1729 - val_loss: 2.5175 - val_accuracy: 0.1985\n",
            "Epoch 2/500\n",
            "71/71 [==============================] - 3s 39ms/step - loss: 2.5207 - accuracy: 0.1819 - val_loss: 2.4542 - val_accuracy: 0.1985\n",
            "Epoch 3/500\n",
            "71/71 [==============================] - 3s 40ms/step - loss: 2.4713 - accuracy: 0.1841 - val_loss: 2.4425 - val_accuracy: 0.1985\n",
            "Epoch 4/500\n",
            "71/71 [==============================] - 3s 40ms/step - loss: 2.4932 - accuracy: 0.1805 - val_loss: 2.4373 - val_accuracy: 0.1621\n",
            "Epoch 5/500\n",
            "71/71 [==============================] - 3s 40ms/step - loss: 2.4973 - accuracy: 0.1794 - val_loss: 2.4347 - val_accuracy: 0.1985\n",
            "Epoch 6/500\n",
            "71/71 [==============================] - 3s 39ms/step - loss: 2.4870 - accuracy: 0.1718 - val_loss: 2.4358 - val_accuracy: 0.1985\n",
            "Epoch 7/500\n",
            "71/71 [==============================] - 3s 40ms/step - loss: 2.4937 - accuracy: 0.1881 - val_loss: 2.4369 - val_accuracy: 0.1608\n",
            "Epoch 8/500\n",
            "71/71 [==============================] - 3s 39ms/step - loss: 2.4852 - accuracy: 0.1750 - val_loss: 2.4371 - val_accuracy: 0.1985\n",
            "Epoch 9/500\n",
            "71/71 [==============================] - 3s 39ms/step - loss: 2.4754 - accuracy: 0.1857 - val_loss: 2.4408 - val_accuracy: 0.1985\n",
            "Epoch 10/500\n",
            "71/71 [==============================] - 3s 40ms/step - loss: 2.4628 - accuracy: 0.1900 - val_loss: 2.4425 - val_accuracy: 0.1608\n",
            "Epoch 11/500\n",
            "71/71 [==============================] - 3s 40ms/step - loss: 2.4802 - accuracy: 0.1736 - val_loss: 2.4383 - val_accuracy: 0.1985\n",
            "Epoch 12/500\n",
            "71/71 [==============================] - 3s 40ms/step - loss: 2.4781 - accuracy: 0.1758 - val_loss: 2.4367 - val_accuracy: 0.1985\n",
            "Epoch 13/500\n",
            "71/71 [==============================] - 3s 40ms/step - loss: 2.4814 - accuracy: 0.1832 - val_loss: 2.4379 - val_accuracy: 0.1985\n",
            "Epoch 14/500\n",
            "71/71 [==============================] - 3s 40ms/step - loss: 2.4849 - accuracy: 0.1892 - val_loss: 2.4418 - val_accuracy: 0.1621\n",
            "Epoch 15/500\n",
            "71/71 [==============================] - 3s 39ms/step - loss: 2.4698 - accuracy: 0.1739 - val_loss: 2.4406 - val_accuracy: 0.1985\n",
            "Epoch 16/500\n",
            "71/71 [==============================] - 3s 39ms/step - loss: 2.4719 - accuracy: 0.1871 - val_loss: 2.4334 - val_accuracy: 0.1985\n",
            "Epoch 17/500\n",
            "71/71 [==============================] - 3s 40ms/step - loss: 2.4704 - accuracy: 0.1864 - val_loss: 2.3503 - val_accuracy: 0.2535\n",
            "Epoch 18/500\n",
            "71/71 [==============================] - 3s 39ms/step - loss: 2.3740 - accuracy: 0.2406 - val_loss: 2.2614 - val_accuracy: 0.2882\n",
            "Epoch 19/500\n",
            "71/71 [==============================] - 3s 39ms/step - loss: 2.2770 - accuracy: 0.2849 - val_loss: 2.2077 - val_accuracy: 0.3031\n",
            "Epoch 20/500\n",
            "71/71 [==============================] - 3s 39ms/step - loss: 2.2510 - accuracy: 0.2935 - val_loss: 2.1942 - val_accuracy: 0.3048\n",
            "Epoch 21/500\n",
            "71/71 [==============================] - 3s 39ms/step - loss: 2.2394 - accuracy: 0.2993 - val_loss: 2.1868 - val_accuracy: 0.3084\n",
            "Epoch 22/500\n",
            "71/71 [==============================] - 3s 39ms/step - loss: 2.2213 - accuracy: 0.3053 - val_loss: 2.1841 - val_accuracy: 0.3163\n",
            "Epoch 23/500\n",
            "71/71 [==============================] - 3s 39ms/step - loss: 2.2429 - accuracy: 0.3023 - val_loss: 2.1920 - val_accuracy: 0.3233\n",
            "Epoch 24/500\n",
            "71/71 [==============================] - 3s 39ms/step - loss: 2.2145 - accuracy: 0.3027 - val_loss: 2.1953 - val_accuracy: 0.3001\n",
            "Epoch 25/500\n",
            "71/71 [==============================] - 3s 39ms/step - loss: 2.2107 - accuracy: 0.3100 - val_loss: 2.1725 - val_accuracy: 0.3243\n",
            "Epoch 26/500\n",
            "71/71 [==============================] - 3s 39ms/step - loss: 2.2020 - accuracy: 0.3171 - val_loss: 2.1678 - val_accuracy: 0.3021\n",
            "Epoch 27/500\n",
            "71/71 [==============================] - 3s 41ms/step - loss: 2.1709 - accuracy: 0.3331 - val_loss: 2.1387 - val_accuracy: 0.3762\n",
            "Epoch 28/500\n",
            "71/71 [==============================] - 3s 40ms/step - loss: 2.1502 - accuracy: 0.3718 - val_loss: 2.0278 - val_accuracy: 0.3984\n",
            "Epoch 29/500\n",
            "71/71 [==============================] - 3s 40ms/step - loss: 2.0237 - accuracy: 0.3855 - val_loss: 1.9512 - val_accuracy: 0.4037\n",
            "Epoch 30/500\n",
            "71/71 [==============================] - 3s 40ms/step - loss: 1.9554 - accuracy: 0.3943 - val_loss: 1.9004 - val_accuracy: 0.4100\n",
            "Epoch 31/500\n",
            "71/71 [==============================] - 3s 39ms/step - loss: 1.8891 - accuracy: 0.4072 - val_loss: 1.8873 - val_accuracy: 0.4163\n",
            "Epoch 32/500\n",
            "71/71 [==============================] - 3s 39ms/step - loss: 1.8936 - accuracy: 0.4088 - val_loss: 1.8885 - val_accuracy: 0.4067\n",
            "Epoch 33/500\n",
            "71/71 [==============================] - 3s 40ms/step - loss: 1.8926 - accuracy: 0.4011 - val_loss: 1.8711 - val_accuracy: 0.4136\n",
            "Epoch 34/500\n",
            "71/71 [==============================] - 3s 39ms/step - loss: 1.9123 - accuracy: 0.3955 - val_loss: 1.8722 - val_accuracy: 0.4159\n",
            "Epoch 35/500\n",
            "71/71 [==============================] - 3s 40ms/step - loss: 1.8903 - accuracy: 0.4089 - val_loss: 1.8740 - val_accuracy: 0.4113\n",
            "Epoch 36/500\n",
            "71/71 [==============================] - 3s 39ms/step - loss: 1.8704 - accuracy: 0.4041 - val_loss: 1.8656 - val_accuracy: 0.4107\n",
            "Epoch 37/500\n",
            "71/71 [==============================] - 3s 39ms/step - loss: 1.8629 - accuracy: 0.4070 - val_loss: 1.8677 - val_accuracy: 0.4120\n",
            "Epoch 38/500\n",
            "71/71 [==============================] - 3s 40ms/step - loss: 1.8729 - accuracy: 0.4074 - val_loss: 1.8632 - val_accuracy: 0.4113\n",
            "Epoch 39/500\n",
            "71/71 [==============================] - 3s 39ms/step - loss: 1.8429 - accuracy: 0.4077 - val_loss: 1.8589 - val_accuracy: 0.4126\n",
            "Epoch 40/500\n",
            "71/71 [==============================] - 3s 40ms/step - loss: 1.8694 - accuracy: 0.4090 - val_loss: 1.8712 - val_accuracy: 0.4116\n",
            "Epoch 41/500\n",
            "71/71 [==============================] - 3s 40ms/step - loss: 1.8550 - accuracy: 0.4112 - val_loss: 1.8623 - val_accuracy: 0.4103\n",
            "Epoch 42/500\n",
            "71/71 [==============================] - 3s 40ms/step - loss: 1.8569 - accuracy: 0.4023 - val_loss: 1.8608 - val_accuracy: 0.4120\n",
            "Epoch 43/500\n",
            "71/71 [==============================] - 3s 39ms/step - loss: 1.8576 - accuracy: 0.4108 - val_loss: 1.8572 - val_accuracy: 0.4120\n",
            "Epoch 44/500\n",
            "71/71 [==============================] - 3s 39ms/step - loss: 1.8465 - accuracy: 0.4144 - val_loss: 1.8572 - val_accuracy: 0.4116\n",
            "Epoch 45/500\n",
            "71/71 [==============================] - 3s 39ms/step - loss: 1.8587 - accuracy: 0.4075 - val_loss: 1.8544 - val_accuracy: 0.4120\n",
            "Epoch 46/500\n",
            "71/71 [==============================] - 3s 40ms/step - loss: 1.8477 - accuracy: 0.4078 - val_loss: 1.8647 - val_accuracy: 0.4054\n",
            "Epoch 47/500\n",
            "71/71 [==============================] - 3s 40ms/step - loss: 1.8600 - accuracy: 0.4044 - val_loss: 1.8525 - val_accuracy: 0.4126\n",
            "Epoch 48/500\n",
            "71/71 [==============================] - 3s 39ms/step - loss: 1.8723 - accuracy: 0.4014 - val_loss: 1.8506 - val_accuracy: 0.4120\n",
            "Epoch 49/500\n",
            "71/71 [==============================] - 3s 41ms/step - loss: 1.8266 - accuracy: 0.4160 - val_loss: 1.8470 - val_accuracy: 0.4123\n",
            "Epoch 50/500\n",
            "71/71 [==============================] - 3s 40ms/step - loss: 1.8575 - accuracy: 0.4044 - val_loss: 1.8442 - val_accuracy: 0.4120\n",
            "Epoch 51/500\n",
            "71/71 [==============================] - 3s 40ms/step - loss: 1.8416 - accuracy: 0.4075 - val_loss: 1.8489 - val_accuracy: 0.4097\n",
            "Epoch 52/500\n",
            "71/71 [==============================] - 3s 39ms/step - loss: 1.8248 - accuracy: 0.4112 - val_loss: 1.8438 - val_accuracy: 0.4126\n",
            "Epoch 53/500\n",
            "71/71 [==============================] - 3s 39ms/step - loss: 1.8318 - accuracy: 0.4137 - val_loss: 1.8370 - val_accuracy: 0.4123\n",
            "Epoch 54/500\n",
            "71/71 [==============================] - 3s 40ms/step - loss: 1.8295 - accuracy: 0.4152 - val_loss: 1.8390 - val_accuracy: 0.4080\n",
            "Epoch 55/500\n",
            "71/71 [==============================] - 3s 39ms/step - loss: 1.7971 - accuracy: 0.4228 - val_loss: 1.8412 - val_accuracy: 0.4110\n",
            "Epoch 56/500\n",
            "71/71 [==============================] - 3s 39ms/step - loss: 1.8103 - accuracy: 0.4213 - val_loss: 1.8354 - val_accuracy: 0.4123\n",
            "Epoch 57/500\n",
            "71/71 [==============================] - 3s 39ms/step - loss: 1.8186 - accuracy: 0.4164 - val_loss: 1.8325 - val_accuracy: 0.4116\n",
            "Epoch 58/500\n",
            "71/71 [==============================] - 3s 39ms/step - loss: 1.8217 - accuracy: 0.4145 - val_loss: 1.8276 - val_accuracy: 0.4130\n",
            "Epoch 59/500\n",
            "71/71 [==============================] - 3s 40ms/step - loss: 1.7978 - accuracy: 0.4182 - val_loss: 1.8199 - val_accuracy: 0.4120\n",
            "Epoch 60/500\n",
            "71/71 [==============================] - 3s 39ms/step - loss: 1.8294 - accuracy: 0.4081 - val_loss: 1.8227 - val_accuracy: 0.4100\n",
            "Epoch 61/500\n",
            "71/71 [==============================] - 3s 39ms/step - loss: 1.8055 - accuracy: 0.4153 - val_loss: 1.8185 - val_accuracy: 0.4156\n",
            "Epoch 62/500\n",
            "71/71 [==============================] - 3s 41ms/step - loss: 1.8042 - accuracy: 0.4159 - val_loss: 1.8256 - val_accuracy: 0.4140\n",
            "Epoch 63/500\n",
            "71/71 [==============================] - 3s 39ms/step - loss: 1.8118 - accuracy: 0.4097 - val_loss: 1.8146 - val_accuracy: 0.4143\n",
            "Epoch 64/500\n",
            "71/71 [==============================] - 3s 39ms/step - loss: 1.8027 - accuracy: 0.4058 - val_loss: 1.8092 - val_accuracy: 0.4133\n",
            "Epoch 65/500\n",
            "71/71 [==============================] - 3s 39ms/step - loss: 1.7833 - accuracy: 0.4195 - val_loss: 1.8125 - val_accuracy: 0.4116\n",
            "Epoch 66/500\n",
            "71/71 [==============================] - 3s 40ms/step - loss: 1.7891 - accuracy: 0.4152 - val_loss: 1.8088 - val_accuracy: 0.4143\n",
            "Epoch 67/500\n",
            "71/71 [==============================] - 3s 40ms/step - loss: 1.8057 - accuracy: 0.4050 - val_loss: 1.8061 - val_accuracy: 0.4146\n",
            "Epoch 68/500\n",
            "71/71 [==============================] - 3s 40ms/step - loss: 1.7715 - accuracy: 0.4267 - val_loss: 1.8056 - val_accuracy: 0.4140\n",
            "Epoch 69/500\n",
            "71/71 [==============================] - 3s 40ms/step - loss: 1.7815 - accuracy: 0.4174 - val_loss: 1.8107 - val_accuracy: 0.4140\n",
            "Epoch 70/500\n",
            "71/71 [==============================] - 3s 40ms/step - loss: 1.7690 - accuracy: 0.4221 - val_loss: 1.8096 - val_accuracy: 0.4140\n",
            "Epoch 71/500\n",
            "71/71 [==============================] - 3s 40ms/step - loss: 1.7847 - accuracy: 0.4209 - val_loss: 1.8050 - val_accuracy: 0.4166\n",
            "Epoch 72/500\n",
            "71/71 [==============================] - 3s 39ms/step - loss: 1.8047 - accuracy: 0.4086 - val_loss: 1.8073 - val_accuracy: 0.4166\n",
            "Epoch 73/500\n",
            "71/71 [==============================] - 3s 40ms/step - loss: 1.7947 - accuracy: 0.4150 - val_loss: 1.8044 - val_accuracy: 0.4156\n",
            "Epoch 74/500\n",
            "71/71 [==============================] - 3s 40ms/step - loss: 1.7695 - accuracy: 0.4202 - val_loss: 1.8087 - val_accuracy: 0.4110\n",
            "Epoch 75/500\n",
            "71/71 [==============================] - 3s 40ms/step - loss: 1.7862 - accuracy: 0.4226 - val_loss: 1.8066 - val_accuracy: 0.4173\n",
            "Epoch 76/500\n",
            "71/71 [==============================] - 3s 40ms/step - loss: 1.7762 - accuracy: 0.4198 - val_loss: 1.8077 - val_accuracy: 0.4116\n",
            "Epoch 77/500\n",
            "71/71 [==============================] - 3s 39ms/step - loss: 1.7629 - accuracy: 0.4254 - val_loss: 1.8086 - val_accuracy: 0.4156\n",
            "Epoch 78/500\n",
            "71/71 [==============================] - 3s 41ms/step - loss: 1.8030 - accuracy: 0.4099 - val_loss: 1.8052 - val_accuracy: 0.4143\n",
            "Epoch 79/500\n",
            "71/71 [==============================] - 3s 40ms/step - loss: 1.7795 - accuracy: 0.4219 - val_loss: 1.8063 - val_accuracy: 0.4146\n",
            "Epoch 80/500\n",
            "71/71 [==============================] - 3s 41ms/step - loss: 1.7887 - accuracy: 0.4212 - val_loss: 1.8051 - val_accuracy: 0.4146\n",
            "Epoch 81/500\n",
            "71/71 [==============================] - 3s 39ms/step - loss: 1.7771 - accuracy: 0.4239 - val_loss: 1.8054 - val_accuracy: 0.4143\n",
            "Epoch 82/500\n",
            "71/71 [==============================] - 3s 39ms/step - loss: 1.7627 - accuracy: 0.4243 - val_loss: 1.8045 - val_accuracy: 0.4133\n",
            "Epoch 83/500\n",
            "71/71 [==============================] - 3s 40ms/step - loss: 1.7641 - accuracy: 0.4295 - val_loss: 1.8169 - val_accuracy: 0.4087\n",
            "Epoch 84/500\n",
            "71/71 [==============================] - 3s 39ms/step - loss: 1.7707 - accuracy: 0.4253 - val_loss: 1.8166 - val_accuracy: 0.4130\n",
            "Epoch 85/500\n",
            "71/71 [==============================] - 3s 40ms/step - loss: 1.7853 - accuracy: 0.4255 - val_loss: 1.8062 - val_accuracy: 0.4163\n",
            "Epoch 86/500\n",
            "71/71 [==============================] - 3s 39ms/step - loss: 1.7646 - accuracy: 0.4205 - val_loss: 1.8075 - val_accuracy: 0.4136\n",
            "Epoch 87/500\n",
            "71/71 [==============================] - 3s 40ms/step - loss: 1.7752 - accuracy: 0.4213 - val_loss: 1.8131 - val_accuracy: 0.4107\n",
            "Epoch 88/500\n",
            "71/71 [==============================] - 3s 40ms/step - loss: 1.7575 - accuracy: 0.4212 - val_loss: 1.8076 - val_accuracy: 0.4153\n",
            "Epoch 89/500\n",
            "71/71 [==============================] - 3s 40ms/step - loss: 1.7748 - accuracy: 0.4207 - val_loss: 1.8210 - val_accuracy: 0.4100\n",
            "Epoch 90/500\n",
            "71/71 [==============================] - 3s 40ms/step - loss: 1.7702 - accuracy: 0.4208 - val_loss: 1.8133 - val_accuracy: 0.4123\n",
            "Epoch 91/500\n",
            "71/71 [==============================] - 3s 41ms/step - loss: 1.7547 - accuracy: 0.4275 - val_loss: 1.8061 - val_accuracy: 0.4126\n",
            "Epoch 92/500\n",
            "71/71 [==============================] - 3s 41ms/step - loss: 1.7717 - accuracy: 0.4195 - val_loss: 1.8115 - val_accuracy: 0.4156\n",
            "Epoch 93/500\n",
            "71/71 [==============================] - 3s 42ms/step - loss: 1.7658 - accuracy: 0.4167 - val_loss: 1.8132 - val_accuracy: 0.4126\n",
            "Epoch 94/500\n",
            "71/71 [==============================] - 3s 40ms/step - loss: 1.7546 - accuracy: 0.4278 - val_loss: 1.8074 - val_accuracy: 0.4126\n",
            "Epoch 95/500\n",
            "71/71 [==============================] - 3s 39ms/step - loss: 1.7672 - accuracy: 0.4186 - val_loss: 1.8101 - val_accuracy: 0.4116\n",
            "Epoch 96/500\n",
            "71/71 [==============================] - 3s 39ms/step - loss: 1.7505 - accuracy: 0.4278 - val_loss: 1.8083 - val_accuracy: 0.4143\n",
            "Epoch 97/500\n",
            "71/71 [==============================] - 3s 39ms/step - loss: 1.7578 - accuracy: 0.4230 - val_loss: 1.8096 - val_accuracy: 0.4159\n",
            "Epoch 98/500\n",
            "71/71 [==============================] - 3s 39ms/step - loss: 1.7642 - accuracy: 0.4213 - val_loss: 1.8112 - val_accuracy: 0.4166\n",
            "Epoch 99/500\n",
            "71/71 [==============================] - 3s 41ms/step - loss: 1.7567 - accuracy: 0.4243 - val_loss: 1.8123 - val_accuracy: 0.4103\n",
            "Epoch 100/500\n",
            "71/71 [==============================] - 3s 40ms/step - loss: 1.7725 - accuracy: 0.4185 - val_loss: 1.8168 - val_accuracy: 0.4100\n",
            "Epoch 101/500\n",
            "71/71 [==============================] - 3s 40ms/step - loss: 1.7505 - accuracy: 0.4270 - val_loss: 1.8151 - val_accuracy: 0.4107\n",
            "Epoch 102/500\n",
            "71/71 [==============================] - 3s 40ms/step - loss: 1.7613 - accuracy: 0.4233 - val_loss: 1.8158 - val_accuracy: 0.4110\n",
            "Epoch 103/500\n",
            "71/71 [==============================] - 3s 40ms/step - loss: 1.7528 - accuracy: 0.4246 - val_loss: 1.8116 - val_accuracy: 0.4136\n",
            "Epoch 104/500\n",
            "71/71 [==============================] - 3s 40ms/step - loss: 1.7742 - accuracy: 0.4190 - val_loss: 1.8108 - val_accuracy: 0.4163\n",
            "Epoch 105/500\n",
            "71/71 [==============================] - 3s 39ms/step - loss: 1.7581 - accuracy: 0.4232 - val_loss: 1.8113 - val_accuracy: 0.4150\n",
            "Epoch 106/500\n",
            "71/71 [==============================] - 3s 40ms/step - loss: 1.7604 - accuracy: 0.4307 - val_loss: 1.8196 - val_accuracy: 0.4113\n",
            "Epoch 107/500\n",
            "71/71 [==============================] - 3s 40ms/step - loss: 1.7650 - accuracy: 0.4194 - val_loss: 1.8157 - val_accuracy: 0.4159\n",
            "Epoch 108/500\n",
            "71/71 [==============================] - 3s 39ms/step - loss: 1.7687 - accuracy: 0.4240 - val_loss: 1.8134 - val_accuracy: 0.4153\n",
            "Epoch 109/500\n",
            "71/71 [==============================] - 3s 41ms/step - loss: 1.7349 - accuracy: 0.4320 - val_loss: 1.8163 - val_accuracy: 0.4146\n",
            "Epoch 110/500\n",
            "71/71 [==============================] - 3s 40ms/step - loss: 1.7539 - accuracy: 0.4222 - val_loss: 1.8151 - val_accuracy: 0.4140\n",
            "Epoch 111/500\n",
            "71/71 [==============================] - 3s 40ms/step - loss: 1.7701 - accuracy: 0.4212 - val_loss: 1.8188 - val_accuracy: 0.4107\n",
            "Epoch 112/500\n",
            "71/71 [==============================] - 3s 40ms/step - loss: 1.7710 - accuracy: 0.4196 - val_loss: 1.8183 - val_accuracy: 0.4120\n",
            "Epoch 113/500\n",
            "71/71 [==============================] - 3s 39ms/step - loss: 1.7485 - accuracy: 0.4248 - val_loss: 1.8162 - val_accuracy: 0.4110\n",
            "Epoch 114/500\n",
            "71/71 [==============================] - 3s 40ms/step - loss: 1.7607 - accuracy: 0.4225 - val_loss: 1.8167 - val_accuracy: 0.4150\n",
            "Epoch 115/500\n",
            "71/71 [==============================] - 3s 39ms/step - loss: 1.7442 - accuracy: 0.4230 - val_loss: 1.8248 - val_accuracy: 0.4107\n",
            "Epoch 116/500\n",
            "71/71 [==============================] - 3s 41ms/step - loss: 1.7570 - accuracy: 0.4186 - val_loss: 1.8201 - val_accuracy: 0.4146\n",
            "Epoch 117/500\n",
            "71/71 [==============================] - 3s 40ms/step - loss: 1.7613 - accuracy: 0.4244 - val_loss: 1.8187 - val_accuracy: 0.4107\n",
            "Epoch 118/500\n",
            "71/71 [==============================] - 3s 40ms/step - loss: 1.7641 - accuracy: 0.4252 - val_loss: 1.8131 - val_accuracy: 0.4156\n",
            "Epoch 119/500\n",
            "71/71 [==============================] - 3s 40ms/step - loss: 1.7569 - accuracy: 0.4200 - val_loss: 1.8216 - val_accuracy: 0.4110\n",
            "Epoch 120/500\n",
            "71/71 [==============================] - 3s 40ms/step - loss: 1.7536 - accuracy: 0.4210 - val_loss: 1.8212 - val_accuracy: 0.4140\n",
            "Epoch 121/500\n",
            "71/71 [==============================] - 3s 40ms/step - loss: 1.7526 - accuracy: 0.4206 - val_loss: 1.8237 - val_accuracy: 0.4116\n",
            "Epoch 122/500\n",
            "71/71 [==============================] - 3s 40ms/step - loss: 1.7536 - accuracy: 0.4229 - val_loss: 1.8221 - val_accuracy: 0.4136\n",
            "Epoch 123/500\n",
            "71/71 [==============================] - 3s 40ms/step - loss: 1.7237 - accuracy: 0.4299 - val_loss: 1.8263 - val_accuracy: 0.4179\n",
            "\u001b[1;37m2021-03-24 12:44:38 [INFO] Model Accuracy on test: 42.12%, Loss: 1.81\u001b[0m\n",
            "\u001b[1;37m2021-03-24 12:44:38 [INFO] 保存模型：result/model/lstm/phpbb.h5\u001b[0m\n",
            "\u001b[1;37m2021-03-24 12:44:39 [INFO] TensorBoard 日志：logs/lstm/phpbb210324123845\u001b[0m\n",
            "\u001b[1;37m2021-03-24 12:44:39 [INFO] ************************************************完成训练LSTM模型************************************************\u001b[0m\n",
            "\u001b[1;37m2021-03-24 12:44:39 [INFO] 开始加载编码后的密码数据：result/preprocessed/wordlist/myspace_part.txt\u001b[0m\n",
            "\u001b[1;37m2021-03-24 12:44:39 [INFO] 开始加载tokenizer模型：result/model/tokenizer/myspace_part.pkl\u001b[0m\n",
            "\u001b[1;37m2021-03-24 12:44:39 [INFO] 将编码后的密码转换为（整数）序列\u001b[0m\n",
            "\u001b[1;37m2021-03-24 12:44:39 [INFO] Total Sequences: 5179\u001b[0m\n",
            "\u001b[1;37m2021-03-24 12:44:39 [INFO] 创建LSTM模型的输入输出\u001b[0m\n",
            "\u001b[1;37m2021-03-24 12:44:39 [INFO] X Shape: (5179, 19), y Shape: (5179,)\u001b[0m\n",
            "\u001b[1;37m2021-03-24 12:44:39 [INFO] 划分训练集、验证集和测试集\u001b[0m\n",
            "\u001b[1;37m2021-03-24 12:44:39 [INFO] x_train Shape: (3107, 19), y_train Shape: (3107, 41)\u001b[0m\n",
            "\u001b[1;37m2021-03-24 12:44:39 [INFO] x_val Shape: (1036, 19), y_val Shape: (1036, 41)\u001b[0m\n",
            "\u001b[1;37m2021-03-24 12:44:39 [INFO] x_test Shape: (1036, 19), y_test Shape: (1036, 41)\u001b[0m\n",
            "\u001b[1;37m2021-03-24 12:44:39 [INFO] *************************************************创建LSTM模型*************************************************\u001b[0m\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 19, 10)            410       \n",
            "_________________________________________________________________\n",
            "lstm_6 (LSTM)                (None, 19, 32)            5504      \n",
            "_________________________________________________________________\n",
            "lstm_7 (LSTM)                (None, 19, 32)            8320      \n",
            "_________________________________________________________________\n",
            "lstm_8 (LSTM)                (None, 32)                8320      \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 41)                1353      \n",
            "=================================================================\n",
            "Total params: 24,963\n",
            "Trainable params: 24,963\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\u001b[1;37m2021-03-24 12:44:39 [INFO] 训练日志文件：logs/lstm/myspace_part210324124439\u001b[0m\n",
            "2021-03-24 12:44:39.954735: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.\n",
            "2021-03-24 12:44:39.954794: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.\n",
            "2021-03-24 12:44:39.954841: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.\n",
            "\u001b[1;37m2021-03-24 12:44:39 [INFO] ************************************************开始训练LSTM模型************************************************\u001b[0m\n",
            "Epoch 1/500\n",
            " 1/25 [>.............................] - ETA: 1:52 - loss: 3.7145 - accuracy: 0.0000e+002021-03-24 12:44:44.855345: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.\n",
            "2021-03-24 12:44:44.855416: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.\n",
            " 2/25 [=>............................] - ETA: 4s - loss: 3.7139 - accuracy: 0.0020      2021-03-24 12:44:45.072108: I tensorflow/core/profiler/lib/profiler_session.cc:71] Profiler session collecting data.\n",
            "2021-03-24 12:44:45.106152: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.\n",
            "25/25 [==============================] - 7s 110ms/step - loss: 3.6743 - accuracy: 0.1499 - val_loss: 3.2480 - val_accuracy: 0.1197\n",
            "Epoch 2/500\n",
            "25/25 [==============================] - 1s 39ms/step - loss: 3.0833 - accuracy: 0.1932 - val_loss: 2.8140 - val_accuracy: 0.1863\n",
            "Epoch 3/500\n",
            "25/25 [==============================] - 1s 39ms/step - loss: 2.7069 - accuracy: 0.2042 - val_loss: 2.6629 - val_accuracy: 0.1863\n",
            "Epoch 4/500\n",
            "25/25 [==============================] - 1s 40ms/step - loss: 2.5813 - accuracy: 0.2087 - val_loss: 2.6364 - val_accuracy: 0.1863\n",
            "Epoch 5/500\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 2.5939 - accuracy: 0.2034 - val_loss: 2.6233 - val_accuracy: 0.1863\n",
            "Epoch 6/500\n",
            "25/25 [==============================] - 1s 40ms/step - loss: 2.5597 - accuracy: 0.2187 - val_loss: 2.6175 - val_accuracy: 0.1863\n",
            "Epoch 7/500\n",
            "25/25 [==============================] - 1s 40ms/step - loss: 2.5420 - accuracy: 0.2049 - val_loss: 2.6158 - val_accuracy: 0.1863\n",
            "Epoch 8/500\n",
            "25/25 [==============================] - 1s 39ms/step - loss: 2.5621 - accuracy: 0.2128 - val_loss: 2.6115 - val_accuracy: 0.1863\n",
            "Epoch 9/500\n",
            "25/25 [==============================] - 1s 40ms/step - loss: 2.5436 - accuracy: 0.2108 - val_loss: 2.6121 - val_accuracy: 0.1863\n",
            "Epoch 10/500\n",
            "25/25 [==============================] - 1s 43ms/step - loss: 2.5594 - accuracy: 0.2054 - val_loss: 2.6117 - val_accuracy: 0.1863\n",
            "Epoch 11/500\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 2.5717 - accuracy: 0.2067 - val_loss: 2.6087 - val_accuracy: 0.1863\n",
            "Epoch 12/500\n",
            "25/25 [==============================] - 1s 43ms/step - loss: 2.5391 - accuracy: 0.2128 - val_loss: 2.6189 - val_accuracy: 0.1863\n",
            "Epoch 13/500\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 2.5627 - accuracy: 0.2025 - val_loss: 2.6060 - val_accuracy: 0.1863\n",
            "Epoch 14/500\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 2.5385 - accuracy: 0.2059 - val_loss: 2.6078 - val_accuracy: 0.1863\n",
            "Epoch 15/500\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 2.5504 - accuracy: 0.2056 - val_loss: 2.6222 - val_accuracy: 0.1863\n",
            "Epoch 16/500\n",
            "25/25 [==============================] - 1s 42ms/step - loss: 2.5468 - accuracy: 0.2078 - val_loss: 2.6052 - val_accuracy: 0.1863\n",
            "Epoch 17/500\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 2.5548 - accuracy: 0.2061 - val_loss: 2.6107 - val_accuracy: 0.1863\n",
            "Epoch 18/500\n",
            "25/25 [==============================] - 1s 42ms/step - loss: 2.5657 - accuracy: 0.2041 - val_loss: 2.6113 - val_accuracy: 0.1863\n",
            "Epoch 19/500\n",
            "25/25 [==============================] - 1s 40ms/step - loss: 2.5161 - accuracy: 0.2129 - val_loss: 2.6061 - val_accuracy: 0.1863\n",
            "Epoch 20/500\n",
            "25/25 [==============================] - 1s 42ms/step - loss: 2.5582 - accuracy: 0.2061 - val_loss: 2.6160 - val_accuracy: 0.1863\n",
            "Epoch 21/500\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 2.5587 - accuracy: 0.2120 - val_loss: 2.6125 - val_accuracy: 0.1863\n",
            "Epoch 22/500\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 2.5597 - accuracy: 0.2091 - val_loss: 2.6064 - val_accuracy: 0.1863\n",
            "Epoch 23/500\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 2.5465 - accuracy: 0.2082 - val_loss: 2.6139 - val_accuracy: 0.1863\n",
            "Epoch 24/500\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 2.5894 - accuracy: 0.1970 - val_loss: 2.6119 - val_accuracy: 0.1863\n",
            "Epoch 25/500\n",
            "25/25 [==============================] - 1s 40ms/step - loss: 2.5473 - accuracy: 0.2244 - val_loss: 2.6082 - val_accuracy: 0.1863\n",
            "Epoch 26/500\n",
            "25/25 [==============================] - 1s 40ms/step - loss: 2.5669 - accuracy: 0.2020 - val_loss: 2.6169 - val_accuracy: 0.1863\n",
            "Epoch 27/500\n",
            "25/25 [==============================] - 1s 40ms/step - loss: 2.5703 - accuracy: 0.2067 - val_loss: 2.6069 - val_accuracy: 0.1863\n",
            "Epoch 28/500\n",
            "25/25 [==============================] - 1s 40ms/step - loss: 2.5503 - accuracy: 0.2032 - val_loss: 2.6149 - val_accuracy: 0.1863\n",
            "Epoch 29/500\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 2.5479 - accuracy: 0.2114 - val_loss: 2.6090 - val_accuracy: 0.1863\n",
            "Epoch 30/500\n",
            "25/25 [==============================] - 1s 43ms/step - loss: 2.5408 - accuracy: 0.2035 - val_loss: 2.6107 - val_accuracy: 0.1863\n",
            "Epoch 31/500\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 2.5462 - accuracy: 0.2059 - val_loss: 2.6051 - val_accuracy: 0.1863\n",
            "Epoch 32/500\n",
            "25/25 [==============================] - 1s 42ms/step - loss: 2.5504 - accuracy: 0.1982 - val_loss: 2.6097 - val_accuracy: 0.1863\n",
            "Epoch 33/500\n",
            "25/25 [==============================] - 1s 42ms/step - loss: 2.5583 - accuracy: 0.2099 - val_loss: 2.6097 - val_accuracy: 0.1863\n",
            "Epoch 34/500\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 2.5253 - accuracy: 0.2160 - val_loss: 2.6019 - val_accuracy: 0.1863\n",
            "Epoch 35/500\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 2.5169 - accuracy: 0.2065 - val_loss: 2.5923 - val_accuracy: 0.1863\n",
            "Epoch 36/500\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 2.5223 - accuracy: 0.2082 - val_loss: 2.5532 - val_accuracy: 0.1863\n",
            "Epoch 37/500\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 2.4530 - accuracy: 0.2430 - val_loss: 2.4968 - val_accuracy: 0.2336\n",
            "Epoch 38/500\n",
            "25/25 [==============================] - 1s 40ms/step - loss: 2.4057 - accuracy: 0.2561 - val_loss: 2.4385 - val_accuracy: 0.2490\n",
            "Epoch 39/500\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 2.3693 - accuracy: 0.2676 - val_loss: 2.4122 - val_accuracy: 0.2587\n",
            "Epoch 40/500\n",
            "25/25 [==============================] - 1s 42ms/step - loss: 2.3356 - accuracy: 0.2890 - val_loss: 2.4030 - val_accuracy: 0.2568\n",
            "Epoch 41/500\n",
            "25/25 [==============================] - 1s 42ms/step - loss: 2.3270 - accuracy: 0.2845 - val_loss: 2.3826 - val_accuracy: 0.2722\n",
            "Epoch 42/500\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 2.3262 - accuracy: 0.2773 - val_loss: 2.3740 - val_accuracy: 0.2616\n",
            "Epoch 43/500\n",
            "25/25 [==============================] - 1s 40ms/step - loss: 2.2812 - accuracy: 0.3026 - val_loss: 2.3624 - val_accuracy: 0.3176\n",
            "Epoch 44/500\n",
            "25/25 [==============================] - 1s 42ms/step - loss: 2.2971 - accuracy: 0.3027 - val_loss: 2.3605 - val_accuracy: 0.2635\n",
            "Epoch 45/500\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 2.3120 - accuracy: 0.2828 - val_loss: 2.3858 - val_accuracy: 0.2490\n",
            "Epoch 46/500\n",
            "25/25 [==============================] - 1s 42ms/step - loss: 2.3123 - accuracy: 0.2918 - val_loss: 2.3472 - val_accuracy: 0.2616\n",
            "Epoch 47/500\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 2.2925 - accuracy: 0.2842 - val_loss: 2.3383 - val_accuracy: 0.3050\n",
            "Epoch 48/500\n",
            "25/25 [==============================] - 1s 40ms/step - loss: 2.2747 - accuracy: 0.3181 - val_loss: 2.3294 - val_accuracy: 0.3050\n",
            "Epoch 49/500\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 2.2678 - accuracy: 0.3186 - val_loss: 2.3215 - val_accuracy: 0.2992\n",
            "Epoch 50/500\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 2.2702 - accuracy: 0.3044 - val_loss: 2.2968 - val_accuracy: 0.3012\n",
            "Epoch 51/500\n",
            "25/25 [==============================] - 1s 40ms/step - loss: 2.1928 - accuracy: 0.3607 - val_loss: 2.2486 - val_accuracy: 0.3542\n",
            "Epoch 52/500\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 2.1397 - accuracy: 0.3574 - val_loss: 2.2144 - val_accuracy: 0.3591\n",
            "Epoch 53/500\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 2.1327 - accuracy: 0.3649 - val_loss: 2.1365 - val_accuracy: 0.3398\n",
            "Epoch 54/500\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 2.0609 - accuracy: 0.3708 - val_loss: 2.1136 - val_accuracy: 0.3292\n",
            "Epoch 55/500\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 1.9525 - accuracy: 0.3823 - val_loss: 2.0717 - val_accuracy: 0.3407\n",
            "Epoch 56/500\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 1.9902 - accuracy: 0.3790 - val_loss: 2.0455 - val_accuracy: 0.3407\n",
            "Epoch 57/500\n",
            "25/25 [==============================] - 1s 40ms/step - loss: 1.9737 - accuracy: 0.3651 - val_loss: 2.0233 - val_accuracy: 0.3388\n",
            "Epoch 58/500\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 1.9389 - accuracy: 0.3648 - val_loss: 2.0110 - val_accuracy: 0.3436\n",
            "Epoch 59/500\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 1.9230 - accuracy: 0.3885 - val_loss: 2.0044 - val_accuracy: 0.3465\n",
            "Epoch 60/500\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 1.9108 - accuracy: 0.3618 - val_loss: 1.9889 - val_accuracy: 0.3378\n",
            "Epoch 61/500\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 1.8857 - accuracy: 0.3742 - val_loss: 1.9836 - val_accuracy: 0.3407\n",
            "Epoch 62/500\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 1.8858 - accuracy: 0.3810 - val_loss: 1.9895 - val_accuracy: 0.3349\n",
            "Epoch 63/500\n",
            "25/25 [==============================] - 1s 42ms/step - loss: 1.9043 - accuracy: 0.3799 - val_loss: 1.9695 - val_accuracy: 0.3600\n",
            "Epoch 64/500\n",
            "25/25 [==============================] - 1s 40ms/step - loss: 1.8655 - accuracy: 0.3787 - val_loss: 1.9685 - val_accuracy: 0.3407\n",
            "Epoch 65/500\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 1.8625 - accuracy: 0.3762 - val_loss: 1.9748 - val_accuracy: 0.3485\n",
            "Epoch 66/500\n",
            "25/25 [==============================] - 1s 40ms/step - loss: 1.8719 - accuracy: 0.3735 - val_loss: 1.9867 - val_accuracy: 0.3301\n",
            "Epoch 67/500\n",
            "25/25 [==============================] - 1s 42ms/step - loss: 1.9000 - accuracy: 0.3818 - val_loss: 1.9716 - val_accuracy: 0.3465\n",
            "Epoch 68/500\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 1.8899 - accuracy: 0.3759 - val_loss: 1.9624 - val_accuracy: 0.3552\n",
            "Epoch 69/500\n",
            "25/25 [==============================] - 1s 42ms/step - loss: 1.8632 - accuracy: 0.3846 - val_loss: 1.9690 - val_accuracy: 0.3407\n",
            "Epoch 70/500\n",
            "25/25 [==============================] - 1s 42ms/step - loss: 1.8974 - accuracy: 0.3853 - val_loss: 1.9728 - val_accuracy: 0.3465\n",
            "Epoch 71/500\n",
            "25/25 [==============================] - 1s 40ms/step - loss: 1.8747 - accuracy: 0.3715 - val_loss: 1.9750 - val_accuracy: 0.3369\n",
            "Epoch 72/500\n",
            "25/25 [==============================] - 1s 42ms/step - loss: 1.8692 - accuracy: 0.3779 - val_loss: 1.9766 - val_accuracy: 0.3485\n",
            "Epoch 73/500\n",
            "25/25 [==============================] - 1s 40ms/step - loss: 1.8598 - accuracy: 0.3850 - val_loss: 1.9604 - val_accuracy: 0.3417\n",
            "Epoch 74/500\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 1.8657 - accuracy: 0.3719 - val_loss: 1.9597 - val_accuracy: 0.3542\n",
            "Epoch 75/500\n",
            "25/25 [==============================] - 1s 40ms/step - loss: 1.8544 - accuracy: 0.3722 - val_loss: 1.9654 - val_accuracy: 0.3591\n",
            "Epoch 76/500\n",
            "25/25 [==============================] - 1s 40ms/step - loss: 1.8678 - accuracy: 0.3825 - val_loss: 1.9634 - val_accuracy: 0.3446\n",
            "Epoch 77/500\n",
            "25/25 [==============================] - 1s 42ms/step - loss: 1.8435 - accuracy: 0.3890 - val_loss: 1.9617 - val_accuracy: 0.3456\n",
            "Epoch 78/500\n",
            "25/25 [==============================] - 1s 43ms/step - loss: 1.8538 - accuracy: 0.3814 - val_loss: 1.9643 - val_accuracy: 0.3600\n",
            "Epoch 79/500\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 1.8180 - accuracy: 0.3957 - val_loss: 1.9668 - val_accuracy: 0.3610\n",
            "Epoch 80/500\n",
            "25/25 [==============================] - 1s 42ms/step - loss: 1.8489 - accuracy: 0.3941 - val_loss: 1.9632 - val_accuracy: 0.3581\n",
            "Epoch 81/500\n",
            "25/25 [==============================] - 1s 42ms/step - loss: 1.8398 - accuracy: 0.3916 - val_loss: 1.9647 - val_accuracy: 0.3427\n",
            "Epoch 82/500\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 1.8716 - accuracy: 0.3911 - val_loss: 1.9725 - val_accuracy: 0.3562\n",
            "Epoch 83/500\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 1.8465 - accuracy: 0.4015 - val_loss: 1.9627 - val_accuracy: 0.3552\n",
            "Epoch 84/500\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 1.8704 - accuracy: 0.3787 - val_loss: 1.9669 - val_accuracy: 0.3552\n",
            "Epoch 85/500\n",
            "25/25 [==============================] - 1s 40ms/step - loss: 1.8153 - accuracy: 0.3967 - val_loss: 1.9712 - val_accuracy: 0.3427\n",
            "Epoch 86/500\n",
            "25/25 [==============================] - 1s 40ms/step - loss: 1.8778 - accuracy: 0.3793 - val_loss: 1.9728 - val_accuracy: 0.3591\n",
            "Epoch 87/500\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 1.8732 - accuracy: 0.3834 - val_loss: 1.9614 - val_accuracy: 0.3581\n",
            "Epoch 88/500\n",
            "25/25 [==============================] - 1s 40ms/step - loss: 1.8129 - accuracy: 0.3995 - val_loss: 1.9679 - val_accuracy: 0.3552\n",
            "Epoch 89/500\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 1.8420 - accuracy: 0.3941 - val_loss: 1.9660 - val_accuracy: 0.3581\n",
            "Epoch 90/500\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 1.8508 - accuracy: 0.3981 - val_loss: 1.9647 - val_accuracy: 0.3571\n",
            "Epoch 91/500\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 1.8580 - accuracy: 0.3979 - val_loss: 1.9648 - val_accuracy: 0.3562\n",
            "Epoch 92/500\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 1.8236 - accuracy: 0.3957 - val_loss: 1.9648 - val_accuracy: 0.3571\n",
            "Epoch 93/500\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 1.8024 - accuracy: 0.3993 - val_loss: 1.9621 - val_accuracy: 0.3571\n",
            "Epoch 94/500\n",
            "25/25 [==============================] - 1s 39ms/step - loss: 1.8423 - accuracy: 0.4030 - val_loss: 1.9629 - val_accuracy: 0.3581\n",
            "Epoch 95/500\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 1.8606 - accuracy: 0.3914 - val_loss: 1.9626 - val_accuracy: 0.3571\n",
            "Epoch 96/500\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 1.8378 - accuracy: 0.3837 - val_loss: 1.9698 - val_accuracy: 0.3562\n",
            "Epoch 97/500\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 1.8184 - accuracy: 0.3960 - val_loss: 1.9656 - val_accuracy: 0.3533\n",
            "Epoch 98/500\n",
            "25/25 [==============================] - 1s 42ms/step - loss: 1.8558 - accuracy: 0.3846 - val_loss: 1.9621 - val_accuracy: 0.3562\n",
            "Epoch 99/500\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 1.8303 - accuracy: 0.3992 - val_loss: 1.9709 - val_accuracy: 0.3533\n",
            "Epoch 100/500\n",
            "25/25 [==============================] - 1s 40ms/step - loss: 1.8442 - accuracy: 0.3896 - val_loss: 1.9656 - val_accuracy: 0.3533\n",
            "Epoch 101/500\n",
            "25/25 [==============================] - 1s 42ms/step - loss: 1.8476 - accuracy: 0.3809 - val_loss: 1.9681 - val_accuracy: 0.3581\n",
            "Epoch 102/500\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 1.8315 - accuracy: 0.3989 - val_loss: 1.9725 - val_accuracy: 0.3581\n",
            "Epoch 103/500\n",
            "25/25 [==============================] - 1s 42ms/step - loss: 1.8276 - accuracy: 0.3862 - val_loss: 1.9627 - val_accuracy: 0.3571\n",
            "Epoch 104/500\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 1.8395 - accuracy: 0.3945 - val_loss: 1.9703 - val_accuracy: 0.3542\n",
            "Epoch 105/500\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 1.8187 - accuracy: 0.3997 - val_loss: 1.9621 - val_accuracy: 0.3591\n",
            "Epoch 106/500\n",
            "25/25 [==============================] - 1s 42ms/step - loss: 1.8142 - accuracy: 0.4017 - val_loss: 1.9717 - val_accuracy: 0.3571\n",
            "Epoch 107/500\n",
            "25/25 [==============================] - 1s 42ms/step - loss: 1.8225 - accuracy: 0.3946 - val_loss: 1.9623 - val_accuracy: 0.3591\n",
            "Epoch 108/500\n",
            "25/25 [==============================] - 1s 43ms/step - loss: 1.8043 - accuracy: 0.3992 - val_loss: 1.9672 - val_accuracy: 0.3591\n",
            "Epoch 109/500\n",
            "25/25 [==============================] - 1s 43ms/step - loss: 1.7999 - accuracy: 0.3941 - val_loss: 1.9649 - val_accuracy: 0.3562\n",
            "Epoch 110/500\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 1.8476 - accuracy: 0.3816 - val_loss: 1.9714 - val_accuracy: 0.3581\n",
            "Epoch 111/500\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 1.8146 - accuracy: 0.4061 - val_loss: 1.9677 - val_accuracy: 0.3600\n",
            "Epoch 112/500\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 1.8501 - accuracy: 0.3854 - val_loss: 1.9664 - val_accuracy: 0.3571\n",
            "Epoch 113/500\n",
            "25/25 [==============================] - 1s 39ms/step - loss: 1.8207 - accuracy: 0.3947 - val_loss: 1.9640 - val_accuracy: 0.3591\n",
            "Epoch 114/500\n",
            "25/25 [==============================] - 1s 42ms/step - loss: 1.8221 - accuracy: 0.4001 - val_loss: 1.9688 - val_accuracy: 0.3523\n",
            "Epoch 115/500\n",
            "25/25 [==============================] - 1s 44ms/step - loss: 1.8129 - accuracy: 0.3938 - val_loss: 1.9676 - val_accuracy: 0.3591\n",
            "Epoch 116/500\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 1.8157 - accuracy: 0.3882 - val_loss: 1.9673 - val_accuracy: 0.3620\n",
            "Epoch 117/500\n",
            "25/25 [==============================] - 1s 40ms/step - loss: 1.8348 - accuracy: 0.3856 - val_loss: 1.9661 - val_accuracy: 0.3600\n",
            "Epoch 118/500\n",
            "25/25 [==============================] - 1s 40ms/step - loss: 1.8058 - accuracy: 0.3958 - val_loss: 1.9709 - val_accuracy: 0.3571\n",
            "Epoch 119/500\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 1.8493 - accuracy: 0.3796 - val_loss: 1.9602 - val_accuracy: 0.3600\n",
            "Epoch 120/500\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 1.7881 - accuracy: 0.4054 - val_loss: 1.9635 - val_accuracy: 0.3600\n",
            "Epoch 121/500\n",
            "25/25 [==============================] - 1s 42ms/step - loss: 1.8267 - accuracy: 0.3938 - val_loss: 1.9652 - val_accuracy: 0.3523\n",
            "Epoch 122/500\n",
            "25/25 [==============================] - 1s 42ms/step - loss: 1.8039 - accuracy: 0.4056 - val_loss: 1.9745 - val_accuracy: 0.3552\n",
            "Epoch 123/500\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 1.7941 - accuracy: 0.3945 - val_loss: 1.9611 - val_accuracy: 0.3610\n",
            "Epoch 124/500\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 1.7986 - accuracy: 0.4118 - val_loss: 1.9649 - val_accuracy: 0.3591\n",
            "\u001b[1;37m2021-03-24 12:46:53 [INFO] Model Accuracy on test: 38.22%, Loss: 1.93\u001b[0m\n",
            "\u001b[1;37m2021-03-24 12:46:53 [INFO] 保存模型：result/model/lstm/myspace_part.h5\u001b[0m\n",
            "\u001b[1;37m2021-03-24 12:46:54 [INFO] TensorBoard 日志：logs/lstm/myspace_part210324124439\u001b[0m\n",
            "\u001b[1;37m2021-03-24 12:46:54 [INFO] ************************************************完成训练LSTM模型************************************************\u001b[0m\n",
            "\u001b[1;37m2021-03-24 12:46:54 [INFO] 开始加载编码后的密码数据：result/preprocessed/wordlist/phpbb_part.txt\u001b[0m\n",
            "\u001b[1;37m2021-03-24 12:46:54 [INFO] 开始加载tokenizer模型：result/model/tokenizer/phpbb_part.pkl\u001b[0m\n",
            "\u001b[1;37m2021-03-24 12:46:54 [INFO] 将编码后的密码转换为（整数）序列\u001b[0m\n",
            "\u001b[1;37m2021-03-24 12:46:54 [INFO] Total Sequences: 10311\u001b[0m\n",
            "\u001b[1;37m2021-03-24 12:46:54 [INFO] 创建LSTM模型的输入输出\u001b[0m\n",
            "\u001b[1;37m2021-03-24 12:46:54 [INFO] X Shape: (10311, 19), y Shape: (10311,)\u001b[0m\n",
            "\u001b[1;37m2021-03-24 12:46:54 [INFO] 划分训练集、验证集和测试集\u001b[0m\n",
            "\u001b[1;37m2021-03-24 12:46:54 [INFO] x_train Shape: (6186, 19), y_train Shape: (6186, 49)\u001b[0m\n",
            "\u001b[1;37m2021-03-24 12:46:54 [INFO] x_val Shape: (2062, 19), y_val Shape: (2062, 49)\u001b[0m\n",
            "\u001b[1;37m2021-03-24 12:46:54 [INFO] x_test Shape: (2063, 19), y_test Shape: (2063, 49)\u001b[0m\n",
            "\u001b[1;37m2021-03-24 12:46:54 [INFO] *************************************************创建LSTM模型*************************************************\u001b[0m\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 19, 10)            490       \n",
            "_________________________________________________________________\n",
            "lstm_9 (LSTM)                (None, 19, 32)            5504      \n",
            "_________________________________________________________________\n",
            "lstm_10 (LSTM)               (None, 19, 32)            8320      \n",
            "_________________________________________________________________\n",
            "lstm_11 (LSTM)               (None, 32)                8320      \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 49)                1617      \n",
            "=================================================================\n",
            "Total params: 25,307\n",
            "Trainable params: 25,307\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\u001b[1;37m2021-03-24 12:46:55 [INFO] 训练日志文件：logs/lstm/phpbb_part210324124655\u001b[0m\n",
            "2021-03-24 12:46:55.249980: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.\n",
            "2021-03-24 12:46:55.250043: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.\n",
            "2021-03-24 12:46:55.250093: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.\n",
            "\u001b[1;37m2021-03-24 12:46:55 [INFO] ************************************************开始训练LSTM模型************************************************\u001b[0m\n",
            "Epoch 1/500\n",
            " 1/49 [..............................] - ETA: 3:43 - loss: 3.8923 - accuracy: 0.0000e+002021-03-24 12:47:00.127921: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.\n",
            "2021-03-24 12:47:00.127996: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.\n",
            " 2/49 [>.............................] - ETA: 10s - loss: 3.8916 - accuracy: 0.0000e+00 2021-03-24 12:47:00.343133: I tensorflow/core/profiler/lib/profiler_session.cc:71] Profiler session collecting data.\n",
            "2021-03-24 12:47:00.380931: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.\n",
            "49/49 [==============================] - 8s 75ms/step - loss: 3.6446 - accuracy: 0.1512 - val_loss: 2.5681 - val_accuracy: 0.1823\n",
            "Epoch 2/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 2.5460 - accuracy: 0.1879 - val_loss: 2.4492 - val_accuracy: 0.1823\n",
            "Epoch 3/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 2.4501 - accuracy: 0.1759 - val_loss: 2.4348 - val_accuracy: 0.1823\n",
            "Epoch 4/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 2.4640 - accuracy: 0.1838 - val_loss: 2.4366 - val_accuracy: 0.1823\n",
            "Epoch 5/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 2.4456 - accuracy: 0.1989 - val_loss: 2.4324 - val_accuracy: 0.1823\n",
            "Epoch 6/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 2.4409 - accuracy: 0.1888 - val_loss: 2.4361 - val_accuracy: 0.1736\n",
            "Epoch 7/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 2.4428 - accuracy: 0.1861 - val_loss: 2.4309 - val_accuracy: 0.1823\n",
            "Epoch 8/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 2.4400 - accuracy: 0.1932 - val_loss: 2.4292 - val_accuracy: 0.1823\n",
            "Epoch 9/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 2.4565 - accuracy: 0.1942 - val_loss: 2.4348 - val_accuracy: 0.1717\n",
            "Epoch 10/500\n",
            "49/49 [==============================] - 2s 40ms/step - loss: 2.4720 - accuracy: 0.1799 - val_loss: 2.4292 - val_accuracy: 0.1823\n",
            "Epoch 11/500\n",
            "49/49 [==============================] - 2s 40ms/step - loss: 2.4497 - accuracy: 0.1894 - val_loss: 2.4391 - val_accuracy: 0.1823\n",
            "Epoch 12/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 2.4741 - accuracy: 0.1839 - val_loss: 2.4301 - val_accuracy: 0.1736\n",
            "Epoch 13/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 2.4407 - accuracy: 0.1857 - val_loss: 2.4299 - val_accuracy: 0.1823\n",
            "Epoch 14/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 2.4577 - accuracy: 0.1887 - val_loss: 2.4335 - val_accuracy: 0.1823\n",
            "Epoch 15/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 2.4363 - accuracy: 0.1960 - val_loss: 2.4316 - val_accuracy: 0.1823\n",
            "Epoch 16/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 2.4198 - accuracy: 0.1978 - val_loss: 2.4320 - val_accuracy: 0.1823\n",
            "Epoch 17/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 2.4404 - accuracy: 0.1902 - val_loss: 2.4331 - val_accuracy: 0.1823\n",
            "Epoch 18/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 2.4209 - accuracy: 0.1948 - val_loss: 2.4307 - val_accuracy: 0.1823\n",
            "Epoch 19/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 2.4349 - accuracy: 0.1925 - val_loss: 2.3554 - val_accuracy: 0.2532\n",
            "Epoch 20/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 2.3326 - accuracy: 0.2726 - val_loss: 2.0956 - val_accuracy: 0.3400\n",
            "Epoch 21/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 2.0852 - accuracy: 0.3197 - val_loss: 2.0090 - val_accuracy: 0.3497\n",
            "Epoch 22/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 2.0161 - accuracy: 0.3458 - val_loss: 1.9769 - val_accuracy: 0.3438\n",
            "Epoch 23/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 1.9641 - accuracy: 0.3512 - val_loss: 1.9483 - val_accuracy: 0.3453\n",
            "Epoch 24/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 1.9424 - accuracy: 0.3483 - val_loss: 1.9374 - val_accuracy: 0.3598\n",
            "Epoch 25/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 1.9347 - accuracy: 0.3597 - val_loss: 1.9129 - val_accuracy: 0.3666\n",
            "Epoch 26/500\n",
            "49/49 [==============================] - 2s 40ms/step - loss: 1.9391 - accuracy: 0.3560 - val_loss: 1.9041 - val_accuracy: 0.3972\n",
            "Epoch 27/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 1.8890 - accuracy: 0.3849 - val_loss: 1.8548 - val_accuracy: 0.4103\n",
            "Epoch 28/500\n",
            "49/49 [==============================] - 2s 40ms/step - loss: 1.8459 - accuracy: 0.4115 - val_loss: 1.8312 - val_accuracy: 0.4210\n",
            "Epoch 29/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 1.8262 - accuracy: 0.4193 - val_loss: 1.8190 - val_accuracy: 0.4350\n",
            "Epoch 30/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 1.8250 - accuracy: 0.4219 - val_loss: 1.8070 - val_accuracy: 0.4297\n",
            "Epoch 31/500\n",
            "49/49 [==============================] - 2s 40ms/step - loss: 1.8314 - accuracy: 0.4068 - val_loss: 1.8143 - val_accuracy: 0.4258\n",
            "Epoch 32/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.7876 - accuracy: 0.4264 - val_loss: 1.8071 - val_accuracy: 0.4229\n",
            "Epoch 33/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.8176 - accuracy: 0.4168 - val_loss: 1.7944 - val_accuracy: 0.4311\n",
            "Epoch 34/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 1.7814 - accuracy: 0.4324 - val_loss: 1.7983 - val_accuracy: 0.4321\n",
            "Epoch 35/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 1.7938 - accuracy: 0.4222 - val_loss: 1.7984 - val_accuracy: 0.4331\n",
            "Epoch 36/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.7888 - accuracy: 0.4219 - val_loss: 1.7966 - val_accuracy: 0.4316\n",
            "Epoch 37/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 1.7735 - accuracy: 0.4335 - val_loss: 1.7975 - val_accuracy: 0.4258\n",
            "Epoch 38/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.7879 - accuracy: 0.4243 - val_loss: 1.7878 - val_accuracy: 0.4370\n",
            "Epoch 39/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 1.7715 - accuracy: 0.4278 - val_loss: 1.7853 - val_accuracy: 0.4360\n",
            "Epoch 40/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 1.7843 - accuracy: 0.4305 - val_loss: 1.7858 - val_accuracy: 0.4370\n",
            "Epoch 41/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 1.7712 - accuracy: 0.4307 - val_loss: 1.7854 - val_accuracy: 0.4340\n",
            "Epoch 42/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.7668 - accuracy: 0.4275 - val_loss: 1.7867 - val_accuracy: 0.4287\n",
            "Epoch 43/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 1.7777 - accuracy: 0.4287 - val_loss: 1.7847 - val_accuracy: 0.4297\n",
            "Epoch 44/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 1.7566 - accuracy: 0.4302 - val_loss: 1.7825 - val_accuracy: 0.4360\n",
            "Epoch 45/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 1.7799 - accuracy: 0.4245 - val_loss: 1.7902 - val_accuracy: 0.4277\n",
            "Epoch 46/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 1.7743 - accuracy: 0.4254 - val_loss: 1.7811 - val_accuracy: 0.4355\n",
            "Epoch 47/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.7739 - accuracy: 0.4243 - val_loss: 1.7804 - val_accuracy: 0.4374\n",
            "Epoch 48/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.7865 - accuracy: 0.4293 - val_loss: 1.7823 - val_accuracy: 0.4331\n",
            "Epoch 49/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 1.7697 - accuracy: 0.4347 - val_loss: 1.7853 - val_accuracy: 0.4326\n",
            "Epoch 50/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 1.7561 - accuracy: 0.4455 - val_loss: 1.7774 - val_accuracy: 0.4321\n",
            "Epoch 51/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.7609 - accuracy: 0.4277 - val_loss: 1.7800 - val_accuracy: 0.4340\n",
            "Epoch 52/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.7748 - accuracy: 0.4276 - val_loss: 1.7763 - val_accuracy: 0.4374\n",
            "Epoch 53/500\n",
            "49/49 [==============================] - 2s 43ms/step - loss: 1.7651 - accuracy: 0.4212 - val_loss: 1.7861 - val_accuracy: 0.4273\n",
            "Epoch 54/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.7743 - accuracy: 0.4289 - val_loss: 1.7816 - val_accuracy: 0.4399\n",
            "Epoch 55/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.7729 - accuracy: 0.4275 - val_loss: 1.7743 - val_accuracy: 0.4384\n",
            "Epoch 56/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 1.7753 - accuracy: 0.4241 - val_loss: 1.7888 - val_accuracy: 0.4365\n",
            "Epoch 57/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.7712 - accuracy: 0.4302 - val_loss: 1.7740 - val_accuracy: 0.4394\n",
            "Epoch 58/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 1.7498 - accuracy: 0.4278 - val_loss: 1.8021 - val_accuracy: 0.4234\n",
            "Epoch 59/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.7697 - accuracy: 0.4192 - val_loss: 1.7797 - val_accuracy: 0.4331\n",
            "Epoch 60/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.7495 - accuracy: 0.4300 - val_loss: 1.7732 - val_accuracy: 0.4370\n",
            "Epoch 61/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.7516 - accuracy: 0.4270 - val_loss: 1.7813 - val_accuracy: 0.4253\n",
            "Epoch 62/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.7488 - accuracy: 0.4402 - val_loss: 1.7829 - val_accuracy: 0.4253\n",
            "Epoch 63/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 1.7580 - accuracy: 0.4365 - val_loss: 1.7728 - val_accuracy: 0.4345\n",
            "Epoch 64/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.7575 - accuracy: 0.4254 - val_loss: 1.7712 - val_accuracy: 0.4389\n",
            "Epoch 65/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 1.7637 - accuracy: 0.4277 - val_loss: 1.7760 - val_accuracy: 0.4408\n",
            "Epoch 66/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 1.7545 - accuracy: 0.4272 - val_loss: 1.7727 - val_accuracy: 0.4360\n",
            "Epoch 67/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.7646 - accuracy: 0.4235 - val_loss: 1.7739 - val_accuracy: 0.4374\n",
            "Epoch 68/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.7733 - accuracy: 0.4286 - val_loss: 1.7735 - val_accuracy: 0.4350\n",
            "Epoch 69/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.7423 - accuracy: 0.4290 - val_loss: 1.7707 - val_accuracy: 0.4321\n",
            "Epoch 70/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.7871 - accuracy: 0.4205 - val_loss: 1.7696 - val_accuracy: 0.4374\n",
            "Epoch 71/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 1.7585 - accuracy: 0.4263 - val_loss: 1.7700 - val_accuracy: 0.4379\n",
            "Epoch 72/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 1.7500 - accuracy: 0.4302 - val_loss: 1.7709 - val_accuracy: 0.4340\n",
            "Epoch 73/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.7579 - accuracy: 0.4245 - val_loss: 1.7691 - val_accuracy: 0.4384\n",
            "Epoch 74/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.7429 - accuracy: 0.4301 - val_loss: 1.7701 - val_accuracy: 0.4408\n",
            "Epoch 75/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.7526 - accuracy: 0.4383 - val_loss: 1.7736 - val_accuracy: 0.4297\n",
            "Epoch 76/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 1.7389 - accuracy: 0.4284 - val_loss: 1.7695 - val_accuracy: 0.4374\n",
            "Epoch 77/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.7674 - accuracy: 0.4235 - val_loss: 1.7700 - val_accuracy: 0.4302\n",
            "Epoch 78/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.7511 - accuracy: 0.4288 - val_loss: 1.7717 - val_accuracy: 0.4268\n",
            "Epoch 79/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.7216 - accuracy: 0.4356 - val_loss: 1.7760 - val_accuracy: 0.4287\n",
            "Epoch 80/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 1.7559 - accuracy: 0.4267 - val_loss: 1.7674 - val_accuracy: 0.4418\n",
            "Epoch 81/500\n",
            "49/49 [==============================] - 2s 40ms/step - loss: 1.7389 - accuracy: 0.4378 - val_loss: 1.7685 - val_accuracy: 0.4297\n",
            "Epoch 82/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.7424 - accuracy: 0.4347 - val_loss: 1.7677 - val_accuracy: 0.4403\n",
            "Epoch 83/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 1.7655 - accuracy: 0.4220 - val_loss: 1.7706 - val_accuracy: 0.4277\n",
            "Epoch 84/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.7300 - accuracy: 0.4359 - val_loss: 1.7704 - val_accuracy: 0.4263\n",
            "Epoch 85/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 1.7464 - accuracy: 0.4297 - val_loss: 1.7671 - val_accuracy: 0.4331\n",
            "Epoch 86/500\n",
            "49/49 [==============================] - 2s 44ms/step - loss: 1.7447 - accuracy: 0.4357 - val_loss: 1.7666 - val_accuracy: 0.4326\n",
            "Epoch 87/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 1.7205 - accuracy: 0.4331 - val_loss: 1.7696 - val_accuracy: 0.4379\n",
            "Epoch 88/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.7385 - accuracy: 0.4332 - val_loss: 1.7608 - val_accuracy: 0.4428\n",
            "Epoch 89/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 1.7405 - accuracy: 0.4385 - val_loss: 1.7601 - val_accuracy: 0.4355\n",
            "Epoch 90/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.7427 - accuracy: 0.4281 - val_loss: 1.7598 - val_accuracy: 0.4306\n",
            "Epoch 91/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.7531 - accuracy: 0.4316 - val_loss: 1.7570 - val_accuracy: 0.4423\n",
            "Epoch 92/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.7296 - accuracy: 0.4365 - val_loss: 1.7637 - val_accuracy: 0.4389\n",
            "Epoch 93/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.7237 - accuracy: 0.4357 - val_loss: 1.7591 - val_accuracy: 0.4365\n",
            "Epoch 94/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.7486 - accuracy: 0.4251 - val_loss: 1.7611 - val_accuracy: 0.4360\n",
            "Epoch 95/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 1.7026 - accuracy: 0.4437 - val_loss: 1.7631 - val_accuracy: 0.4302\n",
            "Epoch 96/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 1.7410 - accuracy: 0.4298 - val_loss: 1.7558 - val_accuracy: 0.4394\n",
            "Epoch 97/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 1.7457 - accuracy: 0.4316 - val_loss: 1.7903 - val_accuracy: 0.4263\n",
            "Epoch 98/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.7318 - accuracy: 0.4333 - val_loss: 1.7781 - val_accuracy: 0.4205\n",
            "Epoch 99/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 1.7603 - accuracy: 0.4137 - val_loss: 1.7597 - val_accuracy: 0.4292\n",
            "Epoch 100/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 1.7024 - accuracy: 0.4441 - val_loss: 1.7531 - val_accuracy: 0.4360\n",
            "Epoch 101/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.7247 - accuracy: 0.4395 - val_loss: 1.7643 - val_accuracy: 0.4263\n",
            "Epoch 102/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 1.7179 - accuracy: 0.4308 - val_loss: 1.7524 - val_accuracy: 0.4379\n",
            "Epoch 103/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.7193 - accuracy: 0.4336 - val_loss: 1.7540 - val_accuracy: 0.4370\n",
            "Epoch 104/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.7206 - accuracy: 0.4295 - val_loss: 1.7644 - val_accuracy: 0.4394\n",
            "Epoch 105/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.7087 - accuracy: 0.4384 - val_loss: 1.7619 - val_accuracy: 0.4394\n",
            "Epoch 106/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 1.7149 - accuracy: 0.4420 - val_loss: 1.7612 - val_accuracy: 0.4316\n",
            "Epoch 107/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 1.7220 - accuracy: 0.4334 - val_loss: 1.7574 - val_accuracy: 0.4248\n",
            "Epoch 108/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 1.7370 - accuracy: 0.4286 - val_loss: 1.7532 - val_accuracy: 0.4340\n",
            "Epoch 109/500\n",
            "49/49 [==============================] - 2s 43ms/step - loss: 1.7536 - accuracy: 0.4214 - val_loss: 1.7502 - val_accuracy: 0.4355\n",
            "Epoch 110/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.6949 - accuracy: 0.4370 - val_loss: 1.7463 - val_accuracy: 0.4336\n",
            "Epoch 111/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 1.6736 - accuracy: 0.4413 - val_loss: 1.7457 - val_accuracy: 0.4306\n",
            "Epoch 112/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 1.7161 - accuracy: 0.4279 - val_loss: 1.7455 - val_accuracy: 0.4394\n",
            "Epoch 113/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.7085 - accuracy: 0.4360 - val_loss: 1.7436 - val_accuracy: 0.4355\n",
            "Epoch 114/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.7116 - accuracy: 0.4374 - val_loss: 1.7546 - val_accuracy: 0.4253\n",
            "Epoch 115/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 1.7040 - accuracy: 0.4372 - val_loss: 1.7465 - val_accuracy: 0.4384\n",
            "Epoch 116/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 1.6985 - accuracy: 0.4402 - val_loss: 1.7434 - val_accuracy: 0.4277\n",
            "Epoch 117/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 1.6814 - accuracy: 0.4349 - val_loss: 1.7614 - val_accuracy: 0.4214\n",
            "Epoch 118/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 1.6828 - accuracy: 0.4416 - val_loss: 1.7549 - val_accuracy: 0.4277\n",
            "Epoch 119/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.7083 - accuracy: 0.4358 - val_loss: 1.7440 - val_accuracy: 0.4316\n",
            "Epoch 120/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 1.6887 - accuracy: 0.4370 - val_loss: 1.7394 - val_accuracy: 0.4331\n",
            "Epoch 121/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.6813 - accuracy: 0.4452 - val_loss: 1.7419 - val_accuracy: 0.4297\n",
            "Epoch 122/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 1.7017 - accuracy: 0.4355 - val_loss: 1.7415 - val_accuracy: 0.4437\n",
            "Epoch 123/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.6879 - accuracy: 0.4380 - val_loss: 1.7457 - val_accuracy: 0.4302\n",
            "Epoch 124/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.7010 - accuracy: 0.4286 - val_loss: 1.7334 - val_accuracy: 0.4413\n",
            "Epoch 125/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.7155 - accuracy: 0.4384 - val_loss: 1.7390 - val_accuracy: 0.4418\n",
            "Epoch 126/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.6945 - accuracy: 0.4416 - val_loss: 1.7545 - val_accuracy: 0.4321\n",
            "Epoch 127/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.7113 - accuracy: 0.4262 - val_loss: 1.7336 - val_accuracy: 0.4389\n",
            "Epoch 128/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.6991 - accuracy: 0.4361 - val_loss: 1.7350 - val_accuracy: 0.4394\n",
            "Epoch 129/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 1.6758 - accuracy: 0.4406 - val_loss: 1.7329 - val_accuracy: 0.4457\n",
            "Epoch 130/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.6660 - accuracy: 0.4534 - val_loss: 1.7384 - val_accuracy: 0.4340\n",
            "Epoch 131/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 1.6816 - accuracy: 0.4456 - val_loss: 1.7484 - val_accuracy: 0.4374\n",
            "Epoch 132/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.7181 - accuracy: 0.4277 - val_loss: 1.7343 - val_accuracy: 0.4408\n",
            "Epoch 133/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.6998 - accuracy: 0.4418 - val_loss: 1.7390 - val_accuracy: 0.4340\n",
            "Epoch 134/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.6929 - accuracy: 0.4338 - val_loss: 1.7352 - val_accuracy: 0.4447\n",
            "Epoch 135/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.6787 - accuracy: 0.4432 - val_loss: 1.7346 - val_accuracy: 0.4437\n",
            "Epoch 136/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.6873 - accuracy: 0.4353 - val_loss: 1.7335 - val_accuracy: 0.4384\n",
            "Epoch 137/500\n",
            "49/49 [==============================] - 2s 43ms/step - loss: 1.6872 - accuracy: 0.4347 - val_loss: 1.7350 - val_accuracy: 0.4379\n",
            "Epoch 138/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.6974 - accuracy: 0.4310 - val_loss: 1.7321 - val_accuracy: 0.4403\n",
            "Epoch 139/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.7069 - accuracy: 0.4327 - val_loss: 1.7352 - val_accuracy: 0.4403\n",
            "Epoch 140/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 1.6873 - accuracy: 0.4358 - val_loss: 1.7303 - val_accuracy: 0.4428\n",
            "Epoch 141/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.7020 - accuracy: 0.4405 - val_loss: 1.7331 - val_accuracy: 0.4442\n",
            "Epoch 142/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.6811 - accuracy: 0.4436 - val_loss: 1.7386 - val_accuracy: 0.4370\n",
            "Epoch 143/500\n",
            "49/49 [==============================] - 2s 43ms/step - loss: 1.6571 - accuracy: 0.4546 - val_loss: 1.7365 - val_accuracy: 0.4374\n",
            "Epoch 144/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.6859 - accuracy: 0.4392 - val_loss: 1.7417 - val_accuracy: 0.4316\n",
            "Epoch 145/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.6868 - accuracy: 0.4347 - val_loss: 1.7299 - val_accuracy: 0.4418\n",
            "Epoch 146/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 1.6891 - accuracy: 0.4436 - val_loss: 1.7373 - val_accuracy: 0.4437\n",
            "Epoch 147/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.6605 - accuracy: 0.4439 - val_loss: 1.7368 - val_accuracy: 0.4370\n",
            "Epoch 148/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.6914 - accuracy: 0.4370 - val_loss: 1.7332 - val_accuracy: 0.4389\n",
            "Epoch 149/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 1.6802 - accuracy: 0.4402 - val_loss: 1.7401 - val_accuracy: 0.4340\n",
            "Epoch 150/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 1.6728 - accuracy: 0.4535 - val_loss: 1.7500 - val_accuracy: 0.4413\n",
            "Epoch 151/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.6947 - accuracy: 0.4350 - val_loss: 1.7350 - val_accuracy: 0.4423\n",
            "Epoch 152/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.6785 - accuracy: 0.4326 - val_loss: 1.7374 - val_accuracy: 0.4462\n",
            "Epoch 153/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.7124 - accuracy: 0.4312 - val_loss: 1.7484 - val_accuracy: 0.4399\n",
            "Epoch 154/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.6810 - accuracy: 0.4367 - val_loss: 1.7353 - val_accuracy: 0.4433\n",
            "Epoch 155/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.6662 - accuracy: 0.4484 - val_loss: 1.7337 - val_accuracy: 0.4394\n",
            "Epoch 156/500\n",
            "49/49 [==============================] - 2s 43ms/step - loss: 1.6803 - accuracy: 0.4361 - val_loss: 1.7308 - val_accuracy: 0.4408\n",
            "Epoch 157/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.6834 - accuracy: 0.4439 - val_loss: 1.7346 - val_accuracy: 0.4379\n",
            "Epoch 158/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.6589 - accuracy: 0.4498 - val_loss: 1.7371 - val_accuracy: 0.4428\n",
            "Epoch 159/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.6611 - accuracy: 0.4481 - val_loss: 1.7354 - val_accuracy: 0.4423\n",
            "Epoch 160/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.6910 - accuracy: 0.4395 - val_loss: 1.7358 - val_accuracy: 0.4418\n",
            "Epoch 161/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.6818 - accuracy: 0.4422 - val_loss: 1.7407 - val_accuracy: 0.4321\n",
            "Epoch 162/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.6723 - accuracy: 0.4435 - val_loss: 1.7360 - val_accuracy: 0.4418\n",
            "Epoch 163/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.6485 - accuracy: 0.4452 - val_loss: 1.7414 - val_accuracy: 0.4389\n",
            "Epoch 164/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.6941 - accuracy: 0.4417 - val_loss: 1.7497 - val_accuracy: 0.4340\n",
            "Epoch 165/500\n",
            "49/49 [==============================] - 2s 43ms/step - loss: 1.6608 - accuracy: 0.4365 - val_loss: 1.7390 - val_accuracy: 0.4447\n",
            "Epoch 166/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.6678 - accuracy: 0.4459 - val_loss: 1.7348 - val_accuracy: 0.4360\n",
            "Epoch 167/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 1.6556 - accuracy: 0.4482 - val_loss: 1.7356 - val_accuracy: 0.4379\n",
            "Epoch 168/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.6851 - accuracy: 0.4384 - val_loss: 1.7381 - val_accuracy: 0.4423\n",
            "Epoch 169/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.6958 - accuracy: 0.4451 - val_loss: 1.7355 - val_accuracy: 0.4321\n",
            "Epoch 170/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 1.6837 - accuracy: 0.4307 - val_loss: 1.7345 - val_accuracy: 0.4413\n",
            "Epoch 171/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.6584 - accuracy: 0.4466 - val_loss: 1.7367 - val_accuracy: 0.4365\n",
            "Epoch 172/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.6688 - accuracy: 0.4458 - val_loss: 1.7360 - val_accuracy: 0.4403\n",
            "Epoch 173/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 1.7011 - accuracy: 0.4218 - val_loss: 1.7390 - val_accuracy: 0.4428\n",
            "Epoch 174/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 1.7061 - accuracy: 0.4358 - val_loss: 1.7343 - val_accuracy: 0.4423\n",
            "Epoch 175/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 1.6962 - accuracy: 0.4348 - val_loss: 1.7329 - val_accuracy: 0.4389\n",
            "Epoch 176/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 1.6559 - accuracy: 0.4450 - val_loss: 1.7453 - val_accuracy: 0.4321\n",
            "Epoch 177/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.6926 - accuracy: 0.4402 - val_loss: 1.7423 - val_accuracy: 0.4311\n",
            "Epoch 178/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.6809 - accuracy: 0.4353 - val_loss: 1.7418 - val_accuracy: 0.4336\n",
            "Epoch 179/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.6948 - accuracy: 0.4339 - val_loss: 1.7407 - val_accuracy: 0.4394\n",
            "Epoch 180/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 1.6646 - accuracy: 0.4415 - val_loss: 1.7374 - val_accuracy: 0.4336\n",
            "Epoch 181/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.6940 - accuracy: 0.4235 - val_loss: 1.7330 - val_accuracy: 0.4428\n",
            "Epoch 182/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.6755 - accuracy: 0.4323 - val_loss: 1.7475 - val_accuracy: 0.4355\n",
            "Epoch 183/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 1.6808 - accuracy: 0.4400 - val_loss: 1.7410 - val_accuracy: 0.4389\n",
            "Epoch 184/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.6811 - accuracy: 0.4356 - val_loss: 1.7417 - val_accuracy: 0.4345\n",
            "Epoch 185/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.6725 - accuracy: 0.4383 - val_loss: 1.7394 - val_accuracy: 0.4331\n",
            "Epoch 186/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 1.6730 - accuracy: 0.4406 - val_loss: 1.7335 - val_accuracy: 0.4360\n",
            "Epoch 187/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 1.6934 - accuracy: 0.4261 - val_loss: 1.7526 - val_accuracy: 0.4292\n",
            "Epoch 188/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.6613 - accuracy: 0.4427 - val_loss: 1.7476 - val_accuracy: 0.4287\n",
            "Epoch 189/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 1.6705 - accuracy: 0.4342 - val_loss: 1.7422 - val_accuracy: 0.4345\n",
            "Epoch 190/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.6828 - accuracy: 0.4377 - val_loss: 1.7363 - val_accuracy: 0.4365\n",
            "Epoch 191/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.6596 - accuracy: 0.4443 - val_loss: 1.7447 - val_accuracy: 0.4326\n",
            "Epoch 192/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 1.6985 - accuracy: 0.4382 - val_loss: 1.7372 - val_accuracy: 0.4384\n",
            "Epoch 193/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.7108 - accuracy: 0.4270 - val_loss: 1.7387 - val_accuracy: 0.4374\n",
            "Epoch 194/500\n",
            "49/49 [==============================] - 2s 43ms/step - loss: 1.6582 - accuracy: 0.4482 - val_loss: 1.7372 - val_accuracy: 0.4355\n",
            "Epoch 195/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 1.6782 - accuracy: 0.4412 - val_loss: 1.7420 - val_accuracy: 0.4374\n",
            "\u001b[1;37m2021-03-24 12:53:38 [INFO] Model Accuracy on test: 41.44%, Loss: 1.80\u001b[0m\n",
            "\u001b[1;37m2021-03-24 12:53:38 [INFO] 保存模型：result/model/lstm/phpbb_part.h5\u001b[0m\n",
            "\u001b[1;37m2021-03-24 12:53:39 [INFO] TensorBoard 日志：logs/lstm/phpbb_part210324124655\u001b[0m\n",
            "\u001b[1;37m2021-03-24 12:53:39 [INFO] ************************************************完成训练LSTM模型************************************************\u001b[0m\n",
            "\u001b[1;37m2021-03-24 12:53:39 [INFO] End...\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYdgdH0kwUHz"
      },
      "source": [
        "## 训练char-level CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7yH2xi2uA5V",
        "outputId": "42811d49-c0fa-44a0-a8a6-fc95e6a4bb1b"
      },
      "source": [
        "!python main.py \\\n",
        "    -e pro \\\n",
        "    --train \\\n",
        "    --model cnn \\\n",
        "    --dnames myspace phpbb"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-03-24 13:22:18.775391: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[1;37m2021-03-24 13:22:20 [INFO] \n",
            "##########################################################################################################\n",
            "# GENPass\n",
            "# 1 PL模型预测。预测密码中的下一个单元（unit）。\n",
            "# 2 权重选择。按照权重选择从3个PL模型的结果中选择权重最高的unit，并根据wordlist随机选择一个密码进行替换。\n",
            "# 3 分类器。使用CNN模型预测上一步生成的密码属于3个数据集的概率。\n",
            "# 4 判定器。选择出在3个数据集概率相差不大的密码作为结果输出。\n",
            "#\n",
            "##########################################################################################################\n",
            "\u001b[0m\n",
            "\u001b[1;37m2021-03-24 13:22:20 [INFO] Start...\u001b[0m\n",
            "\u001b[1;37m2021-03-24 13:22:20 [INFO] 开始加载数据...\u001b[0m\n",
            "\u001b[1;37m2021-03-24 13:22:20 [INFO] dataset/myspace.txt 数据大小：37144\u001b[0m\n",
            "\u001b[1;37m2021-03-24 13:22:20 [INFO] dataset/phpbb.txt 数据大小：184379\u001b[0m\n",
            "\u001b[1;37m2021-03-24 13:22:20 [INFO] 训练模型的总数据量：77144\u001b[0m\n",
            "\u001b[1;37m2021-03-24 13:22:20 [INFO] 划分验证集和测试集\u001b[0m\n",
            "\u001b[1;37m2021-03-24 13:22:21 [INFO] x_val Shape: (15428, 100), y_val Shape: (15428, 2)\u001b[0m\n",
            "\u001b[1;37m2021-03-24 13:22:21 [INFO] x_test Shape: (15428, 100), y_test Shape: (15428, 2)\u001b[0m\n",
            "\u001b[1;37m2021-03-24 13:22:21 [INFO] 创建CNN模型...\u001b[0m\n",
            "2021-03-24 13:22:21.109872: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2021-03-24 13:22:21.111016: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
            "2021-03-24 13:22:21.123658: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2021-03-24 13:22:21.123724: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (f70d36e0f51d): /proc/driver/nvidia/version does not exist\n",
            "2021-03-24 13:22:21.124303: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "\u001b[1;37m2021-03-24 13:22:21 [INFO] 创建模型：\u001b[0m\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 100, 50)           3550      \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 100, 256)          89856     \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 33, 256)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 33, 256)           459008    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 11, 256)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 11, 256)           196864    \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 11, 256)           196864    \n",
            "_________________________________________________________________\n",
            "conv1d_4 (Conv1D)            (None, 11, 256)           196864    \n",
            "_________________________________________________________________\n",
            "conv1d_5 (Conv1D)            (None, 11, 256)           196864    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 3, 256)            0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 768)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1024)              787456    \n",
            "_________________________________________________________________\n",
            "alpha_dropout (AlphaDropout) (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1024)              1049600   \n",
            "_________________________________________________________________\n",
            "alpha_dropout_1 (AlphaDropou (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 2)                 2050      \n",
            "=================================================================\n",
            "Total params: 3,178,976\n",
            "Trainable params: 3,178,976\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\u001b[1;37m2021-03-24 13:22:21 [INFO] 开始训练CNN模型\u001b[0m\n",
            "\u001b[1;37m2021-03-24 13:22:21 [INFO] 训练日志文件：logs/cnn/cnn210324132221\u001b[0m\n",
            "2021-03-24 13:22:21.360362: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.\n",
            "2021-03-24 13:22:21.360425: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.\n",
            "2021-03-24 13:22:21.369949: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.\n",
            "\u001b[1;37m2021-03-24 13:22:21 [INFO] 生成数据...\u001b[0m\n",
            "2021-03-24 13:22:21.426454: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
            "2021-03-24 13:22:21.426923: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2299995000 Hz\n",
            "Epoch 1/10\n",
            "  1/602 [..............................] - ETA: 19:18 - loss: 1.1682 - accuracy: 0.51562021-03-24 13:22:23.387055: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.\n",
            "2021-03-24 13:22:23.387148: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.\n",
            "  2/602 [..............................] - ETA: 9:11 - loss: 1.1446 - accuracy: 0.5293 2021-03-24 13:22:24.282558: I tensorflow/core/profiler/lib/profiler_session.cc:71] Profiler session collecting data.\n",
            "2021-03-24 13:22:24.284237: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.\n",
            "602/602 [==============================] - 338s 559ms/step - loss: 0.6902 - accuracy: 0.6862 - val_loss: 0.7010 - val_accuracy: 0.7737\n",
            "Epoch 2/10\n",
            " 27/602 [>.............................] - ETA: 8:16 - loss: 0.4654 - accuracy: 0.8013Traceback (most recent call last):\n",
            "  File \"main.py\", line 104, in <module>\n",
            "    main()\n",
            "  File \"main.py\", line 97, in main\n",
            "    char_cnn.create_and_train_model()\n",
            "  File \"/content/drive/My Drive/gen_pass/src/neural_network/classifier.py\", line 254, in create_and_train_model\n",
            "    callbacks=[tensorboard])\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\", line 1100, in fit\n",
            "    tmp_logs = self.train_function(iterator)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\", line 828, in __call__\n",
            "    result = self._call(*args, **kwds)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\", line 855, in _call\n",
            "    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\", line 2943, in __call__\n",
            "    filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\", line 1919, in _call_flat\n",
            "    ctx, args, cancellation_manager=cancellation_manager))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\", line 560, in call\n",
            "    ctx=ctx)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\", line 60, in quick_execute\n",
            "    inputs, attrs, num_outputs)\n",
            "KeyboardInterrupt\n",
            "2021-03-24 13:28:23.769163: W tensorflow/core/kernels/data/generator_dataset_op.cc:107] Error occurred when finalizing GeneratorDataset iterator: Failed precondition: Python interpreter state is not initialized. The process may be terminated.\n",
            "\t [[{{node PyFunc}}]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yU47aUJIE1cz"
      },
      "source": [
        "## 生成密码"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8gjzrA_FGsN"
      },
      "source": [
        "!python main.py \\\n",
        "  --generate genpass \\\n",
        "  -c 0.2 \\\n",
        "  --alphas 6 \\\n",
        "  --chunk 100000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b993O7PPJnCt",
        "outputId": "193def1b-14aa-45a3-838b-71811f23c3ea"
      },
      "source": [
        "!python main.py \\\n",
        "  --generate pl \\\n",
        "  --dnames myspace phpbb myspace_part phpbb_part\\\n",
        "  --alphas 6 \\\n",
        "  --chunk 100000"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-03-25 07:44:25.651283: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[1;37m2021-03-25 07:44:27 [INFO] \n",
            "##########################################################################################################\n",
            "# GENPass\n",
            "# 1 PL模型预测。预测密码中的下一个单元（unit）。\n",
            "# 2 权重选择。按照权重选择从3个PL模型的结果中选择权重最高的unit，并根据wordlist随机选择一个密码进行替换。\n",
            "# 3 分类器。使用CNN模型预测上一步生成的密码属于3个数据集的概率。\n",
            "# 4 判定器。选择出在3个数据集概率相差不大的密码作为结果输出。\n",
            "#\n",
            "##########################################################################################################\n",
            "\u001b[0m\n",
            "\u001b[1;37m2021-03-25 07:44:27 [INFO] Start...\u001b[0m\n",
            "\u001b[1;37m2021-03-25 07:44:27 [INFO] 使用 myspace PL模型生成密码\u001b[0m\n",
            "\u001b[1;37m2021-03-25 07:44:27 [INFO] 创建PL模型。数据集名称：myspace\u001b[0m\n",
            "2021-03-25 07:44:27.733464: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2021-03-25 07:44:27.734616: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
            "2021-03-25 07:44:27.746518: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2021-03-25 07:44:27.746574: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (f24462cf026b): /proc/driver/nvidia/version does not exist\n",
            "2021-03-25 07:44:27.747166: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "\u001b[1;37m2021-03-25 07:44:28 [INFO] 待生成密码数量：1,000,000\u001b[0m\n",
            "2021-03-25 07:44:28.927988: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
            "2021-03-25 07:44:28.928511: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2299995000 Hz\n",
            "\u001b[1;37m2021-03-25 07:48:48 [INFO] 生成好的 1,000,000 个密码保存到文件：result/predict/pl/cross/myspace_6_210325074848.txt\u001b[0m\n",
            "\u001b[1;37m2021-03-25 07:53:11 [INFO] 生成好的 1,000,000 个密码保存到文件：result/predict/pl/cross/myspace_6_210325075311.txt\u001b[0m\n",
            "\u001b[1;37m2021-03-25 07:57:31 [INFO] 生成好的 1,000,000 个密码保存到文件：result/predict/pl/cross/myspace_6_210325075731.txt\u001b[0m\n",
            "\u001b[1;37m2021-03-25 08:02:00 [INFO] 生成好的 1,000,000 个密码保存到文件：result/predict/pl/cross/myspace_6_210325080200.txt\u001b[0m\n",
            "\u001b[1;37m2021-03-25 08:06:29 [INFO] 生成好的 1,000,000 个密码保存到文件：result/predict/pl/cross/myspace_6_210325080629.txt\u001b[0m\n",
            "\u001b[1;37m2021-03-25 08:10:56 [INFO] 生成好的 1,000,000 个密码保存到文件：result/predict/pl/cross/myspace_6_210325081056.txt\u001b[0m\n",
            "\u001b[1;37m2021-03-25 08:15:34 [INFO] 生成好的 1,000,000 个密码保存到文件：result/predict/pl/cross/myspace_6_210325081534.txt\u001b[0m\n",
            "\u001b[1;37m2021-03-25 08:20:08 [INFO] 生成好的 1,000,000 个密码保存到文件：result/predict/pl/cross/myspace_6_210325082008.txt\u001b[0m\n",
            "\u001b[1;37m2021-03-25 08:24:48 [INFO] 生成好的 1,000,000 个密码保存到文件：result/predict/pl/cross/myspace_6_210325082448.txt\u001b[0m\n",
            "\u001b[1;37m2021-03-25 08:29:20 [INFO] 生成好的 1,000,000 个密码保存到文件：result/predict/pl/cross/myspace_6_210325082920.txt\u001b[0m\n",
            "\u001b[1;37m2021-03-25 08:29:20 [INFO] 使用 phpbb PL模型生成密码\u001b[0m\n",
            "\u001b[1;37m2021-03-25 08:29:20 [INFO] 创建PL模型。数据集名称：phpbb\u001b[0m\n",
            "\u001b[1;37m2021-03-25 08:29:22 [INFO] 待生成密码数量：1,000,000\u001b[0m\n",
            "\u001b[1;37m2021-03-25 08:39:11 [INFO] 生成好的 1,000,000 个密码保存到文件：result/predict/pl/cross/phpbb_6_210325083911.txt\u001b[0m\n",
            "\u001b[1;37m2021-03-25 08:48:52 [INFO] 生成好的 1,000,000 个密码保存到文件：result/predict/pl/cross/phpbb_6_210325084852.txt\u001b[0m\n",
            "\u001b[1;37m2021-03-25 08:58:36 [INFO] 生成好的 1,000,000 个密码保存到文件：result/predict/pl/cross/phpbb_6_210325085836.txt\u001b[0m\n",
            "\u001b[1;37m2021-03-25 09:08:27 [INFO] 生成好的 1,000,000 个密码保存到文件：result/predict/pl/cross/phpbb_6_210325090827.txt\u001b[0m\n",
            "\u001b[1;37m2021-03-25 09:18:31 [INFO] 生成好的 1,000,000 个密码保存到文件：result/predict/pl/cross/phpbb_6_210325091831.txt\u001b[0m\n",
            "\u001b[1;37m2021-03-25 09:28:09 [INFO] 生成好的 1,000,000 个密码保存到文件：result/predict/pl/cross/phpbb_6_210325092809.txt\u001b[0m\n",
            "\u001b[1;37m2021-03-25 09:37:49 [INFO] 生成好的 1,000,000 个密码保存到文件：result/predict/pl/cross/phpbb_6_210325093749.txt\u001b[0m\n",
            "\u001b[1;37m2021-03-25 09:47:34 [INFO] 生成好的 1,000,000 个密码保存到文件：result/predict/pl/cross/phpbb_6_210325094734.txt\u001b[0m\n",
            "\u001b[1;37m2021-03-25 09:57:15 [INFO] 生成好的 1,000,000 个密码保存到文件：result/predict/pl/cross/phpbb_6_210325095715.txt\u001b[0m\n",
            "\u001b[1;37m2021-03-25 10:06:59 [INFO] 生成好的 1,000,000 个密码保存到文件：result/predict/pl/cross/phpbb_6_210325100659.txt\u001b[0m\n",
            "\u001b[1;37m2021-03-25 10:07:00 [INFO] 使用 myspace_part PL模型生成密码\u001b[0m\n",
            "\u001b[1;37m2021-03-25 10:07:00 [INFO] 创建PL模型。数据集名称：myspace_part\u001b[0m\n",
            "\u001b[1;37m2021-03-25 10:07:02 [INFO] 待生成密码数量：1,000,000\u001b[0m\n",
            "\u001b[1;37m2021-03-25 10:11:21 [INFO] 生成好的 1,000,000 个密码保存到文件：result/predict/pl/one/myspace_part_6_210325101121.txt\u001b[0m\n",
            "\u001b[1;37m2021-03-25 10:15:36 [INFO] 生成好的 1,000,000 个密码保存到文件：result/predict/pl/one/myspace_part_6_210325101536.txt\u001b[0m\n",
            "\u001b[1;37m2021-03-25 10:19:48 [INFO] 生成好的 1,000,000 个密码保存到文件：result/predict/pl/one/myspace_part_6_210325101948.txt\u001b[0m\n",
            "\u001b[1;37m2021-03-25 10:23:53 [INFO] 生成好的 1,000,000 个密码保存到文件：result/predict/pl/one/myspace_part_6_210325102353.txt\u001b[0m\n",
            "\u001b[1;37m2021-03-25 10:28:07 [INFO] 生成好的 1,000,000 个密码保存到文件：result/predict/pl/one/myspace_part_6_210325102807.txt\u001b[0m\n",
            "\u001b[1;37m2021-03-25 10:32:15 [INFO] 生成好的 1,000,000 个密码保存到文件：result/predict/pl/one/myspace_part_6_210325103215.txt\u001b[0m\n",
            "\u001b[1;37m2021-03-25 10:36:26 [INFO] 生成好的 1,000,000 个密码保存到文件：result/predict/pl/one/myspace_part_6_210325103626.txt\u001b[0m\n",
            "\u001b[1;37m2021-03-25 10:40:30 [INFO] 生成好的 1,000,000 个密码保存到文件：result/predict/pl/one/myspace_part_6_210325104030.txt\u001b[0m\n",
            "\u001b[1;37m2021-03-25 10:44:41 [INFO] 生成好的 1,000,000 个密码保存到文件：result/predict/pl/one/myspace_part_6_210325104441.txt\u001b[0m\n",
            "\u001b[1;37m2021-03-25 10:48:51 [INFO] 生成好的 1,000,000 个密码保存到文件：result/predict/pl/one/myspace_part_6_210325104851.txt\u001b[0m\n",
            "\u001b[1;37m2021-03-25 10:48:51 [INFO] 使用 phpbb_part PL模型生成密码\u001b[0m\n",
            "\u001b[1;37m2021-03-25 10:48:51 [INFO] 创建PL模型。数据集名称：phpbb_part\u001b[0m\n",
            "\u001b[1;37m2021-03-25 10:48:53 [INFO] 待生成密码数量：1,000,000\u001b[0m\n",
            "\u001b[1;37m2021-03-25 10:58:36 [INFO] 生成好的 1,000,000 个密码保存到文件：result/predict/pl/one/phpbb_part_6_210325105836.txt\u001b[0m\n",
            "\u001b[1;37m2021-03-25 11:08:15 [INFO] 生成好的 1,000,000 个密码保存到文件：result/predict/pl/one/phpbb_part_6_210325110815.txt\u001b[0m\n",
            "\u001b[1;37m2021-03-25 11:17:46 [INFO] 生成好的 1,000,000 个密码保存到文件：result/predict/pl/one/phpbb_part_6_210325111746.txt\u001b[0m\n",
            "\u001b[1;37m2021-03-25 11:27:17 [INFO] 生成好的 1,000,000 个密码保存到文件：result/predict/pl/one/phpbb_part_6_210325112717.txt\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yHtWUb6E3Ow"
      },
      "source": [
        "## 评估模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VV2QMbwwXmH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "530c5f25-cc47-47d0-e238-003c8c01de9c"
      },
      "source": [
        "!python main.py --evaluate --alphas 3 4 5 6"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-03-25 14:11:44.819287: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[1;37m2021-03-25 14:11:46 [INFO] \n",
            "##########################################################################################################\n",
            "# GENPass\n",
            "# 1 PL模型预测。预测密码中的下一个单元（unit）。\n",
            "# 2 权重选择。按照权重选择从3个PL模型的结果中选择权重最高的unit，并根据wordlist随机选择一个密码进行替换。\n",
            "# 3 分类器。使用CNN模型预测上一步生成的密码属于3个数据集的概率。\n",
            "# 4 判定器。选择出在3个数据集概率相差不大的密码作为结果输出。\n",
            "#\n",
            "##########################################################################################################\n",
            "\u001b[0m\n",
            "\u001b[1;37m2021-03-25 14:11:46 [INFO] Start...\u001b[0m\n",
            "\u001b[1;37m2021-03-25 14:11:46 [INFO] PL模型评估。评估方法：cross-site\u001b[0m\n",
            "\u001b[1;37m2021-03-25 14:11:47 [INFO] 测试集文件：result/preprocessed/rockyou_small.txt，密码个数：99970\u001b[0m\n",
            "\u001b[1;37m2021-03-25 14:11:47 [INFO] 测试集文件：result/preprocessed/rockyou_small.txt，密码个数：99970\u001b[0m\n",
            "\u001b[1;37m2021-03-25 14:11:47 [INFO] data_name：myspace, alpha：3, unique value：999, test_size: 7000, guessed: 1, mr：0.01%\u001b[0m\n",
            "\u001b[1;37m2021-03-25 14:11:47 [INFO] data_name：myspace, alpha：4, unique value：9922, test_size: 7000, guessed: 2, mr：0.03%\u001b[0m\n",
            "\u001b[1;37m2021-03-25 14:11:47 [INFO] data_name：myspace, alpha：5, unique value：98205, test_size: 7000, guessed: 46, mr：0.66%\u001b[0m\n",
            "\u001b[1;37m2021-03-25 14:11:52 [INFO] data_name：myspace, alpha：6, unique value：1187594, test_size: 7000, guessed: 502, mr：7.17%\u001b[0m\n",
            "\u001b[1;37m2021-03-25 14:11:52 [INFO] data_name：phpbb, alpha：3, unique value：995, test_size: 7000, guessed: 1, mr：0.01%\u001b[0m\n",
            "\u001b[1;37m2021-03-25 14:11:52 [INFO] data_name：phpbb, alpha：4, unique value：9910, test_size: 7000, guessed: 4, mr：0.06%\u001b[0m\n",
            "\u001b[1;37m2021-03-25 14:11:53 [INFO] data_name：phpbb, alpha：5, unique value：98517, test_size: 7000, guessed: 19, mr：0.27%\u001b[0m\n",
            "\u001b[1;37m2021-03-25 14:11:57 [INFO] data_name：phpbb, alpha：6, unique value：984954, test_size: 7000, guessed: 162, mr：2.31%\u001b[0m\n",
            "\u001b[1;37m2021-03-25 14:11:57 [INFO] genpass模型评估\u001b[0m\n",
            "\u001b[1;37m2021-03-25 14:11:57 [INFO] 测试集文件：result/preprocessed/rockyou_small.txt，密码个数：99970\u001b[0m\n",
            "\u001b[1;37m2021-03-25 14:11:57 [INFO] alpha：3, unique value：52, test_size: 7000, guessed: 1, mr：0.01%\u001b[0m\n",
            "\u001b[1;37m2021-03-25 14:11:57 [INFO] alpha：4, unique value：446, test_size: 7000, guessed: 1, mr：0.01%\u001b[0m\n",
            "\u001b[1;37m2021-03-25 14:11:57 [INFO] alpha：5, unique value：4437, test_size: 7000, guessed: 1, mr：0.01%\u001b[0m\n",
            "\u001b[1;37m2021-03-25 14:11:57 [INFO] alpha：6, unique value：43993, test_size: 7000, guessed: 15, mr：0.21%\u001b[0m\n",
            "\u001b[1;37m2021-03-25 14:11:58 [INFO] PL模型评估。评估方法：one-site\u001b[0m\n",
            "\u001b[1;37m2021-03-25 14:11:58 [INFO] 测试集文件：result/preprocessed/myspace_test.txt，密码个数：7405\u001b[0m\n",
            "\u001b[1;37m2021-03-25 14:11:58 [INFO] 测试集文件：result/preprocessed/phpbb_test.txt，密码个数：36823\u001b[0m\n",
            "\u001b[1;37m2021-03-25 14:11:59 [INFO] data_name：myspace, alpha：3, unique value：999, test_size: 7000, guessed: 3, mr：0.04%\u001b[0m\n",
            "\u001b[1;37m2021-03-25 14:11:59 [INFO] data_name：myspace, alpha：4, unique value：9960, test_size: 7000, guessed: 7, mr：0.10%\u001b[0m\n",
            "tcmalloc: large alloc 2677907456 bytes == 0x556bb90c0000 @  0x7f0035dc0001 0x7f003357a54f 0x7f00335cab58 0x7f00335cad18 0x7f0033672010 0x7f003367273c 0x7f003367285d 0x556b9bfeb2f8 0x7f00335b7ef7 0x556b9bfe8fd7 0x556b9bfe8de0 0x556b9c05cac2 0x556b9c057b0e 0x556b9bfea77a 0x556b9c05ce50 0x556b9c057b0e 0x556b9bf29e2b 0x7f00335b7ef7 0x556b9bfe8fd7 0x556b9bfe8de0 0x556b9c05cac2 0x556b9c057b0e 0x556b9bfea77a 0x556b9c05986a 0x556b9bfea69a 0x556b9c058a45 0x556b9c057b0e 0x556b9bfea77a 0x556b9c05986a 0x556b9c057b0e 0x556b9bfea77a\n",
            "\u001b[1;37m2021-03-25 14:12:03 [INFO] data_name：myspace, alpha：5, unique value：98579, test_size: 7000, guessed: 30, mr：0.43%\u001b[0m\n",
            "tcmalloc: large alloc 2676031488 bytes == 0x556bb90c0000 @  0x7f0035dc0001 0x7f003357a54f 0x7f00335cab58 0x7f00335cad18 0x7f0033672010 0x7f003367273c 0x7f003367285d 0x556b9bfeb2f8 0x7f00335b7ef7 0x556b9bfe8fd7 0x556b9bfe8de0 0x556b9c05cac2 0x556b9c057b0e 0x556b9bfea77a 0x556b9c05ce50 0x556b9c057b0e 0x556b9bf29e2b 0x7f00335b7ef7 0x556b9bfe8fd7 0x556b9bfe8de0 0x556b9c05cac2 0x556b9c057b0e 0x556b9bfea77a 0x556b9c05986a 0x556b9bfea69a 0x556b9c058a45 0x556b9c057b0e 0x556b9bfea77a 0x556b9c05986a 0x556b9c057b0e 0x556b9bfea77a\n",
            "tcmalloc: large alloc 2675957760 bytes == 0x556bbdb28000 @  0x7f0035dc0001 0x7f003357a54f 0x7f00335cab58 0x7f00335cad18 0x7f0033672010 0x7f003367273c 0x7f003367285d 0x556b9bfeb2f8 0x7f00335b7ef7 0x556b9bfe8fd7 0x556b9bfe8de0 0x556b9c05cac2 0x556b9c057b0e 0x556b9bfea77a 0x556b9c05ce50 0x556b9c057b0e 0x556b9bf29e2b 0x7f00335b7ef7 0x556b9bfe8fd7 0x556b9bfe8de0 0x556b9c05cac2 0x556b9c057b0e 0x556b9bfea77a 0x556b9c05986a 0x556b9bfea69a 0x556b9c058a45 0x556b9c057b0e 0x556b9bfea77a 0x556b9c05986a 0x556b9c057b0e 0x556b9bfea77a\n",
            "tcmalloc: large alloc 2675351552 bytes == 0x556bb90c0000 @  0x7f0035dc0001 0x7f003357a54f 0x7f00335cab58 0x7f00335cad18 0x7f0033672010 0x7f003367273c 0x7f003367285d 0x556b9bfeb2f8 0x7f00335b7ef7 0x556b9bfe8fd7 0x556b9bfe8de0 0x556b9c05cac2 0x556b9c057b0e 0x556b9bfea77a 0x556b9c05ce50 0x556b9c057b0e 0x556b9bf29e2b 0x7f00335b7ef7 0x556b9bfe8fd7 0x556b9bfe8de0 0x556b9c05cac2 0x556b9c057b0e 0x556b9bfea77a 0x556b9c05986a 0x556b9bfea69a 0x556b9c058a45 0x556b9c057b0e 0x556b9bfea77a 0x556b9c05986a 0x556b9c057b0e 0x556b9bfea77a\n",
            "tcmalloc: large alloc 2675318784 bytes == 0x556bb90c0000 @  0x7f0035dc0001 0x7f003357a54f 0x7f00335cab58 0x7f00335cad18 0x7f0033672010 0x7f003367273c 0x7f003367285d 0x556b9bfeb2f8 0x7f00335b7ef7 0x556b9bfe8fd7 0x556b9bfe8de0 0x556b9c05cac2 0x556b9c057b0e 0x556b9bfea77a 0x556b9c05ce50 0x556b9c057b0e 0x556b9bf29e2b 0x7f00335b7ef7 0x556b9bfe8fd7 0x556b9bfe8de0 0x556b9c05cac2 0x556b9c057b0e 0x556b9bfea77a 0x556b9c05986a 0x556b9bfea69a 0x556b9c058a45 0x556b9c057b0e 0x556b9bfea77a 0x556b9c05986a 0x556b9c057b0e 0x556b9bfea77a\n",
            "tcmalloc: large alloc 2678063104 bytes == 0x556bb90c0000 @  0x7f0035dc0001 0x7f003357a54f 0x7f00335cab58 0x7f00335cad18 0x7f0033672010 0x7f003367273c 0x7f003367285d 0x556b9bfeb2f8 0x7f00335b7ef7 0x556b9bfe8fd7 0x556b9bfe8de0 0x556b9c05cac2 0x556b9c057b0e 0x556b9bfea77a 0x556b9c05ce50 0x556b9c057b0e 0x556b9bf29e2b 0x7f00335b7ef7 0x556b9bfe8fd7 0x556b9bfe8de0 0x556b9c05cac2 0x556b9c057b0e 0x556b9bfea77a 0x556b9c05986a 0x556b9bfea69a 0x556b9c058a45 0x556b9c057b0e 0x556b9bfea77a 0x556b9c05986a 0x556b9c057b0e 0x556b9bfea77a\n",
            "tcmalloc: large alloc 2673975296 bytes == 0x556bb90c0000 @  0x7f0035dc0001 0x7f003357a54f 0x7f00335cab58 0x7f00335cad18 0x7f0033672010 0x7f003367273c 0x7f003367285d 0x556b9bfeb2f8 0x7f00335b7ef7 0x556b9bfe8fd7 0x556b9bfe8de0 0x556b9c05cac2 0x556b9c057b0e 0x556b9bfea77a 0x556b9c05ce50 0x556b9c057b0e 0x556b9bf29e2b 0x7f00335b7ef7 0x556b9bfe8fd7 0x556b9bfe8de0 0x556b9c05cac2 0x556b9c057b0e 0x556b9bfea77a 0x556b9c05986a 0x556b9bfea69a 0x556b9c058a45 0x556b9c057b0e 0x556b9bfea77a 0x556b9c05986a 0x556b9c057b0e 0x556b9bfea77a\n",
            "tcmalloc: large alloc 2676563968 bytes == 0x556bbd468000 @  0x7f0035dc0001 0x7f003357a54f 0x7f00335cab58 0x7f00335cad18 0x7f0033672010 0x7f003367273c 0x7f003367285d 0x556b9bfeb2f8 0x7f00335b7ef7 0x556b9bfe8fd7 0x556b9bfe8de0 0x556b9c05cac2 0x556b9c057b0e 0x556b9bfea77a 0x556b9c05ce50 0x556b9c057b0e 0x556b9bf29e2b 0x7f00335b7ef7 0x556b9bfe8fd7 0x556b9bfe8de0 0x556b9c05cac2 0x556b9c057b0e 0x556b9bfea77a 0x556b9c05986a 0x556b9bfea69a 0x556b9c058a45 0x556b9c057b0e 0x556b9bfea77a 0x556b9c05986a 0x556b9c057b0e 0x556b9bfea77a\n",
            "\u001b[1;37m2021-03-25 14:12:32 [INFO] data_name：myspace, alpha：6, unique value：985014, test_size: 7000, guessed: 203, mr：2.90%\u001b[0m\n",
            "\u001b[1;37m2021-03-25 14:12:32 [INFO] data_name：phpbb, alpha：3, unique value：1000, test_size: 7000, guessed: 1, mr：0.01%\u001b[0m\n",
            "\u001b[1;37m2021-03-25 14:12:32 [INFO] data_name：phpbb, alpha：4, unique value：9934, test_size: 7000, guessed: 3, mr：0.04%\u001b[0m\n",
            "\u001b[1;37m2021-03-25 14:12:33 [INFO] data_name：phpbb, alpha：5, unique value：98889, test_size: 7000, guessed: 5, mr：0.07%\u001b[0m\n",
            "\u001b[1;37m2021-03-25 14:12:37 [INFO] data_name：phpbb, alpha：6, unique value：988474, test_size: 7000, guessed: 77, mr：1.10%\u001b[0m\n",
            "\u001b[1;37m2021-03-25 14:12:38 [INFO] End...\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}