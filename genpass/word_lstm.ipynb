{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "word_lstm.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPYmPQT5iXYfPm2r96Ry87W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YapingWu/GoogleColab/blob/main/genpass/word_lstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuLbXO_oxr1j"
      },
      "source": [
        "# 准备工作\r\n",
        "1. 上传编码后的密码文件：`myspace.txt` `phpbb.txt`\r\n",
        "2. 上传分词器模型：`myspace.pkl` `phpbb.pkl`\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5lJvYbs-x_T",
        "outputId": "64ede5e3-369a-446d-a2aa-ed973e3d051c"
      },
      "source": [
        "!unzip '/content/tokenizer.zip' -d './tokenizer'\r\n",
        "!unzip '/content/wordlist.zip' -d './wordlist'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/tokenizer.zip\n",
            "  inflating: ./tokenizer/myspace.pkl  \n",
            "  inflating: ./tokenizer/phpbb.pkl   \n",
            "  inflating: ./tokenizer/rockyou.pkl  \n",
            "  inflating: ./tokenizer/phpbb_7.pkl  \n",
            "  inflating: ./tokenizer/myspace_7.pkl  \n",
            "Archive:  /content/wordlist.zip\n",
            "  inflating: ./wordlist/phpbb.txt    \n",
            "  inflating: ./wordlist/myspace.txt  \n",
            "  inflating: ./wordlist/phpbb_7.txt  \n",
            "  inflating: ./wordlist/myspace_7.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZaJUC-DFxb-r"
      },
      "source": [
        "# WordLSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LYC6j5I_ufn"
      },
      "source": [
        "## 定义模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpNehT6sw8YN"
      },
      "source": [
        "from collections import ChainMap\r\n",
        "import os\r\n",
        "import sys\r\n",
        "import time\r\n",
        "import pickle\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "from keras.utils import to_categorical\r\n",
        "from keras.preprocessing.sequence import pad_sequences\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense\r\n",
        "from keras.layers import LSTM\r\n",
        "from keras.layers import Embedding\r\n",
        "from keras import optimizers\r\n",
        "from keras.callbacks import TensorBoard, EarlyStopping\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "SEED = 7\r\n",
        "np.random.seed(SEED)\r\n",
        "max_seq_len = {\r\n",
        "        'myspace': 18,\r\n",
        "        'phpbb': 20,\r\n",
        "        'myspace_7': 18,\r\n",
        "        'phpbb_7': 20,\r\n",
        "        'rockyou': 47,\r\n",
        "    }\r\n",
        "\r\n",
        "class WordLSTM:\r\n",
        "    \"\"\"\r\n",
        "    Word-level LSTM模型\r\n",
        "\r\n",
        "    :param data_path: 数据集路径\r\n",
        "    :param data_name: 数据集名称\r\n",
        "    \"\"\"\r\n",
        "    def __init__(self, data_name):\r\n",
        "        self.data_name = data_name  # 数据集名称\r\n",
        "        self.data = self.load_data('{}{}.txt'.format('./wordlist/', data_name))\r\n",
        "        # 分词器\r\n",
        "        self.tokenizer = self.load_tokenizer('{}{}.pkl'.format('/content/tokenizer/', data_name))\r\n",
        "        self.vocab_size = len(self.tokenizer.word_index) + 1  # 词汇表大小\r\n",
        "\r\n",
        "        self.max_length = max_seq_len[data_name]  # 最大序列长度（单词长度）\r\n",
        "        # lstm的超参数\r\n",
        "        self.epochs = 500\r\n",
        "        self.batch_size = 128\r\n",
        "        self.lstm_layers = [[32, True], [32, True], [32, False]]\r\n",
        "        self.fully_layers = [32]\r\n",
        "        self.lr = 0.001\r\n",
        "        self.log_dir = './logs/'  # tensorboard日志文件\r\n",
        "\r\n",
        "        self.model_file = '{}{}.h5'.format('./model/', data_name)  # lstm模型文件\r\n",
        "\r\n",
        "    @staticmethod\r\n",
        "    def load_data(fname):\r\n",
        "        \"\"\"\r\n",
        "        加载数据。\r\n",
        "        :param fname: 数据集文件名\r\n",
        "        :return: dataframe\r\n",
        "        \"\"\"\r\n",
        "        if os.path.exists(fname):\r\n",
        "            print(\"开始加载编码后的密码数据：%s\" % fname)\r\n",
        "            data = pd.read_csv(fname)['grammar']\r\n",
        "            np.random.shuffle(data)\r\n",
        "            return data\r\n",
        "        else:\r\n",
        "            logger.error(\"文件不存在：%s\" % fname)\r\n",
        "            sys.exit(1)\r\n",
        "\r\n",
        "    @staticmethod\r\n",
        "    def load_tokenizer(fname):\r\n",
        "        \"\"\"\r\n",
        "        从文件中加载tokenizer模型\r\n",
        "        :param fname:\r\n",
        "        :return: tokenizer模型\r\n",
        "        \"\"\"\r\n",
        "        if os.path.exists(fname):\r\n",
        "            print(\"开始加载tokenizer模型：%s\" % fname)\r\n",
        "            with open(fname, 'rb') as file:\r\n",
        "                tokenizer = pickle.load(file)\r\n",
        "                return tokenizer\r\n",
        "        else:\r\n",
        "            logger.error(\"tokenizer模型文件不存在：%s\" % fname)\r\n",
        "            sys.exit(1)\r\n",
        "\r\n",
        "    def encode_data(self):\r\n",
        "        \"\"\"\r\n",
        "        将文本转换为（整数）序列\r\n",
        "        :return: None\r\n",
        "        \"\"\"\r\n",
        "        # 将编码后的密码转换为整数序列\r\n",
        "        print(\"将编码后的密码转换为（整数）序列\")\r\n",
        "        sequences = list()\r\n",
        "\r\n",
        "        data = self.data.values.tolist()\r\n",
        "        for line in data:  # 'L8 D1 '\r\n",
        "            line += '<END>'\r\n",
        "            # 将文本转换为（整数）序列\r\n",
        "            encoded = self.tokenizer.texts_to_sequences([line])[0]\r\n",
        "            # 过滤掉长度大于 MAX_SEQ_LEN 的序列\r\n",
        "            if len(encoded) > self.max_length:\r\n",
        "                continue\r\n",
        "            for i in range(1, len(encoded) + 1):\r\n",
        "                sequence = encoded[:i]\r\n",
        "                sequences.append(sequence)\r\n",
        "\r\n",
        "        print('Total Sequences: %d' % len(sequences))\r\n",
        "\r\n",
        "        # pad input sequences\r\n",
        "        self.max_length = max([len(seq) for seq in sequences])\r\n",
        "        sequences = pad_sequences(sequences, self.max_length, padding='pre')  # 左边填充0\r\n",
        "        print('Max Sequence Length: %d' % self.max_length)\r\n",
        "\r\n",
        "        # 创建输入输出\r\n",
        "        print(\"创建LSTM模型的输入输出\")\r\n",
        "        sequences = np.array(sequences)\r\n",
        "        x, y = sequences[:, :-1], sequences[:, -1]\r\n",
        "        print(\"X Shape: %s, y Shape: %s\" % (x.shape, y.shape))\r\n",
        "        y = to_categorical(y, num_classes=self.vocab_size)  # 对输出进行one-hot编码\r\n",
        "\r\n",
        "        return x, y\r\n",
        "\r\n",
        "    def split_data(self):\r\n",
        "        \"\"\"\r\n",
        "        将lstm的输入输出数据划分为训练集、验证集和测试集\r\n",
        "        :return: x_train, x_val, x_test, y_train, y_val, y_test\r\n",
        "        \"\"\"\r\n",
        "        # 将文本转换为（整数）序列\r\n",
        "        x, y = self.encode_data()\r\n",
        "\r\n",
        "        ratio = 0.6  # 训练集比例\r\n",
        "        if len(x) > 100000:\r\n",
        "            ratio = 0.9\r\n",
        "\r\n",
        "        print(\"划分训练集、验证集和测试集\")\r\n",
        "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=1 - ratio, random_state=SEED)\r\n",
        "        x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=0.5, random_state=SEED)\r\n",
        "\r\n",
        "        print(\"x_train Shape: %s, y_train Shape: %s\" % (x_train.shape, y_train.shape))\r\n",
        "        print(\"x_val Shape: %s, y_val Shape: %s\" % (x_val.shape, y_val.shape))\r\n",
        "        print(\"x_test Shape: %s, y_test Shape: %s\" % (x_test.shape, y_test.shape))\r\n",
        "\r\n",
        "        return x_train, x_val, x_test, y_train, y_val, y_test\r\n",
        "\r\n",
        "    def create_and_train_model(self):\r\n",
        "        \"\"\"\r\n",
        "        创建和训练LSTM模型\r\n",
        "        :return: None\r\n",
        "        \"\"\"\r\n",
        "        # 划分训练集、验证集和测试集\r\n",
        "        x_train, x_val, x_test, y_train, y_val, y_test = self.split_data()\r\n",
        "\r\n",
        "        print('{:*^106}'.format('创建LSTM模型'))\r\n",
        "        model = Sequential()\r\n",
        "        model.add(Embedding(input_dim=self.vocab_size, output_dim=10, input_length=self.max_length - 1))\r\n",
        "\r\n",
        "        for hidden_size, rs in self.lstm_layers:\r\n",
        "            model.add(LSTM(hidden_size, return_sequences=rs))\r\n",
        "\r\n",
        "        for hidden_size in self.fully_layers:\r\n",
        "            model.add(Dense(units=hidden_size, activation='relu'))\r\n",
        "        model.add(Dense(self.vocab_size, activation='softmax'))\r\n",
        "\r\n",
        "        model.summary()\r\n",
        "\r\n",
        "        adam = optimizers.Adam(lr=self.lr)\r\n",
        "        model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\r\n",
        "\r\n",
        "        cur_time = time.strftime(\"%y%m%d%H%M%S\", time.localtime())\r\n",
        "        log_name = '{}{}{}'.format(self.log_dir, self.data_name, cur_time)\r\n",
        "        tensorboard = TensorBoard(log_dir=log_name)\r\n",
        "        early_stopping = EarlyStopping(monitor='val_loss', patience=50)\r\n",
        "\r\n",
        "        print('{:*^106}'.format('开始训练LSTM模型'))\r\n",
        "        model.fit(x_train, y_train,\r\n",
        "                  validation_data=(x_val, y_val),\r\n",
        "                  epochs=self.epochs,\r\n",
        "                  batch_size=self.batch_size,\r\n",
        "                  verbose=1,\r\n",
        "                  callbacks=[tensorboard, early_stopping])\r\n",
        "        loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\r\n",
        "        print(\"Model Accuracy on test: %.2f%%, Loss: %.2f\" % (accuracy * 100, loss))\r\n",
        "\r\n",
        "        print(\"保存模型：%s\" % self.model_file)\r\n",
        "        model.save(self.model_file)\r\n",
        "        print('TensorBoard 日志：{}'.format(log_name))\r\n",
        "        print('{:*^106}'.format('完成训练LSTM模型'))"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcvMaCpUxgq_"
      },
      "source": [
        "## 训练模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izqnpKu5xjtp",
        "outputId": "fee48d66-dc72-4de3-975b-21658e1f7b22"
      },
      "source": [
        "data_sets = ['myspace', 'phpbb', 'myspace_7', 'phpbb_7']\r\n",
        "# 使用PCFG编码后的密码训练lstm模型\r\n",
        "for name in data_sets:\r\n",
        "  word_lstm = WordLSTM(name)\r\n",
        "  word_lstm.create_and_train_model()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "开始加载编码后的密码数据：./wordlist/myspace.txt\n",
            "开始加载tokenizer模型：/content/tokenizer/myspace.pkl\n",
            "将编码后的密码转换为（整数）序列\n",
            "Total Sequences: 8583\n",
            "Max Sequence Length: 18\n",
            "创建LSTM模型的输入输出\n",
            "X Shape: (8583, 17), y Shape: (8583,)\n",
            "划分训练集、验证集和测试集\n",
            "x_train Shape: (5149, 17), y_train Shape: (5149, 70)\n",
            "x_val Shape: (1717, 17), y_val Shape: (1717, 70)\n",
            "x_test Shape: (1717, 17), y_test Shape: (1717, 70)\n",
            "*************************************************创建LSTM模型*************************************************\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 17, 10)            700       \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 17, 32)            5504      \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 17, 32)            8320      \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 32)                8320      \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 70)                2310      \n",
            "=================================================================\n",
            "Total params: 26,210\n",
            "Trainable params: 26,210\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "************************************************开始训练LSTM模型************************************************\n",
            "Epoch 1/500\n",
            "41/41 [==============================] - 8s 56ms/step - loss: 4.1157 - accuracy: 0.1575 - val_loss: 2.9413 - val_accuracy: 0.1998\n",
            "Epoch 2/500\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 2.8387 - accuracy: 0.2033 - val_loss: 2.6247 - val_accuracy: 0.1998\n",
            "Epoch 3/500\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 2.6428 - accuracy: 0.2008 - val_loss: 2.5944 - val_accuracy: 0.1998\n",
            "Epoch 4/500\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 2.6232 - accuracy: 0.2029 - val_loss: 2.5915 - val_accuracy: 0.1998\n",
            "Epoch 5/500\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 2.6289 - accuracy: 0.2006 - val_loss: 2.5880 - val_accuracy: 0.1998\n",
            "Epoch 6/500\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 2.6109 - accuracy: 0.2117 - val_loss: 2.5885 - val_accuracy: 0.1998\n",
            "Epoch 7/500\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 2.6617 - accuracy: 0.1998 - val_loss: 2.5867 - val_accuracy: 0.1998\n",
            "Epoch 8/500\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 2.6166 - accuracy: 0.1983 - val_loss: 2.5897 - val_accuracy: 0.1998\n",
            "Epoch 9/500\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 2.6438 - accuracy: 0.2001 - val_loss: 2.5894 - val_accuracy: 0.1998\n",
            "Epoch 10/500\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 2.6194 - accuracy: 0.2034 - val_loss: 2.5916 - val_accuracy: 0.1998\n",
            "Epoch 11/500\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 2.6436 - accuracy: 0.2006 - val_loss: 2.5879 - val_accuracy: 0.1998\n",
            "Epoch 12/500\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 2.6208 - accuracy: 0.1904 - val_loss: 2.5882 - val_accuracy: 0.1998\n",
            "Epoch 13/500\n",
            "41/41 [==============================] - 0s 11ms/step - loss: 2.6183 - accuracy: 0.2037 - val_loss: 2.5879 - val_accuracy: 0.1998\n",
            "Epoch 14/500\n",
            "41/41 [==============================] - 0s 11ms/step - loss: 2.6344 - accuracy: 0.2011 - val_loss: 2.5894 - val_accuracy: 0.1998\n",
            "Epoch 15/500\n",
            "41/41 [==============================] - 0s 11ms/step - loss: 2.6003 - accuracy: 0.1907 - val_loss: 2.5912 - val_accuracy: 0.1998\n",
            "Epoch 16/500\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 2.6423 - accuracy: 0.2004 - val_loss: 2.5903 - val_accuracy: 0.1998\n",
            "Epoch 17/500\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 2.6280 - accuracy: 0.2006 - val_loss: 2.5879 - val_accuracy: 0.1998\n",
            "Epoch 18/500\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 2.6063 - accuracy: 0.1958 - val_loss: 2.5916 - val_accuracy: 0.1998\n",
            "Epoch 19/500\n",
            "41/41 [==============================] - 0s 11ms/step - loss: 2.6321 - accuracy: 0.1993 - val_loss: 2.5904 - val_accuracy: 0.1998\n",
            "Epoch 20/500\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 2.6228 - accuracy: 0.2093 - val_loss: 2.5877 - val_accuracy: 0.1998\n",
            "Epoch 21/500\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 2.6475 - accuracy: 0.1981 - val_loss: 2.5885 - val_accuracy: 0.1998\n",
            "Epoch 22/500\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 2.6273 - accuracy: 0.2013 - val_loss: 2.5876 - val_accuracy: 0.1998\n",
            "Epoch 23/500\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 2.6164 - accuracy: 0.2069 - val_loss: 2.5910 - val_accuracy: 0.1998\n",
            "Epoch 24/500\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 2.6305 - accuracy: 0.1936 - val_loss: 2.5895 - val_accuracy: 0.1998\n",
            "Epoch 25/500\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 2.6359 - accuracy: 0.1946 - val_loss: 2.5900 - val_accuracy: 0.1998\n",
            "Epoch 26/500\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 2.6483 - accuracy: 0.1915 - val_loss: 2.5894 - val_accuracy: 0.1998\n",
            "Epoch 27/500\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 2.5895 - accuracy: 0.1958 - val_loss: 2.5872 - val_accuracy: 0.1998\n",
            "Epoch 28/500\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 2.6239 - accuracy: 0.2014 - val_loss: 2.5400 - val_accuracy: 0.1998\n",
            "Epoch 29/500\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 2.5416 - accuracy: 0.2070 - val_loss: 2.4184 - val_accuracy: 0.1998\n",
            "Epoch 30/500\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 2.3975 - accuracy: 0.2180 - val_loss: 2.3304 - val_accuracy: 0.2068\n",
            "Epoch 31/500\n",
            "41/41 [==============================] - 0s 11ms/step - loss: 2.3698 - accuracy: 0.2210 - val_loss: 2.2788 - val_accuracy: 0.2213\n",
            "Epoch 32/500\n",
            "41/41 [==============================] - 0s 11ms/step - loss: 2.2801 - accuracy: 0.2446 - val_loss: 2.2312 - val_accuracy: 0.2644\n",
            "Epoch 33/500\n",
            "41/41 [==============================] - 0s 11ms/step - loss: 2.2549 - accuracy: 0.2730 - val_loss: 2.1953 - val_accuracy: 0.3098\n",
            "Epoch 34/500\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 2.2364 - accuracy: 0.2696 - val_loss: 2.1797 - val_accuracy: 0.2970\n",
            "Epoch 35/500\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 2.2102 - accuracy: 0.2800 - val_loss: 2.1673 - val_accuracy: 0.3029\n",
            "Epoch 36/500\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 2.1846 - accuracy: 0.2925 - val_loss: 2.1558 - val_accuracy: 0.3110\n",
            "Epoch 37/500\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 2.1688 - accuracy: 0.2936 - val_loss: 2.1413 - val_accuracy: 0.3128\n",
            "Epoch 38/500\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 2.1635 - accuracy: 0.3071 - val_loss: 2.1317 - val_accuracy: 0.3221\n",
            "Epoch 39/500\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 2.1458 - accuracy: 0.2966 - val_loss: 2.1268 - val_accuracy: 0.3291\n",
            "Epoch 40/500\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 2.1295 - accuracy: 0.3049 - val_loss: 2.1170 - val_accuracy: 0.2964\n",
            "Epoch 41/500\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 2.1519 - accuracy: 0.3039 - val_loss: 2.0903 - val_accuracy: 0.3430\n",
            "Epoch 42/500\n",
            "41/41 [==============================] - 0s 11ms/step - loss: 2.1204 - accuracy: 0.3209 - val_loss: 2.0780 - val_accuracy: 0.3448\n",
            "Epoch 43/500\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 2.0932 - accuracy: 0.3249 - val_loss: 2.0621 - val_accuracy: 0.3553\n",
            "Epoch 44/500\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 2.0868 - accuracy: 0.3325 - val_loss: 2.0604 - val_accuracy: 0.3547\n",
            "Epoch 45/500\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 2.0628 - accuracy: 0.3417 - val_loss: 2.0570 - val_accuracy: 0.3436\n",
            "Epoch 46/500\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 2.0745 - accuracy: 0.3341 - val_loss: 2.0472 - val_accuracy: 0.3535\n",
            "Epoch 47/500\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 2.0608 - accuracy: 0.3325 - val_loss: 2.0511 - val_accuracy: 0.3559\n",
            "Epoch 48/500\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 2.0510 - accuracy: 0.3428 - val_loss: 2.0483 - val_accuracy: 0.3529\n",
            "Epoch 49/500\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 2.0806 - accuracy: 0.3217 - val_loss: 2.0424 - val_accuracy: 0.3576\n",
            "Epoch 50/500\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 2.0361 - accuracy: 0.3448 - val_loss: 2.0385 - val_accuracy: 0.3553\n",
            "Epoch 51/500\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 2.0668 - accuracy: 0.3316 - val_loss: 2.0348 - val_accuracy: 0.3559\n",
            "Epoch 52/500\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 2.0456 - accuracy: 0.3409 - val_loss: 2.0371 - val_accuracy: 0.3599\n",
            "Epoch 53/500\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 2.0447 - accuracy: 0.3352 - val_loss: 2.0314 - val_accuracy: 0.3576\n",
            "Epoch 54/500\n",
            "41/41 [==============================] - 0s 11ms/step - loss: 2.0361 - accuracy: 0.3431 - val_loss: 2.0400 - val_accuracy: 0.3553\n",
            "Epoch 55/500\n",
            "41/41 [==============================] - 0s 11ms/step - loss: 2.0750 - accuracy: 0.3336 - val_loss: 2.0320 - val_accuracy: 0.3547\n",
            "Epoch 56/500\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 2.0301 - accuracy: 0.3351 - val_loss: 2.0300 - val_accuracy: 0.3582\n",
            "Epoch 57/500\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 2.0360 - accuracy: 0.3323 - val_loss: 2.0321 - val_accuracy: 0.3541\n",
            "Epoch 58/500\n",
            "41/41 [==============================] - 0s 11ms/step - loss: 2.0447 - accuracy: 0.3302 - val_loss: 2.0351 - val_accuracy: 0.3553\n",
            "Epoch 59/500\n",
            "41/41 [==============================] - 0s 11ms/step - loss: 2.0220 - accuracy: 0.3401 - val_loss: 2.0316 - val_accuracy: 0.3593\n",
            "Epoch 60/500\n",
            "41/41 [==============================] - 0s 11ms/step - loss: 2.0413 - accuracy: 0.3372 - val_loss: 2.0274 - val_accuracy: 0.3588\n",
            "Epoch 61/500\n",
            "41/41 [==============================] - 0s 11ms/step - loss: 2.0528 - accuracy: 0.3310 - val_loss: 2.0401 - val_accuracy: 0.3524\n",
            "Epoch 62/500\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 2.0439 - accuracy: 0.3398 - val_loss: 2.0339 - val_accuracy: 0.3570\n",
            "Epoch 63/500\n",
            "41/41 [==============================] - 0s 11ms/step - loss: 2.0370 - accuracy: 0.3312 - val_loss: 2.0311 - val_accuracy: 0.3547\n",
            "Epoch 64/500\n",
            "41/41 [==============================] - 0s 11ms/step - loss: 2.0244 - accuracy: 0.3363 - val_loss: 2.0329 - val_accuracy: 0.3553\n",
            "Epoch 65/500\n",
            "41/41 [==============================] - 0s 11ms/step - loss: 2.0189 - accuracy: 0.3549 - val_loss: 2.0272 - val_accuracy: 0.3599\n",
            "Epoch 66/500\n",
            "41/41 [==============================] - 0s 11ms/step - loss: 2.0193 - accuracy: 0.3367 - val_loss: 2.0294 - val_accuracy: 0.3547\n",
            "Epoch 67/500\n",
            "41/41 [==============================] - 0s 11ms/step - loss: 2.0160 - accuracy: 0.3424 - val_loss: 2.0240 - val_accuracy: 0.3599\n",
            "Epoch 68/500\n",
            "41/41 [==============================] - 0s 11ms/step - loss: 2.0298 - accuracy: 0.3494 - val_loss: 2.0141 - val_accuracy: 0.3640\n",
            "Epoch 69/500\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 2.0113 - accuracy: 0.3433 - val_loss: 2.0069 - val_accuracy: 0.3704\n",
            "Epoch 70/500\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 1.9739 - accuracy: 0.3731 - val_loss: 2.0124 - val_accuracy: 0.3733\n",
            "Epoch 71/500\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 1.9831 - accuracy: 0.3794 - val_loss: 2.0024 - val_accuracy: 0.3727\n",
            "Epoch 72/500\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 1.9843 - accuracy: 0.3625 - val_loss: 2.0037 - val_accuracy: 0.3739\n",
            "Epoch 73/500\n",
            "41/41 [==============================] - 0s 12ms/step - loss: 1.9546 - accuracy: 0.3830 - val_loss: 2.0021 - val_accuracy: 0.3809\n",
            "Epoch 74/500\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 1.9835 - accuracy: 0.3663 - val_loss: 1.9911 - val_accuracy: 0.3844\n",
            "Epoch 75/500\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 1.9879 - accuracy: 0.3727 - val_loss: 2.0017 - val_accuracy: 0.3844\n",
            "Epoch 76/500\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 1.9895 - accuracy: 0.3690 - val_loss: 1.9961 - val_accuracy: 0.3838\n",
            "Epoch 77/500\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 1.9785 - accuracy: 0.3726 - val_loss: 1.9981 - val_accuracy: 0.3826\n",
            "Epoch 78/500\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 1.9325 - accuracy: 0.3881 - val_loss: 1.9815 - val_accuracy: 0.3861\n",
            "Epoch 79/500\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 1.9726 - accuracy: 0.3827 - val_loss: 1.9878 - val_accuracy: 0.3873\n",
            "Epoch 80/500\n",
            "41/41 [==============================] - 0s 11ms/step - loss: 1.9701 - accuracy: 0.3683 - val_loss: 1.9824 - val_accuracy: 0.3879\n",
            "Epoch 81/500\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 1.9533 - accuracy: 0.3831 - val_loss: 1.9797 - val_accuracy: 0.3902\n",
            "Epoch 82/500\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 1.9524 - accuracy: 0.3926 - val_loss: 1.9827 - val_accuracy: 0.3844\n",
            "Epoch 83/500\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 1.9504 - accuracy: 0.3800 - val_loss: 1.9866 - val_accuracy: 0.3850\n",
            "Epoch 84/500\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 1.9529 - accuracy: 0.3761 - val_loss: 1.9813 - val_accuracy: 0.3873\n",
            "Epoch 85/500\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 1.9429 - accuracy: 0.3913 - val_loss: 1.9706 - val_accuracy: 0.3873\n",
            "Epoch 86/500\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 1.9530 - accuracy: 0.3756 - val_loss: 1.9811 - val_accuracy: 0.3821\n",
            "Epoch 87/500\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 1.9563 - accuracy: 0.3890 - val_loss: 1.9701 - val_accuracy: 0.3914\n",
            "Epoch 88/500\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 1.9411 - accuracy: 0.3959 - val_loss: 1.9666 - val_accuracy: 0.3937\n",
            "Epoch 89/500\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 1.9603 - accuracy: 0.3839 - val_loss: 1.9771 - val_accuracy: 0.3815\n",
            "Epoch 90/500\n",
            "41/41 [==============================] - 0s 11ms/step - loss: 1.9235 - accuracy: 0.3845 - val_loss: 1.9678 - val_accuracy: 0.3879\n",
            "Epoch 91/500\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 1.9458 - accuracy: 0.3861 - val_loss: 1.9717 - val_accuracy: 0.3856\n",
            "Epoch 92/500\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 1.9448 - accuracy: 0.3830 - val_loss: 1.9654 - val_accuracy: 0.3931\n",
            "Epoch 93/500\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 1.9315 - accuracy: 0.3907 - val_loss: 1.9663 - val_accuracy: 0.3879\n",
            "Epoch 94/500\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 1.9483 - accuracy: 0.3813 - val_loss: 1.9662 - val_accuracy: 0.3879\n",
            "Epoch 95/500\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 1.9250 - accuracy: 0.3869 - val_loss: 1.9635 - val_accuracy: 0.3943\n",
            "Epoch 96/500\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 1.9316 - accuracy: 0.3837 - val_loss: 1.9649 - val_accuracy: 0.3896\n",
            "Epoch 97/500\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 1.8991 - accuracy: 0.3972 - val_loss: 1.9661 - val_accuracy: 0.3943\n",
            "Epoch 98/500\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 1.9109 - accuracy: 0.3920 - val_loss: 1.9708 - val_accuracy: 0.3908\n",
            "Epoch 99/500\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 1.9486 - accuracy: 0.3834 - val_loss: 1.9639 - val_accuracy: 0.3908\n",
            "Epoch 100/500\n",
            "41/41 [==============================] - 0s 12ms/step - loss: 1.9680 - accuracy: 0.3831 - val_loss: 1.9662 - val_accuracy: 0.3826\n",
            "Epoch 101/500\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 1.9309 - accuracy: 0.3807 - val_loss: 1.9603 - val_accuracy: 0.3873\n",
            "Epoch 102/500\n",
            "41/41 [==============================] - 0s 12ms/step - loss: 1.9167 - accuracy: 0.3941 - val_loss: 1.9638 - val_accuracy: 0.3867\n",
            "Epoch 103/500\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 1.9279 - accuracy: 0.3900 - val_loss: 1.9683 - val_accuracy: 0.3908\n",
            "Epoch 104/500\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 1.9344 - accuracy: 0.3817 - val_loss: 1.9693 - val_accuracy: 0.3838\n",
            "Epoch 105/500\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 1.9280 - accuracy: 0.3925 - val_loss: 1.9639 - val_accuracy: 0.3914\n",
            "Epoch 106/500\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 1.9153 - accuracy: 0.3846 - val_loss: 1.9609 - val_accuracy: 0.3908\n",
            "Epoch 107/500\n",
            "41/41 [==============================] - 0s 11ms/step - loss: 1.9140 - accuracy: 0.3928 - val_loss: 1.9578 - val_accuracy: 0.3931\n",
            "Epoch 108/500\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 1.9159 - accuracy: 0.3969 - val_loss: 1.9588 - val_accuracy: 0.3867\n",
            "Epoch 109/500\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 1.9400 - accuracy: 0.3822 - val_loss: 1.9614 - val_accuracy: 0.3891\n",
            "Epoch 110/500\n",
            "41/41 [==============================] - 0s 11ms/step - loss: 1.9155 - accuracy: 0.3870 - val_loss: 1.9829 - val_accuracy: 0.3856\n",
            "Epoch 111/500\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 1.8843 - accuracy: 0.3945 - val_loss: 1.9673 - val_accuracy: 0.3826\n",
            "Epoch 112/500\n",
            "41/41 [==============================] - 0s 11ms/step - loss: 1.8965 - accuracy: 0.3990 - val_loss: 1.9577 - val_accuracy: 0.3914\n",
            "Epoch 113/500\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 1.9191 - accuracy: 0.3904 - val_loss: 1.9741 - val_accuracy: 0.3809\n",
            "Epoch 114/500\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 1.9037 - accuracy: 0.3910 - val_loss: 1.9657 - val_accuracy: 0.3891\n",
            "Epoch 115/500\n",
            "41/41 [==============================] - 0s 11ms/step - loss: 1.9292 - accuracy: 0.3864 - val_loss: 1.9592 - val_accuracy: 0.3856\n",
            "Epoch 116/500\n",
            "41/41 [==============================] - 0s 11ms/step - loss: 1.8824 - accuracy: 0.3981 - val_loss: 1.9642 - val_accuracy: 0.3850\n",
            "Epoch 117/500\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 1.9207 - accuracy: 0.3909 - val_loss: 1.9633 - val_accuracy: 0.3815\n",
            "Epoch 118/500\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 1.8693 - accuracy: 0.4023 - val_loss: 1.9606 - val_accuracy: 0.3908\n",
            "Epoch 119/500\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 1.9342 - accuracy: 0.3885 - val_loss: 1.9618 - val_accuracy: 0.3949\n",
            "Epoch 120/500\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 1.8909 - accuracy: 0.3896 - val_loss: 1.9592 - val_accuracy: 0.3896\n",
            "Epoch 121/500\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 1.8955 - accuracy: 0.3959 - val_loss: 1.9735 - val_accuracy: 0.3879\n",
            "Epoch 122/500\n",
            "41/41 [==============================] - 0s 11ms/step - loss: 1.9165 - accuracy: 0.3913 - val_loss: 1.9632 - val_accuracy: 0.3896\n",
            "Epoch 123/500\n",
            "41/41 [==============================] - 0s 11ms/step - loss: 1.9101 - accuracy: 0.3864 - val_loss: 1.9598 - val_accuracy: 0.3902\n",
            "Epoch 124/500\n",
            "41/41 [==============================] - 0s 11ms/step - loss: 1.8963 - accuracy: 0.3912 - val_loss: 1.9623 - val_accuracy: 0.3931\n",
            "Epoch 125/500\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 1.8976 - accuracy: 0.3946 - val_loss: 1.9581 - val_accuracy: 0.3943\n",
            "Epoch 126/500\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 1.9114 - accuracy: 0.3919 - val_loss: 1.9556 - val_accuracy: 0.4001\n",
            "Epoch 127/500\n",
            "41/41 [==============================] - 0s 11ms/step - loss: 1.9069 - accuracy: 0.3923 - val_loss: 1.9681 - val_accuracy: 0.3751\n",
            "Epoch 128/500\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 1.8868 - accuracy: 0.3865 - val_loss: 1.9644 - val_accuracy: 0.3826\n",
            "Epoch 129/500\n",
            "41/41 [==============================] - 0s 11ms/step - loss: 1.8842 - accuracy: 0.4045 - val_loss: 1.9563 - val_accuracy: 0.3914\n",
            "Epoch 130/500\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 1.8771 - accuracy: 0.4087 - val_loss: 1.9586 - val_accuracy: 0.3949\n",
            "Epoch 131/500\n",
            "41/41 [==============================] - 0s 11ms/step - loss: 1.8687 - accuracy: 0.3985 - val_loss: 1.9590 - val_accuracy: 0.3861\n",
            "Epoch 132/500\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 1.8918 - accuracy: 0.3935 - val_loss: 1.9578 - val_accuracy: 0.3937\n",
            "Epoch 133/500\n",
            "41/41 [==============================] - 0s 11ms/step - loss: 1.8654 - accuracy: 0.4014 - val_loss: 1.9604 - val_accuracy: 0.3914\n",
            "Epoch 134/500\n",
            "41/41 [==============================] - 0s 11ms/step - loss: 1.8701 - accuracy: 0.3992 - val_loss: 1.9655 - val_accuracy: 0.3925\n",
            "Epoch 135/500\n",
            "41/41 [==============================] - 0s 12ms/step - loss: 1.8818 - accuracy: 0.3939 - val_loss: 1.9725 - val_accuracy: 0.3937\n",
            "Epoch 136/500\n",
            "41/41 [==============================] - 0s 11ms/step - loss: 1.8798 - accuracy: 0.3982 - val_loss: 1.9819 - val_accuracy: 0.3867\n",
            "Epoch 137/500\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 1.8883 - accuracy: 0.3970 - val_loss: 1.9609 - val_accuracy: 0.3850\n",
            "Epoch 138/500\n",
            "41/41 [==============================] - 0s 11ms/step - loss: 1.9080 - accuracy: 0.3881 - val_loss: 1.9609 - val_accuracy: 0.3914\n",
            "Epoch 139/500\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 1.8891 - accuracy: 0.3968 - val_loss: 1.9757 - val_accuracy: 0.3925\n",
            "Epoch 140/500\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 1.8900 - accuracy: 0.3937 - val_loss: 1.9651 - val_accuracy: 0.3920\n",
            "Epoch 141/500\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 1.8781 - accuracy: 0.3920 - val_loss: 1.9654 - val_accuracy: 0.3914\n",
            "Epoch 142/500\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 1.8670 - accuracy: 0.3975 - val_loss: 1.9592 - val_accuracy: 0.3943\n",
            "Epoch 143/500\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 1.8834 - accuracy: 0.4011 - val_loss: 1.9583 - val_accuracy: 0.3914\n",
            "Epoch 144/500\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 1.8542 - accuracy: 0.4053 - val_loss: 1.9663 - val_accuracy: 0.3902\n",
            "Epoch 145/500\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 1.8986 - accuracy: 0.3941 - val_loss: 1.9744 - val_accuracy: 0.3891\n",
            "Epoch 146/500\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 1.8786 - accuracy: 0.3958 - val_loss: 1.9586 - val_accuracy: 0.3949\n",
            "Epoch 147/500\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 1.8735 - accuracy: 0.4044 - val_loss: 1.9672 - val_accuracy: 0.3931\n",
            "Epoch 148/500\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 1.8715 - accuracy: 0.4085 - val_loss: 1.9600 - val_accuracy: 0.3949\n",
            "Epoch 149/500\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 1.8759 - accuracy: 0.4057 - val_loss: 1.9679 - val_accuracy: 0.3972\n",
            "Epoch 150/500\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 1.8888 - accuracy: 0.3896 - val_loss: 1.9671 - val_accuracy: 0.3931\n",
            "Epoch 151/500\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 1.8937 - accuracy: 0.3969 - val_loss: 1.9607 - val_accuracy: 0.3920\n",
            "Epoch 152/500\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 1.8496 - accuracy: 0.4015 - val_loss: 1.9655 - val_accuracy: 0.3850\n",
            "Epoch 153/500\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 1.9002 - accuracy: 0.3984 - val_loss: 1.9625 - val_accuracy: 0.3891\n",
            "Epoch 154/500\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 1.8594 - accuracy: 0.4061 - val_loss: 1.9692 - val_accuracy: 0.3832\n",
            "Epoch 155/500\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 1.8401 - accuracy: 0.4026 - val_loss: 1.9627 - val_accuracy: 0.3896\n",
            "Epoch 156/500\n",
            "41/41 [==============================] - 0s 11ms/step - loss: 1.8964 - accuracy: 0.3955 - val_loss: 1.9705 - val_accuracy: 0.3826\n",
            "Epoch 157/500\n",
            "41/41 [==============================] - 0s 11ms/step - loss: 1.8679 - accuracy: 0.3956 - val_loss: 1.9822 - val_accuracy: 0.3879\n",
            "Epoch 158/500\n",
            "41/41 [==============================] - 0s 11ms/step - loss: 1.8796 - accuracy: 0.3934 - val_loss: 1.9665 - val_accuracy: 0.3896\n",
            "Epoch 159/500\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 1.8757 - accuracy: 0.3963 - val_loss: 1.9685 - val_accuracy: 0.3960\n",
            "Epoch 160/500\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 1.8594 - accuracy: 0.4085 - val_loss: 1.9702 - val_accuracy: 0.3949\n",
            "Epoch 161/500\n",
            "41/41 [==============================] - 0s 11ms/step - loss: 1.8774 - accuracy: 0.4077 - val_loss: 1.9559 - val_accuracy: 0.3949\n",
            "Epoch 162/500\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 1.8609 - accuracy: 0.4031 - val_loss: 1.9615 - val_accuracy: 0.3990\n",
            "Epoch 163/500\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 1.8772 - accuracy: 0.4092 - val_loss: 1.9672 - val_accuracy: 0.3931\n",
            "Epoch 164/500\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 1.9020 - accuracy: 0.3887 - val_loss: 1.9635 - val_accuracy: 0.3960\n",
            "Epoch 165/500\n",
            "41/41 [==============================] - 0s 12ms/step - loss: 1.8720 - accuracy: 0.3947 - val_loss: 1.9690 - val_accuracy: 0.3925\n",
            "Epoch 166/500\n",
            "41/41 [==============================] - 0s 11ms/step - loss: 1.8565 - accuracy: 0.3970 - val_loss: 1.9782 - val_accuracy: 0.3920\n",
            "Epoch 167/500\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 1.8731 - accuracy: 0.3940 - val_loss: 1.9689 - val_accuracy: 0.3960\n",
            "Epoch 168/500\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 1.8765 - accuracy: 0.3927 - val_loss: 1.9630 - val_accuracy: 0.3990\n",
            "Epoch 169/500\n",
            "41/41 [==============================] - 0s 11ms/step - loss: 1.8758 - accuracy: 0.4060 - val_loss: 1.9789 - val_accuracy: 0.3908\n",
            "Epoch 170/500\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 1.8803 - accuracy: 0.3918 - val_loss: 1.9727 - val_accuracy: 0.3896\n",
            "Epoch 171/500\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 1.8635 - accuracy: 0.4034 - val_loss: 1.9674 - val_accuracy: 0.3943\n",
            "Epoch 172/500\n",
            "41/41 [==============================] - 0s 11ms/step - loss: 1.8848 - accuracy: 0.3986 - val_loss: 1.9618 - val_accuracy: 0.4001\n",
            "Epoch 173/500\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 1.8558 - accuracy: 0.4036 - val_loss: 1.9701 - val_accuracy: 0.3902\n",
            "Epoch 174/500\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 1.8690 - accuracy: 0.3972 - val_loss: 1.9724 - val_accuracy: 0.3960\n",
            "Epoch 175/500\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 1.9016 - accuracy: 0.3937 - val_loss: 1.9612 - val_accuracy: 0.3990\n",
            "Epoch 176/500\n",
            "41/41 [==============================] - 0s 10ms/step - loss: 1.8512 - accuracy: 0.3949 - val_loss: 1.9646 - val_accuracy: 0.3914\n",
            "Model Accuracy on test: 37.51%, Loss: 2.08\n",
            "保存模型：./model/myspace.h5\n",
            "TensorBoard 日志：./logs/myspace210312062155\n",
            "************************************************完成训练LSTM模型************************************************\n",
            "开始加载编码后的密码数据：./wordlist/phpbb.txt\n",
            "开始加载tokenizer模型：/content/tokenizer/phpbb.pkl\n",
            "将编码后的密码转换为（整数）序列\n",
            "Total Sequences: 15301\n",
            "Max Sequence Length: 17\n",
            "创建LSTM模型的输入输出\n",
            "X Shape: (15301, 16), y Shape: (15301,)\n",
            "划分训练集、验证集和测试集\n",
            "x_train Shape: (9180, 16), y_train Shape: (9180, 56)\n",
            "x_val Shape: (3060, 16), y_val Shape: (3060, 56)\n",
            "x_test Shape: (3061, 16), y_test Shape: (3061, 56)\n",
            "*************************************************创建LSTM模型*************************************************\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 16, 10)            560       \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 16, 32)            5504      \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, 16, 32)            8320      \n",
            "_________________________________________________________________\n",
            "lstm_5 (LSTM)                (None, 32)                8320      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 56)                1848      \n",
            "=================================================================\n",
            "Total params: 25,608\n",
            "Trainable params: 25,608\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "************************************************开始训练LSTM模型************************************************\n",
            "Epoch 1/500\n",
            "72/72 [==============================] - 6s 31ms/step - loss: 3.5893 - accuracy: 0.1560 - val_loss: 2.5374 - val_accuracy: 0.1801\n",
            "Epoch 2/500\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 2.4888 - accuracy: 0.1860 - val_loss: 2.4899 - val_accuracy: 0.1801\n",
            "Epoch 3/500\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 2.4677 - accuracy: 0.1999 - val_loss: 2.4800 - val_accuracy: 0.1801\n",
            "Epoch 4/500\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 2.4503 - accuracy: 0.1935 - val_loss: 2.4781 - val_accuracy: 0.1765\n",
            "Epoch 5/500\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 2.4550 - accuracy: 0.1908 - val_loss: 2.4832 - val_accuracy: 0.1801\n",
            "Epoch 6/500\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 2.4608 - accuracy: 0.1904 - val_loss: 2.4790 - val_accuracy: 0.1765\n",
            "Epoch 7/500\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 2.4430 - accuracy: 0.1937 - val_loss: 2.4769 - val_accuracy: 0.1801\n",
            "Epoch 8/500\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 2.4490 - accuracy: 0.1972 - val_loss: 2.4402 - val_accuracy: 0.1801\n",
            "Epoch 9/500\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 2.3606 - accuracy: 0.2527 - val_loss: 2.3228 - val_accuracy: 0.2915\n",
            "Epoch 10/500\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 2.2642 - accuracy: 0.3031 - val_loss: 2.2857 - val_accuracy: 0.3062\n",
            "Epoch 11/500\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 2.2370 - accuracy: 0.3114 - val_loss: 2.2745 - val_accuracy: 0.3049\n",
            "Epoch 12/500\n",
            "72/72 [==============================] - 1s 10ms/step - loss: 2.2293 - accuracy: 0.3159 - val_loss: 2.2646 - val_accuracy: 0.3141\n",
            "Epoch 13/500\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 2.2307 - accuracy: 0.3114 - val_loss: 2.2573 - val_accuracy: 0.3105\n",
            "Epoch 14/500\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 2.2236 - accuracy: 0.3121 - val_loss: 2.2595 - val_accuracy: 0.3095\n",
            "Epoch 15/500\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 2.1966 - accuracy: 0.3167 - val_loss: 2.2520 - val_accuracy: 0.3118\n",
            "Epoch 16/500\n",
            "72/72 [==============================] - 1s 11ms/step - loss: 2.2064 - accuracy: 0.3118 - val_loss: 2.2458 - val_accuracy: 0.3131\n",
            "Epoch 17/500\n",
            "72/72 [==============================] - 1s 11ms/step - loss: 2.2050 - accuracy: 0.3160 - val_loss: 2.2435 - val_accuracy: 0.3134\n",
            "Epoch 18/500\n",
            "72/72 [==============================] - 1s 11ms/step - loss: 2.1949 - accuracy: 0.3221 - val_loss: 2.2310 - val_accuracy: 0.3124\n",
            "Epoch 19/500\n",
            "72/72 [==============================] - 1s 10ms/step - loss: 2.1866 - accuracy: 0.3261 - val_loss: 2.2288 - val_accuracy: 0.3310\n",
            "Epoch 20/500\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 2.1665 - accuracy: 0.3392 - val_loss: 2.2125 - val_accuracy: 0.3549\n",
            "Epoch 21/500\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 2.1350 - accuracy: 0.3704 - val_loss: 2.1867 - val_accuracy: 0.3513\n",
            "Epoch 22/500\n",
            "72/72 [==============================] - 1s 10ms/step - loss: 2.1156 - accuracy: 0.3711 - val_loss: 2.1411 - val_accuracy: 0.3588\n",
            "Epoch 23/500\n",
            "72/72 [==============================] - 1s 10ms/step - loss: 2.0598 - accuracy: 0.3840 - val_loss: 2.0885 - val_accuracy: 0.3693\n",
            "Epoch 24/500\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 2.0137 - accuracy: 0.3902 - val_loss: 2.0727 - val_accuracy: 0.3673\n",
            "Epoch 25/500\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 2.0095 - accuracy: 0.3854 - val_loss: 2.0594 - val_accuracy: 0.3644\n",
            "Epoch 26/500\n",
            "72/72 [==============================] - 1s 10ms/step - loss: 1.9852 - accuracy: 0.3880 - val_loss: 2.0424 - val_accuracy: 0.3755\n",
            "Epoch 27/500\n",
            "72/72 [==============================] - 1s 10ms/step - loss: 1.9768 - accuracy: 0.3872 - val_loss: 2.0218 - val_accuracy: 0.3886\n",
            "Epoch 28/500\n",
            "72/72 [==============================] - 1s 11ms/step - loss: 1.9553 - accuracy: 0.3945 - val_loss: 2.0008 - val_accuracy: 0.3918\n",
            "Epoch 29/500\n",
            "72/72 [==============================] - 1s 10ms/step - loss: 1.9403 - accuracy: 0.3988 - val_loss: 1.9719 - val_accuracy: 0.3873\n",
            "Epoch 30/500\n",
            "72/72 [==============================] - 1s 10ms/step - loss: 1.9180 - accuracy: 0.4019 - val_loss: 1.9508 - val_accuracy: 0.3912\n",
            "Epoch 31/500\n",
            "72/72 [==============================] - 1s 10ms/step - loss: 1.8978 - accuracy: 0.4092 - val_loss: 1.9533 - val_accuracy: 0.3905\n",
            "Epoch 32/500\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 1.9172 - accuracy: 0.3994 - val_loss: 1.9385 - val_accuracy: 0.3990\n",
            "Epoch 33/500\n",
            "72/72 [==============================] - 1s 10ms/step - loss: 1.9072 - accuracy: 0.4063 - val_loss: 1.9307 - val_accuracy: 0.3990\n",
            "Epoch 34/500\n",
            "72/72 [==============================] - 1s 10ms/step - loss: 1.8813 - accuracy: 0.4125 - val_loss: 1.9246 - val_accuracy: 0.4020\n",
            "Epoch 35/500\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 1.8886 - accuracy: 0.4075 - val_loss: 1.9255 - val_accuracy: 0.3925\n",
            "Epoch 36/500\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 1.8840 - accuracy: 0.4081 - val_loss: 1.9181 - val_accuracy: 0.3941\n",
            "Epoch 37/500\n",
            "72/72 [==============================] - 1s 10ms/step - loss: 1.8534 - accuracy: 0.4202 - val_loss: 1.9211 - val_accuracy: 0.3918\n",
            "Epoch 38/500\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 1.8538 - accuracy: 0.4114 - val_loss: 1.9124 - val_accuracy: 0.3980\n",
            "Epoch 39/500\n",
            "72/72 [==============================] - 1s 10ms/step - loss: 1.8663 - accuracy: 0.4116 - val_loss: 1.9197 - val_accuracy: 0.3980\n",
            "Epoch 40/500\n",
            "72/72 [==============================] - 1s 11ms/step - loss: 1.8634 - accuracy: 0.4074 - val_loss: 1.9132 - val_accuracy: 0.3997\n",
            "Epoch 41/500\n",
            "72/72 [==============================] - 1s 10ms/step - loss: 1.8165 - accuracy: 0.4263 - val_loss: 1.9040 - val_accuracy: 0.3974\n",
            "Epoch 42/500\n",
            "72/72 [==============================] - 1s 10ms/step - loss: 1.8504 - accuracy: 0.4189 - val_loss: 1.9102 - val_accuracy: 0.4033\n",
            "Epoch 43/500\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 1.8396 - accuracy: 0.4147 - val_loss: 1.9016 - val_accuracy: 0.4056\n",
            "Epoch 44/500\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 1.8432 - accuracy: 0.4158 - val_loss: 1.9037 - val_accuracy: 0.4020\n",
            "Epoch 45/500\n",
            "72/72 [==============================] - 1s 10ms/step - loss: 1.8408 - accuracy: 0.4192 - val_loss: 1.8982 - val_accuracy: 0.4013\n",
            "Epoch 46/500\n",
            "72/72 [==============================] - 1s 11ms/step - loss: 1.8216 - accuracy: 0.4162 - val_loss: 1.8994 - val_accuracy: 0.4003\n",
            "Epoch 47/500\n",
            "72/72 [==============================] - 1s 11ms/step - loss: 1.8299 - accuracy: 0.4169 - val_loss: 1.8964 - val_accuracy: 0.3993\n",
            "Epoch 48/500\n",
            "72/72 [==============================] - 1s 11ms/step - loss: 1.8209 - accuracy: 0.4215 - val_loss: 1.8923 - val_accuracy: 0.4007\n",
            "Epoch 49/500\n",
            "72/72 [==============================] - 1s 10ms/step - loss: 1.8325 - accuracy: 0.4154 - val_loss: 1.9065 - val_accuracy: 0.3987\n",
            "Epoch 50/500\n",
            "72/72 [==============================] - 1s 10ms/step - loss: 1.8594 - accuracy: 0.4050 - val_loss: 1.8880 - val_accuracy: 0.4026\n",
            "Epoch 51/500\n",
            "72/72 [==============================] - 1s 10ms/step - loss: 1.8173 - accuracy: 0.4221 - val_loss: 1.8917 - val_accuracy: 0.4042\n",
            "Epoch 52/500\n",
            "72/72 [==============================] - 1s 11ms/step - loss: 1.8383 - accuracy: 0.4114 - val_loss: 1.8904 - val_accuracy: 0.3964\n",
            "Epoch 53/500\n",
            "72/72 [==============================] - 1s 11ms/step - loss: 1.8276 - accuracy: 0.4219 - val_loss: 1.8891 - val_accuracy: 0.3997\n",
            "Epoch 54/500\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 1.8259 - accuracy: 0.4105 - val_loss: 1.8862 - val_accuracy: 0.4000\n",
            "Epoch 55/500\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 1.8239 - accuracy: 0.4182 - val_loss: 1.8870 - val_accuracy: 0.4000\n",
            "Epoch 56/500\n",
            "72/72 [==============================] - 1s 10ms/step - loss: 1.8320 - accuracy: 0.4153 - val_loss: 1.8814 - val_accuracy: 0.4007\n",
            "Epoch 57/500\n",
            "72/72 [==============================] - 1s 11ms/step - loss: 1.8305 - accuracy: 0.4160 - val_loss: 1.8802 - val_accuracy: 0.4010\n",
            "Epoch 58/500\n",
            "72/72 [==============================] - 1s 10ms/step - loss: 1.7944 - accuracy: 0.4185 - val_loss: 1.8843 - val_accuracy: 0.4000\n",
            "Epoch 59/500\n",
            "72/72 [==============================] - 1s 10ms/step - loss: 1.8077 - accuracy: 0.4182 - val_loss: 1.8740 - val_accuracy: 0.4033\n",
            "Epoch 60/500\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 1.8207 - accuracy: 0.4187 - val_loss: 1.8762 - val_accuracy: 0.4046\n",
            "Epoch 61/500\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 1.8126 - accuracy: 0.4176 - val_loss: 1.9016 - val_accuracy: 0.3944\n",
            "Epoch 62/500\n",
            "72/72 [==============================] - 1s 10ms/step - loss: 1.8173 - accuracy: 0.4215 - val_loss: 1.8752 - val_accuracy: 0.4023\n",
            "Epoch 63/500\n",
            "72/72 [==============================] - 1s 11ms/step - loss: 1.8051 - accuracy: 0.4178 - val_loss: 1.8785 - val_accuracy: 0.3997\n",
            "Epoch 64/500\n",
            "72/72 [==============================] - 1s 11ms/step - loss: 1.8094 - accuracy: 0.4217 - val_loss: 1.8720 - val_accuracy: 0.4020\n",
            "Epoch 65/500\n",
            "72/72 [==============================] - 1s 11ms/step - loss: 1.8160 - accuracy: 0.4111 - val_loss: 1.8740 - val_accuracy: 0.4013\n",
            "Epoch 66/500\n",
            "72/72 [==============================] - 1s 11ms/step - loss: 1.8047 - accuracy: 0.4129 - val_loss: 1.8772 - val_accuracy: 0.3944\n",
            "Epoch 67/500\n",
            "72/72 [==============================] - 1s 11ms/step - loss: 1.8077 - accuracy: 0.4185 - val_loss: 1.8713 - val_accuracy: 0.3961\n",
            "Epoch 68/500\n",
            "72/72 [==============================] - 1s 11ms/step - loss: 1.8244 - accuracy: 0.4119 - val_loss: 1.8780 - val_accuracy: 0.4013\n",
            "Epoch 69/500\n",
            "72/72 [==============================] - 1s 11ms/step - loss: 1.7773 - accuracy: 0.4234 - val_loss: 1.8679 - val_accuracy: 0.4007\n",
            "Epoch 70/500\n",
            "72/72 [==============================] - 1s 11ms/step - loss: 1.8248 - accuracy: 0.4181 - val_loss: 1.8678 - val_accuracy: 0.3980\n",
            "Epoch 71/500\n",
            "72/72 [==============================] - 1s 11ms/step - loss: 1.7888 - accuracy: 0.4201 - val_loss: 1.8695 - val_accuracy: 0.4003\n",
            "Epoch 72/500\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 1.7960 - accuracy: 0.4227 - val_loss: 1.8633 - val_accuracy: 0.4003\n",
            "Epoch 73/500\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 1.7880 - accuracy: 0.4215 - val_loss: 1.8638 - val_accuracy: 0.4029\n",
            "Epoch 74/500\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 1.7798 - accuracy: 0.4235 - val_loss: 1.8629 - val_accuracy: 0.4000\n",
            "Epoch 75/500\n",
            "72/72 [==============================] - 1s 10ms/step - loss: 1.7988 - accuracy: 0.4234 - val_loss: 1.8621 - val_accuracy: 0.4039\n",
            "Epoch 76/500\n",
            "72/72 [==============================] - 1s 11ms/step - loss: 1.7938 - accuracy: 0.4173 - val_loss: 1.8628 - val_accuracy: 0.4003\n",
            "Epoch 77/500\n",
            "72/72 [==============================] - 1s 10ms/step - loss: 1.7790 - accuracy: 0.4260 - val_loss: 1.8619 - val_accuracy: 0.4013\n",
            "Epoch 78/500\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 1.7805 - accuracy: 0.4171 - val_loss: 1.8663 - val_accuracy: 0.3974\n",
            "Epoch 79/500\n",
            "72/72 [==============================] - 1s 10ms/step - loss: 1.7751 - accuracy: 0.4209 - val_loss: 1.8637 - val_accuracy: 0.4007\n",
            "Epoch 80/500\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 1.7961 - accuracy: 0.4227 - val_loss: 1.8603 - val_accuracy: 0.4039\n",
            "Epoch 81/500\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 1.7794 - accuracy: 0.4173 - val_loss: 1.8629 - val_accuracy: 0.3980\n",
            "Epoch 82/500\n",
            "72/72 [==============================] - 1s 10ms/step - loss: 1.7709 - accuracy: 0.4299 - val_loss: 1.8615 - val_accuracy: 0.4013\n",
            "Epoch 83/500\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 1.7704 - accuracy: 0.4264 - val_loss: 1.8591 - val_accuracy: 0.4046\n",
            "Epoch 84/500\n",
            "72/72 [==============================] - 1s 10ms/step - loss: 1.7674 - accuracy: 0.4278 - val_loss: 1.8615 - val_accuracy: 0.3987\n",
            "Epoch 85/500\n",
            "72/72 [==============================] - 1s 10ms/step - loss: 1.7922 - accuracy: 0.4244 - val_loss: 1.8617 - val_accuracy: 0.4000\n",
            "Epoch 86/500\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 1.7826 - accuracy: 0.4225 - val_loss: 1.8586 - val_accuracy: 0.4039\n",
            "Epoch 87/500\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 1.7707 - accuracy: 0.4246 - val_loss: 1.8614 - val_accuracy: 0.3993\n",
            "Epoch 88/500\n",
            "72/72 [==============================] - 1s 10ms/step - loss: 1.7638 - accuracy: 0.4262 - val_loss: 1.8659 - val_accuracy: 0.3990\n",
            "Epoch 89/500\n",
            "72/72 [==============================] - 1s 10ms/step - loss: 1.7554 - accuracy: 0.4263 - val_loss: 1.8682 - val_accuracy: 0.3977\n",
            "Epoch 90/500\n",
            "72/72 [==============================] - 1s 10ms/step - loss: 1.7849 - accuracy: 0.4235 - val_loss: 1.8648 - val_accuracy: 0.3990\n",
            "Epoch 91/500\n",
            "72/72 [==============================] - 1s 10ms/step - loss: 1.7624 - accuracy: 0.4261 - val_loss: 1.8588 - val_accuracy: 0.4039\n",
            "Epoch 92/500\n",
            "72/72 [==============================] - 1s 10ms/step - loss: 1.7581 - accuracy: 0.4250 - val_loss: 1.8662 - val_accuracy: 0.4016\n",
            "Epoch 93/500\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 1.7704 - accuracy: 0.4280 - val_loss: 1.8551 - val_accuracy: 0.4000\n",
            "Epoch 94/500\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 1.7694 - accuracy: 0.4264 - val_loss: 1.8572 - val_accuracy: 0.3967\n",
            "Epoch 95/500\n",
            "72/72 [==============================] - 1s 10ms/step - loss: 1.7641 - accuracy: 0.4275 - val_loss: 1.8575 - val_accuracy: 0.4033\n",
            "Epoch 96/500\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 1.7681 - accuracy: 0.4187 - val_loss: 1.8709 - val_accuracy: 0.4010\n",
            "Epoch 97/500\n",
            "72/72 [==============================] - 1s 10ms/step - loss: 1.7448 - accuracy: 0.4334 - val_loss: 1.8618 - val_accuracy: 0.3984\n",
            "Epoch 98/500\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 1.7758 - accuracy: 0.4213 - val_loss: 1.8592 - val_accuracy: 0.4039\n",
            "Epoch 99/500\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 1.7970 - accuracy: 0.4156 - val_loss: 1.8608 - val_accuracy: 0.4023\n",
            "Epoch 100/500\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 1.7635 - accuracy: 0.4214 - val_loss: 1.8616 - val_accuracy: 0.4010\n",
            "Epoch 101/500\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 1.7679 - accuracy: 0.4285 - val_loss: 1.8585 - val_accuracy: 0.4007\n",
            "Epoch 102/500\n",
            "72/72 [==============================] - 1s 11ms/step - loss: 1.7612 - accuracy: 0.4290 - val_loss: 1.8623 - val_accuracy: 0.4023\n",
            "Epoch 103/500\n",
            "72/72 [==============================] - 1s 11ms/step - loss: 1.7493 - accuracy: 0.4294 - val_loss: 1.8596 - val_accuracy: 0.3961\n",
            "Epoch 104/500\n",
            "72/72 [==============================] - 1s 10ms/step - loss: 1.7760 - accuracy: 0.4239 - val_loss: 1.8686 - val_accuracy: 0.4007\n",
            "Epoch 105/500\n",
            "72/72 [==============================] - 1s 10ms/step - loss: 1.7565 - accuracy: 0.4267 - val_loss: 1.8619 - val_accuracy: 0.4029\n",
            "Epoch 106/500\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 1.7468 - accuracy: 0.4311 - val_loss: 1.8592 - val_accuracy: 0.4036\n",
            "Epoch 107/500\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 1.7534 - accuracy: 0.4250 - val_loss: 1.8563 - val_accuracy: 0.3971\n",
            "Epoch 108/500\n",
            "72/72 [==============================] - 1s 10ms/step - loss: 1.7548 - accuracy: 0.4305 - val_loss: 1.8603 - val_accuracy: 0.3993\n",
            "Epoch 109/500\n",
            "72/72 [==============================] - 1s 11ms/step - loss: 1.7566 - accuracy: 0.4262 - val_loss: 1.8605 - val_accuracy: 0.4016\n",
            "Epoch 110/500\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 1.7624 - accuracy: 0.4215 - val_loss: 1.8596 - val_accuracy: 0.3980\n",
            "Epoch 111/500\n",
            "72/72 [==============================] - 1s 11ms/step - loss: 1.7592 - accuracy: 0.4244 - val_loss: 1.8614 - val_accuracy: 0.3977\n",
            "Epoch 112/500\n",
            "72/72 [==============================] - 1s 12ms/step - loss: 1.7559 - accuracy: 0.4296 - val_loss: 1.8651 - val_accuracy: 0.3984\n",
            "Epoch 113/500\n",
            "72/72 [==============================] - 1s 10ms/step - loss: 1.7268 - accuracy: 0.4359 - val_loss: 1.8672 - val_accuracy: 0.4016\n",
            "Epoch 114/500\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 1.7639 - accuracy: 0.4285 - val_loss: 1.8605 - val_accuracy: 0.4039\n",
            "Epoch 115/500\n",
            "72/72 [==============================] - 1s 10ms/step - loss: 1.7665 - accuracy: 0.4194 - val_loss: 1.8618 - val_accuracy: 0.4016\n",
            "Epoch 116/500\n",
            "72/72 [==============================] - 1s 10ms/step - loss: 1.7623 - accuracy: 0.4258 - val_loss: 1.8700 - val_accuracy: 0.3958\n",
            "Epoch 117/500\n",
            "72/72 [==============================] - 1s 11ms/step - loss: 1.7566 - accuracy: 0.4233 - val_loss: 1.8630 - val_accuracy: 0.3993\n",
            "Epoch 118/500\n",
            "72/72 [==============================] - 1s 11ms/step - loss: 1.7372 - accuracy: 0.4369 - val_loss: 1.8591 - val_accuracy: 0.4013\n",
            "Epoch 119/500\n",
            "72/72 [==============================] - 1s 11ms/step - loss: 1.7587 - accuracy: 0.4150 - val_loss: 1.8598 - val_accuracy: 0.4010\n",
            "Epoch 120/500\n",
            "72/72 [==============================] - 1s 11ms/step - loss: 1.7553 - accuracy: 0.4290 - val_loss: 1.8661 - val_accuracy: 0.3987\n",
            "Epoch 121/500\n",
            "72/72 [==============================] - 1s 10ms/step - loss: 1.7639 - accuracy: 0.4225 - val_loss: 1.8595 - val_accuracy: 0.4016\n",
            "Epoch 122/500\n",
            "72/72 [==============================] - 1s 10ms/step - loss: 1.7568 - accuracy: 0.4257 - val_loss: 1.8628 - val_accuracy: 0.4003\n",
            "Epoch 123/500\n",
            "72/72 [==============================] - 1s 10ms/step - loss: 1.7502 - accuracy: 0.4318 - val_loss: 1.8616 - val_accuracy: 0.4003\n",
            "Epoch 124/500\n",
            "72/72 [==============================] - 1s 10ms/step - loss: 1.7300 - accuracy: 0.4349 - val_loss: 1.8601 - val_accuracy: 0.4016\n",
            "Epoch 125/500\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 1.7658 - accuracy: 0.4250 - val_loss: 1.8650 - val_accuracy: 0.4036\n",
            "Epoch 126/500\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 1.7590 - accuracy: 0.4230 - val_loss: 1.8606 - val_accuracy: 0.4016\n",
            "Epoch 127/500\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 1.7555 - accuracy: 0.4307 - val_loss: 1.8677 - val_accuracy: 0.3967\n",
            "Epoch 128/500\n",
            "72/72 [==============================] - 1s 11ms/step - loss: 1.7615 - accuracy: 0.4193 - val_loss: 1.8644 - val_accuracy: 0.4000\n",
            "Epoch 129/500\n",
            "72/72 [==============================] - 1s 10ms/step - loss: 1.7490 - accuracy: 0.4294 - val_loss: 1.8674 - val_accuracy: 0.3967\n",
            "Epoch 130/500\n",
            "72/72 [==============================] - 1s 10ms/step - loss: 1.7533 - accuracy: 0.4269 - val_loss: 1.8601 - val_accuracy: 0.4023\n",
            "Epoch 131/500\n",
            "72/72 [==============================] - 1s 11ms/step - loss: 1.7390 - accuracy: 0.4341 - val_loss: 1.8745 - val_accuracy: 0.3944\n",
            "Epoch 132/500\n",
            "72/72 [==============================] - 1s 10ms/step - loss: 1.7401 - accuracy: 0.4233 - val_loss: 1.8608 - val_accuracy: 0.4042\n",
            "Epoch 133/500\n",
            "72/72 [==============================] - 1s 10ms/step - loss: 1.7457 - accuracy: 0.4343 - val_loss: 1.8651 - val_accuracy: 0.4003\n",
            "Epoch 134/500\n",
            "72/72 [==============================] - 1s 11ms/step - loss: 1.7606 - accuracy: 0.4303 - val_loss: 1.8636 - val_accuracy: 0.4013\n",
            "Epoch 135/500\n",
            "72/72 [==============================] - 1s 10ms/step - loss: 1.7314 - accuracy: 0.4347 - val_loss: 1.8653 - val_accuracy: 0.4026\n",
            "Epoch 136/500\n",
            "72/72 [==============================] - 1s 10ms/step - loss: 1.7225 - accuracy: 0.4347 - val_loss: 1.8651 - val_accuracy: 0.4010\n",
            "Epoch 137/500\n",
            "72/72 [==============================] - 1s 11ms/step - loss: 1.7243 - accuracy: 0.4412 - val_loss: 1.8731 - val_accuracy: 0.4026\n",
            "Epoch 138/500\n",
            "72/72 [==============================] - 1s 10ms/step - loss: 1.7448 - accuracy: 0.4314 - val_loss: 1.8651 - val_accuracy: 0.4010\n",
            "Epoch 139/500\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 1.7327 - accuracy: 0.4360 - val_loss: 1.8638 - val_accuracy: 0.4036\n",
            "Epoch 140/500\n",
            "72/72 [==============================] - 1s 10ms/step - loss: 1.7522 - accuracy: 0.4328 - val_loss: 1.8666 - val_accuracy: 0.4016\n",
            "Epoch 141/500\n",
            "72/72 [==============================] - 1s 9ms/step - loss: 1.7331 - accuracy: 0.4279 - val_loss: 1.8665 - val_accuracy: 0.3971\n",
            "Epoch 142/500\n",
            "72/72 [==============================] - 1s 10ms/step - loss: 1.7358 - accuracy: 0.4304 - val_loss: 1.8683 - val_accuracy: 0.4039\n",
            "Epoch 143/500\n",
            "72/72 [==============================] - 1s 10ms/step - loss: 1.7378 - accuracy: 0.4321 - val_loss: 1.8630 - val_accuracy: 0.4000\n",
            "Model Accuracy on test: 40.02%, Loss: 1.83\n",
            "保存模型：./model/phpbb.h5\n",
            "TensorBoard 日志：./logs/phpbb210312062317\n",
            "************************************************完成训练LSTM模型************************************************\n",
            "开始加载编码后的密码数据：./wordlist/myspace_7.txt\n",
            "开始加载tokenizer模型：/content/tokenizer/myspace_7.pkl\n",
            "将编码后的密码转换为（整数）序列\n",
            "Total Sequences: 6599\n",
            "Max Sequence Length: 15\n",
            "创建LSTM模型的输入输出\n",
            "X Shape: (6599, 14), y Shape: (6599,)\n",
            "划分训练集、验证集和测试集\n",
            "x_train Shape: (3959, 14), y_train Shape: (3959, 56)\n",
            "x_val Shape: (1320, 14), y_val Shape: (1320, 56)\n",
            "x_test Shape: (1320, 14), y_test Shape: (1320, 56)\n",
            "*************************************************创建LSTM模型*************************************************\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 14, 10)            560       \n",
            "_________________________________________________________________\n",
            "lstm_6 (LSTM)                (None, 14, 32)            5504      \n",
            "_________________________________________________________________\n",
            "lstm_7 (LSTM)                (None, 14, 32)            8320      \n",
            "_________________________________________________________________\n",
            "lstm_8 (LSTM)                (None, 32)                8320      \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 56)                1848      \n",
            "=================================================================\n",
            "Total params: 25,608\n",
            "Trainable params: 25,608\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "************************************************开始训练LSTM模型************************************************\n",
            "Epoch 1/500\n",
            "31/31 [==============================] - 5s 65ms/step - loss: 3.9616 - accuracy: 0.0345 - val_loss: 3.2934 - val_accuracy: 0.0644\n",
            "Epoch 2/500\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 3.0456 - accuracy: 0.1381 - val_loss: 2.7133 - val_accuracy: 0.1977\n",
            "Epoch 3/500\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 2.6606 - accuracy: 0.2117 - val_loss: 2.6492 - val_accuracy: 0.1977\n",
            "Epoch 4/500\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 2.6217 - accuracy: 0.2064 - val_loss: 2.6313 - val_accuracy: 0.1977\n",
            "Epoch 5/500\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 2.5737 - accuracy: 0.2225 - val_loss: 2.6348 - val_accuracy: 0.1977\n",
            "Epoch 6/500\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 2.5644 - accuracy: 0.2167 - val_loss: 2.6318 - val_accuracy: 0.1977\n",
            "Epoch 7/500\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 2.6079 - accuracy: 0.2072 - val_loss: 2.6355 - val_accuracy: 0.1977\n",
            "Epoch 8/500\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 2.5828 - accuracy: 0.2119 - val_loss: 2.6325 - val_accuracy: 0.1977\n",
            "Epoch 9/500\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 2.5951 - accuracy: 0.2082 - val_loss: 2.6317 - val_accuracy: 0.1977\n",
            "Epoch 10/500\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 2.5872 - accuracy: 0.2110 - val_loss: 2.6293 - val_accuracy: 0.1977\n",
            "Epoch 11/500\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 2.5848 - accuracy: 0.2050 - val_loss: 2.6302 - val_accuracy: 0.1977\n",
            "Epoch 12/500\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 2.5674 - accuracy: 0.2104 - val_loss: 2.6341 - val_accuracy: 0.1977\n",
            "Epoch 13/500\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 2.5620 - accuracy: 0.2160 - val_loss: 2.6317 - val_accuracy: 0.1977\n",
            "Epoch 14/500\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 2.6056 - accuracy: 0.2193 - val_loss: 2.6294 - val_accuracy: 0.1977\n",
            "Epoch 15/500\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 2.5691 - accuracy: 0.2195 - val_loss: 2.6297 - val_accuracy: 0.1977\n",
            "Epoch 16/500\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 2.5871 - accuracy: 0.2075 - val_loss: 2.6308 - val_accuracy: 0.1977\n",
            "Epoch 17/500\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 2.5959 - accuracy: 0.2105 - val_loss: 2.6310 - val_accuracy: 0.1977\n",
            "Epoch 18/500\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 2.5786 - accuracy: 0.2168 - val_loss: 2.6341 - val_accuracy: 0.1977\n",
            "Epoch 19/500\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 2.5637 - accuracy: 0.2111 - val_loss: 2.6305 - val_accuracy: 0.1977\n",
            "Epoch 20/500\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 2.6161 - accuracy: 0.2068 - val_loss: 2.6319 - val_accuracy: 0.1977\n",
            "Epoch 21/500\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 2.5905 - accuracy: 0.2034 - val_loss: 2.6325 - val_accuracy: 0.1977\n",
            "Epoch 22/500\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 2.6080 - accuracy: 0.2130 - val_loss: 2.6332 - val_accuracy: 0.1977\n",
            "Epoch 23/500\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 2.5685 - accuracy: 0.2118 - val_loss: 2.6312 - val_accuracy: 0.1977\n",
            "Epoch 24/500\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 2.5684 - accuracy: 0.2112 - val_loss: 2.6332 - val_accuracy: 0.1977\n",
            "Epoch 25/500\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 2.5845 - accuracy: 0.2116 - val_loss: 2.6302 - val_accuracy: 0.1977\n",
            "Epoch 26/500\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 2.5848 - accuracy: 0.2084 - val_loss: 2.6328 - val_accuracy: 0.1977\n",
            "Epoch 27/500\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 2.5481 - accuracy: 0.2164 - val_loss: 2.6322 - val_accuracy: 0.1977\n",
            "Epoch 28/500\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 2.5756 - accuracy: 0.2091 - val_loss: 2.6308 - val_accuracy: 0.1977\n",
            "Epoch 29/500\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 2.5597 - accuracy: 0.2215 - val_loss: 2.6316 - val_accuracy: 0.1977\n",
            "Epoch 30/500\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 2.6031 - accuracy: 0.2013 - val_loss: 2.6346 - val_accuracy: 0.1977\n",
            "Epoch 31/500\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 2.5825 - accuracy: 0.2167 - val_loss: 2.6321 - val_accuracy: 0.1977\n",
            "Epoch 32/500\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 2.5709 - accuracy: 0.2097 - val_loss: 2.6343 - val_accuracy: 0.1977\n",
            "Epoch 33/500\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 2.5771 - accuracy: 0.2099 - val_loss: 2.6338 - val_accuracy: 0.1977\n",
            "Epoch 34/500\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 2.5827 - accuracy: 0.2112 - val_loss: 2.6311 - val_accuracy: 0.1977\n",
            "Epoch 35/500\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 2.5983 - accuracy: 0.2027 - val_loss: 2.6285 - val_accuracy: 0.1977\n",
            "Epoch 36/500\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 2.5848 - accuracy: 0.2054 - val_loss: 2.5702 - val_accuracy: 0.1977\n",
            "Epoch 37/500\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 2.4912 - accuracy: 0.2263 - val_loss: 2.5339 - val_accuracy: 0.2356\n",
            "Epoch 38/500\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 2.4910 - accuracy: 0.2785 - val_loss: 2.5091 - val_accuracy: 0.2492\n",
            "Epoch 39/500\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 2.4629 - accuracy: 0.2529 - val_loss: 2.4968 - val_accuracy: 0.2576\n",
            "Epoch 40/500\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 2.4173 - accuracy: 0.2799 - val_loss: 2.4416 - val_accuracy: 0.2629\n",
            "Epoch 41/500\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 2.3645 - accuracy: 0.2899 - val_loss: 2.3976 - val_accuracy: 0.2894\n",
            "Epoch 42/500\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 2.3140 - accuracy: 0.2943 - val_loss: 2.3118 - val_accuracy: 0.3212\n",
            "Epoch 43/500\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 2.2243 - accuracy: 0.3292 - val_loss: 2.2467 - val_accuracy: 0.3280\n",
            "Epoch 44/500\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 2.1508 - accuracy: 0.3393 - val_loss: 2.2092 - val_accuracy: 0.3182\n",
            "Epoch 45/500\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 2.1717 - accuracy: 0.3213 - val_loss: 2.1800 - val_accuracy: 0.3167\n",
            "Epoch 46/500\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 2.1601 - accuracy: 0.3172 - val_loss: 2.1765 - val_accuracy: 0.3242\n",
            "Epoch 47/500\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 2.0993 - accuracy: 0.3290 - val_loss: 2.1695 - val_accuracy: 0.3121\n",
            "Epoch 48/500\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 2.1050 - accuracy: 0.3244 - val_loss: 2.1732 - val_accuracy: 0.3182\n",
            "Epoch 49/500\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 2.0857 - accuracy: 0.3268 - val_loss: 2.1355 - val_accuracy: 0.3265\n",
            "Epoch 50/500\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 2.0758 - accuracy: 0.3448 - val_loss: 2.1351 - val_accuracy: 0.3220\n",
            "Epoch 51/500\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 2.0614 - accuracy: 0.3413 - val_loss: 2.1263 - val_accuracy: 0.3303\n",
            "Epoch 52/500\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 2.0539 - accuracy: 0.3464 - val_loss: 2.1027 - val_accuracy: 0.3424\n",
            "Epoch 53/500\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 2.0554 - accuracy: 0.3627 - val_loss: 2.1037 - val_accuracy: 0.3439\n",
            "Epoch 54/500\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 2.0513 - accuracy: 0.3387 - val_loss: 2.0924 - val_accuracy: 0.3364\n",
            "Epoch 55/500\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 2.0458 - accuracy: 0.3505 - val_loss: 2.0826 - val_accuracy: 0.3455\n",
            "Epoch 56/500\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 2.0380 - accuracy: 0.3584 - val_loss: 2.0732 - val_accuracy: 0.3538\n",
            "Epoch 57/500\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 2.0177 - accuracy: 0.3620 - val_loss: 2.0754 - val_accuracy: 0.3523\n",
            "Epoch 58/500\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 1.9706 - accuracy: 0.3752 - val_loss: 2.0649 - val_accuracy: 0.3553\n",
            "Epoch 59/500\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 1.9861 - accuracy: 0.3732 - val_loss: 2.0572 - val_accuracy: 0.3568\n",
            "Epoch 60/500\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 2.0032 - accuracy: 0.3536 - val_loss: 2.0517 - val_accuracy: 0.3576\n",
            "Epoch 61/500\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 2.0089 - accuracy: 0.3571 - val_loss: 2.0473 - val_accuracy: 0.3659\n",
            "Epoch 62/500\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 1.9828 - accuracy: 0.3747 - val_loss: 2.0369 - val_accuracy: 0.3705\n",
            "Epoch 63/500\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 1.9420 - accuracy: 0.3822 - val_loss: 2.0307 - val_accuracy: 0.3894\n",
            "Epoch 64/500\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 1.9761 - accuracy: 0.3865 - val_loss: 2.0436 - val_accuracy: 0.3591\n",
            "Epoch 65/500\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 1.9621 - accuracy: 0.3754 - val_loss: 2.0205 - val_accuracy: 0.3909\n",
            "Epoch 66/500\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 1.9264 - accuracy: 0.3819 - val_loss: 2.0234 - val_accuracy: 0.3674\n",
            "Epoch 67/500\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 1.9181 - accuracy: 0.3960 - val_loss: 2.0220 - val_accuracy: 0.3765\n",
            "Epoch 68/500\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 1.8942 - accuracy: 0.3991 - val_loss: 2.0151 - val_accuracy: 0.3742\n",
            "Epoch 69/500\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 1.9223 - accuracy: 0.3939 - val_loss: 2.0144 - val_accuracy: 0.3750\n",
            "Epoch 70/500\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 1.9202 - accuracy: 0.3957 - val_loss: 2.0122 - val_accuracy: 0.3636\n",
            "Epoch 71/500\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 1.8948 - accuracy: 0.4013 - val_loss: 2.0093 - val_accuracy: 0.3765\n",
            "Epoch 72/500\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 1.9157 - accuracy: 0.3861 - val_loss: 2.0066 - val_accuracy: 0.3712\n",
            "Epoch 73/500\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 1.9116 - accuracy: 0.3880 - val_loss: 1.9997 - val_accuracy: 0.3856\n",
            "Epoch 74/500\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 1.9075 - accuracy: 0.3859 - val_loss: 1.9954 - val_accuracy: 0.3765\n",
            "Epoch 75/500\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 1.9318 - accuracy: 0.3837 - val_loss: 2.0123 - val_accuracy: 0.3735\n",
            "Epoch 76/500\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 1.9107 - accuracy: 0.3855 - val_loss: 1.9916 - val_accuracy: 0.3871\n",
            "Epoch 77/500\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 1.8814 - accuracy: 0.3950 - val_loss: 1.9919 - val_accuracy: 0.3795\n",
            "Epoch 78/500\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 1.8853 - accuracy: 0.3986 - val_loss: 1.9938 - val_accuracy: 0.3705\n",
            "Epoch 79/500\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 1.8533 - accuracy: 0.4137 - val_loss: 1.9968 - val_accuracy: 0.3667\n",
            "Epoch 80/500\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 1.8871 - accuracy: 0.3984 - val_loss: 1.9907 - val_accuracy: 0.3818\n",
            "Epoch 81/500\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 1.8799 - accuracy: 0.3980 - val_loss: 1.9907 - val_accuracy: 0.3864\n",
            "Epoch 82/500\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 1.8857 - accuracy: 0.4000 - val_loss: 1.9874 - val_accuracy: 0.3833\n",
            "Epoch 83/500\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 1.8900 - accuracy: 0.3918 - val_loss: 1.9935 - val_accuracy: 0.3758\n",
            "Epoch 84/500\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 1.9097 - accuracy: 0.3847 - val_loss: 1.9959 - val_accuracy: 0.3674\n",
            "Epoch 85/500\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 1.8626 - accuracy: 0.3999 - val_loss: 1.9981 - val_accuracy: 0.3674\n",
            "Epoch 86/500\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 1.8962 - accuracy: 0.3871 - val_loss: 1.9917 - val_accuracy: 0.3689\n",
            "Epoch 87/500\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 1.8734 - accuracy: 0.3971 - val_loss: 1.9926 - val_accuracy: 0.3788\n",
            "Epoch 88/500\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 1.8737 - accuracy: 0.3976 - val_loss: 1.9868 - val_accuracy: 0.3727\n",
            "Epoch 89/500\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 1.8816 - accuracy: 0.4014 - val_loss: 1.9883 - val_accuracy: 0.3848\n",
            "Epoch 90/500\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 1.8892 - accuracy: 0.3863 - val_loss: 1.9916 - val_accuracy: 0.3811\n",
            "Epoch 91/500\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 1.9024 - accuracy: 0.3898 - val_loss: 1.9890 - val_accuracy: 0.3712\n",
            "Epoch 92/500\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 1.8965 - accuracy: 0.3936 - val_loss: 1.9865 - val_accuracy: 0.3780\n",
            "Epoch 93/500\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 1.8256 - accuracy: 0.4074 - val_loss: 1.9924 - val_accuracy: 0.3727\n",
            "Epoch 94/500\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 1.8523 - accuracy: 0.3968 - val_loss: 1.9929 - val_accuracy: 0.3697\n",
            "Epoch 95/500\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 1.8634 - accuracy: 0.4108 - val_loss: 1.9930 - val_accuracy: 0.3720\n",
            "Epoch 96/500\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 1.8548 - accuracy: 0.3971 - val_loss: 1.9996 - val_accuracy: 0.3682\n",
            "Epoch 97/500\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 1.8676 - accuracy: 0.4036 - val_loss: 2.0036 - val_accuracy: 0.3568\n",
            "Epoch 98/500\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 1.8855 - accuracy: 0.3885 - val_loss: 2.0020 - val_accuracy: 0.3712\n",
            "Epoch 99/500\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 1.8722 - accuracy: 0.3959 - val_loss: 1.9903 - val_accuracy: 0.3795\n",
            "Epoch 100/500\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 1.8334 - accuracy: 0.4042 - val_loss: 1.9954 - val_accuracy: 0.3636\n",
            "Epoch 101/500\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 1.8533 - accuracy: 0.3965 - val_loss: 1.9919 - val_accuracy: 0.3795\n",
            "Epoch 102/500\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 1.8603 - accuracy: 0.4021 - val_loss: 1.9845 - val_accuracy: 0.3886\n",
            "Epoch 103/500\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 1.8515 - accuracy: 0.4103 - val_loss: 1.9872 - val_accuracy: 0.3742\n",
            "Epoch 104/500\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 1.8489 - accuracy: 0.3977 - val_loss: 1.9935 - val_accuracy: 0.3720\n",
            "Epoch 105/500\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 1.8308 - accuracy: 0.4055 - val_loss: 1.9889 - val_accuracy: 0.3720\n",
            "Epoch 106/500\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 1.8032 - accuracy: 0.4160 - val_loss: 1.9929 - val_accuracy: 0.3826\n",
            "Epoch 107/500\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 1.8390 - accuracy: 0.4090 - val_loss: 1.9868 - val_accuracy: 0.3864\n",
            "Epoch 108/500\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 1.8230 - accuracy: 0.4017 - val_loss: 1.9850 - val_accuracy: 0.3735\n",
            "Epoch 109/500\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 1.8142 - accuracy: 0.4054 - val_loss: 1.9930 - val_accuracy: 0.3727\n",
            "Epoch 110/500\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 1.8432 - accuracy: 0.4066 - val_loss: 1.9921 - val_accuracy: 0.3795\n",
            "Epoch 111/500\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 1.8508 - accuracy: 0.4034 - val_loss: 1.9936 - val_accuracy: 0.3735\n",
            "Epoch 112/500\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 1.8421 - accuracy: 0.4109 - val_loss: 1.9951 - val_accuracy: 0.3659\n",
            "Epoch 113/500\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 1.8307 - accuracy: 0.4070 - val_loss: 1.9892 - val_accuracy: 0.3856\n",
            "Epoch 114/500\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 1.8437 - accuracy: 0.4029 - val_loss: 1.9908 - val_accuracy: 0.3697\n",
            "Epoch 115/500\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 1.8327 - accuracy: 0.4073 - val_loss: 1.9936 - val_accuracy: 0.3727\n",
            "Epoch 116/500\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 1.8260 - accuracy: 0.4183 - val_loss: 1.9885 - val_accuracy: 0.3720\n",
            "Epoch 117/500\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 1.8201 - accuracy: 0.4023 - val_loss: 1.9875 - val_accuracy: 0.3879\n",
            "Epoch 118/500\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 1.8354 - accuracy: 0.4055 - val_loss: 1.9989 - val_accuracy: 0.3697\n",
            "Epoch 119/500\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 1.8549 - accuracy: 0.4043 - val_loss: 2.0094 - val_accuracy: 0.3712\n",
            "Epoch 120/500\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 1.8489 - accuracy: 0.3988 - val_loss: 1.9897 - val_accuracy: 0.3705\n",
            "Epoch 121/500\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 1.8586 - accuracy: 0.3994 - val_loss: 1.9920 - val_accuracy: 0.3727\n",
            "Epoch 122/500\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 1.8348 - accuracy: 0.4174 - val_loss: 1.9884 - val_accuracy: 0.3735\n",
            "Epoch 123/500\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 1.8330 - accuracy: 0.4007 - val_loss: 1.9942 - val_accuracy: 0.3652\n",
            "Epoch 124/500\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 1.8455 - accuracy: 0.4032 - val_loss: 1.9974 - val_accuracy: 0.3765\n",
            "Epoch 125/500\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 1.8263 - accuracy: 0.4195 - val_loss: 1.9902 - val_accuracy: 0.3780\n",
            "Epoch 126/500\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 1.7958 - accuracy: 0.4112 - val_loss: 2.0003 - val_accuracy: 0.3659\n",
            "Epoch 127/500\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 1.8203 - accuracy: 0.4011 - val_loss: 1.9936 - val_accuracy: 0.3818\n",
            "Epoch 128/500\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 1.7981 - accuracy: 0.4132 - val_loss: 1.9947 - val_accuracy: 0.3705\n",
            "Epoch 129/500\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 1.8519 - accuracy: 0.4029 - val_loss: 1.9951 - val_accuracy: 0.3758\n",
            "Epoch 130/500\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 1.8290 - accuracy: 0.4028 - val_loss: 2.0002 - val_accuracy: 0.3659\n",
            "Epoch 131/500\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 1.8062 - accuracy: 0.4093 - val_loss: 1.9984 - val_accuracy: 0.3652\n",
            "Epoch 132/500\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 1.8220 - accuracy: 0.4114 - val_loss: 1.9964 - val_accuracy: 0.3644\n",
            "Epoch 133/500\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 1.8276 - accuracy: 0.4033 - val_loss: 2.0020 - val_accuracy: 0.3818\n",
            "Epoch 134/500\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 1.8055 - accuracy: 0.4130 - val_loss: 1.9954 - val_accuracy: 0.3788\n",
            "Epoch 135/500\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 1.8041 - accuracy: 0.4042 - val_loss: 1.9952 - val_accuracy: 0.3818\n",
            "Epoch 136/500\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 1.8261 - accuracy: 0.4014 - val_loss: 2.0135 - val_accuracy: 0.3636\n",
            "Epoch 137/500\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 1.7950 - accuracy: 0.4191 - val_loss: 1.9950 - val_accuracy: 0.3606\n",
            "Epoch 138/500\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 1.7937 - accuracy: 0.4211 - val_loss: 2.0023 - val_accuracy: 0.3621\n",
            "Epoch 139/500\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 1.8281 - accuracy: 0.4112 - val_loss: 2.0031 - val_accuracy: 0.3674\n",
            "Epoch 140/500\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 1.8017 - accuracy: 0.4001 - val_loss: 2.0028 - val_accuracy: 0.3621\n",
            "Epoch 141/500\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 1.7899 - accuracy: 0.4101 - val_loss: 2.0017 - val_accuracy: 0.3712\n",
            "Epoch 142/500\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 1.8157 - accuracy: 0.4099 - val_loss: 2.0136 - val_accuracy: 0.3697\n",
            "Epoch 143/500\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 1.8058 - accuracy: 0.4057 - val_loss: 2.0064 - val_accuracy: 0.3644\n",
            "Epoch 144/500\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 1.8401 - accuracy: 0.4007 - val_loss: 2.0013 - val_accuracy: 0.3659\n",
            "Epoch 145/500\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 1.7882 - accuracy: 0.4245 - val_loss: 1.9972 - val_accuracy: 0.3811\n",
            "Epoch 146/500\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 1.8071 - accuracy: 0.4053 - val_loss: 2.0107 - val_accuracy: 0.3591\n",
            "Epoch 147/500\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 1.8107 - accuracy: 0.4006 - val_loss: 2.0097 - val_accuracy: 0.3667\n",
            "Epoch 148/500\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 1.8246 - accuracy: 0.4088 - val_loss: 2.0081 - val_accuracy: 0.3636\n",
            "Epoch 149/500\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 1.7829 - accuracy: 0.4188 - val_loss: 2.0196 - val_accuracy: 0.3606\n",
            "Epoch 150/500\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 1.8028 - accuracy: 0.4113 - val_loss: 2.0086 - val_accuracy: 0.3583\n",
            "Epoch 151/500\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 1.7759 - accuracy: 0.4152 - val_loss: 2.0012 - val_accuracy: 0.3811\n",
            "Epoch 152/500\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 1.7977 - accuracy: 0.4154 - val_loss: 2.0037 - val_accuracy: 0.3856\n",
            "Model Accuracy on test: 36.67%, Loss: 2.08\n",
            "保存模型：./model/myspace_7.h5\n",
            "TensorBoard 日志：./logs/myspace_7210312062506\n",
            "************************************************完成训练LSTM模型************************************************\n",
            "开始加载编码后的密码数据：./wordlist/phpbb_7.txt\n",
            "开始加载tokenizer模型：/content/tokenizer/phpbb_7.pkl\n",
            "将编码后的密码转换为（整数）序列\n",
            "Total Sequences: 12340\n",
            "Max Sequence Length: 17\n",
            "创建LSTM模型的输入输出\n",
            "X Shape: (12340, 16), y Shape: (12340,)\n",
            "划分训练集、验证集和测试集\n",
            "x_train Shape: (7404, 16), y_train Shape: (7404, 53)\n",
            "x_val Shape: (2468, 16), y_val Shape: (2468, 53)\n",
            "x_test Shape: (2468, 16), y_test Shape: (2468, 53)\n",
            "*************************************************创建LSTM模型*************************************************\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 16, 10)            530       \n",
            "_________________________________________________________________\n",
            "lstm_9 (LSTM)                (None, 16, 32)            5504      \n",
            "_________________________________________________________________\n",
            "lstm_10 (LSTM)               (None, 16, 32)            8320      \n",
            "_________________________________________________________________\n",
            "lstm_11 (LSTM)               (None, 32)                8320      \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 53)                1749      \n",
            "=================================================================\n",
            "Total params: 25,479\n",
            "Trainable params: 25,479\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "************************************************开始训练LSTM模型************************************************\n",
            "Epoch 1/500\n",
            "58/58 [==============================] - 6s 38ms/step - loss: 3.6151 - accuracy: 0.1342 - val_loss: 2.5174 - val_accuracy: 0.1835\n",
            "Epoch 2/500\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 2.5032 - accuracy: 0.1839 - val_loss: 2.4763 - val_accuracy: 0.1835\n",
            "Epoch 3/500\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 2.4747 - accuracy: 0.2024 - val_loss: 2.4772 - val_accuracy: 0.1835\n",
            "Epoch 4/500\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 2.4563 - accuracy: 0.1987 - val_loss: 2.4697 - val_accuracy: 0.1835\n",
            "Epoch 5/500\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 2.4572 - accuracy: 0.2010 - val_loss: 2.4714 - val_accuracy: 0.1835\n",
            "Epoch 6/500\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 2.4502 - accuracy: 0.2005 - val_loss: 2.4727 - val_accuracy: 0.1835\n",
            "Epoch 7/500\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 2.4548 - accuracy: 0.2002 - val_loss: 2.4734 - val_accuracy: 0.1835\n",
            "Epoch 8/500\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 2.4367 - accuracy: 0.1976 - val_loss: 2.4738 - val_accuracy: 0.1835\n",
            "Epoch 9/500\n",
            "58/58 [==============================] - 1s 12ms/step - loss: 2.4524 - accuracy: 0.1992 - val_loss: 2.4747 - val_accuracy: 0.1835\n",
            "Epoch 10/500\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 2.4695 - accuracy: 0.1964 - val_loss: 2.4740 - val_accuracy: 0.1669\n",
            "Epoch 11/500\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 2.4632 - accuracy: 0.1891 - val_loss: 2.4766 - val_accuracy: 0.1669\n",
            "Epoch 12/500\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 2.4592 - accuracy: 0.1922 - val_loss: 2.4753 - val_accuracy: 0.1835\n",
            "Epoch 13/500\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 2.4470 - accuracy: 0.1965 - val_loss: 2.4765 - val_accuracy: 0.1835\n",
            "Epoch 14/500\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 2.4425 - accuracy: 0.1922 - val_loss: 2.4762 - val_accuracy: 0.1835\n",
            "Epoch 15/500\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 2.4351 - accuracy: 0.1860 - val_loss: 2.4734 - val_accuracy: 0.1835\n",
            "Epoch 16/500\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 2.4702 - accuracy: 0.1899 - val_loss: 2.4746 - val_accuracy: 0.1835\n",
            "Epoch 17/500\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 2.4445 - accuracy: 0.2053 - val_loss: 2.4518 - val_accuracy: 0.1835\n",
            "Epoch 18/500\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 2.3985 - accuracy: 0.2164 - val_loss: 2.3606 - val_accuracy: 0.2650\n",
            "Epoch 19/500\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 2.3288 - accuracy: 0.2712 - val_loss: 2.2907 - val_accuracy: 0.2897\n",
            "Epoch 20/500\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 2.2716 - accuracy: 0.3043 - val_loss: 2.2942 - val_accuracy: 0.2812\n",
            "Epoch 21/500\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 2.2211 - accuracy: 0.3144 - val_loss: 2.2633 - val_accuracy: 0.2954\n",
            "Epoch 22/500\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 2.2087 - accuracy: 0.3193 - val_loss: 2.2655 - val_accuracy: 0.2978\n",
            "Epoch 23/500\n",
            "58/58 [==============================] - 1s 12ms/step - loss: 2.1918 - accuracy: 0.3197 - val_loss: 2.2552 - val_accuracy: 0.2990\n",
            "Epoch 24/500\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 2.2007 - accuracy: 0.3113 - val_loss: 2.2589 - val_accuracy: 0.2950\n",
            "Epoch 25/500\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 2.1899 - accuracy: 0.3113 - val_loss: 2.2510 - val_accuracy: 0.2978\n",
            "Epoch 26/500\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 2.1882 - accuracy: 0.3204 - val_loss: 2.2483 - val_accuracy: 0.2994\n",
            "Epoch 27/500\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 2.1891 - accuracy: 0.3160 - val_loss: 2.2497 - val_accuracy: 0.2958\n",
            "Epoch 28/500\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 2.1776 - accuracy: 0.3219 - val_loss: 2.2521 - val_accuracy: 0.2990\n",
            "Epoch 29/500\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 2.1805 - accuracy: 0.3102 - val_loss: 2.2540 - val_accuracy: 0.2938\n",
            "Epoch 30/500\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 2.2081 - accuracy: 0.3099 - val_loss: 2.2441 - val_accuracy: 0.2958\n",
            "Epoch 31/500\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 2.1799 - accuracy: 0.3141 - val_loss: 2.2433 - val_accuracy: 0.2966\n",
            "Epoch 32/500\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 2.1783 - accuracy: 0.3082 - val_loss: 2.2364 - val_accuracy: 0.3104\n",
            "Epoch 33/500\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 2.1576 - accuracy: 0.3286 - val_loss: 2.2167 - val_accuracy: 0.3448\n",
            "Epoch 34/500\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 2.1243 - accuracy: 0.3670 - val_loss: 2.1459 - val_accuracy: 0.3744\n",
            "Epoch 35/500\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 2.0395 - accuracy: 0.3960 - val_loss: 2.0493 - val_accuracy: 0.3886\n",
            "Epoch 36/500\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 1.9826 - accuracy: 0.3993 - val_loss: 2.0028 - val_accuracy: 0.3926\n",
            "Epoch 37/500\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 1.9120 - accuracy: 0.4111 - val_loss: 1.9861 - val_accuracy: 0.3926\n",
            "Epoch 38/500\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 1.8819 - accuracy: 0.4190 - val_loss: 1.9644 - val_accuracy: 0.3951\n",
            "Epoch 39/500\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 1.8612 - accuracy: 0.4217 - val_loss: 1.9614 - val_accuracy: 0.3951\n",
            "Epoch 40/500\n",
            "58/58 [==============================] - 1s 12ms/step - loss: 1.8779 - accuracy: 0.4114 - val_loss: 1.9512 - val_accuracy: 0.4007\n",
            "Epoch 41/500\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 1.8713 - accuracy: 0.4075 - val_loss: 1.9390 - val_accuracy: 0.3995\n",
            "Epoch 42/500\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 1.8481 - accuracy: 0.4219 - val_loss: 1.9406 - val_accuracy: 0.3991\n",
            "Epoch 43/500\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 1.8559 - accuracy: 0.4200 - val_loss: 1.9362 - val_accuracy: 0.4007\n",
            "Epoch 44/500\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 1.8456 - accuracy: 0.4232 - val_loss: 1.9328 - val_accuracy: 0.4019\n",
            "Epoch 45/500\n",
            "58/58 [==============================] - 1s 13ms/step - loss: 1.8740 - accuracy: 0.4087 - val_loss: 1.9379 - val_accuracy: 0.4007\n",
            "Epoch 46/500\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 1.8280 - accuracy: 0.4317 - val_loss: 1.9328 - val_accuracy: 0.4015\n",
            "Epoch 47/500\n",
            "58/58 [==============================] - 1s 12ms/step - loss: 1.8426 - accuracy: 0.4182 - val_loss: 1.9298 - val_accuracy: 0.4040\n",
            "Epoch 48/500\n",
            "58/58 [==============================] - 1s 12ms/step - loss: 1.8345 - accuracy: 0.4229 - val_loss: 1.9383 - val_accuracy: 0.4048\n",
            "Epoch 49/500\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 1.8470 - accuracy: 0.4207 - val_loss: 1.9336 - val_accuracy: 0.3999\n",
            "Epoch 50/500\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 1.8304 - accuracy: 0.4240 - val_loss: 1.9297 - val_accuracy: 0.3983\n",
            "Epoch 51/500\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 1.8340 - accuracy: 0.4190 - val_loss: 1.9351 - val_accuracy: 0.4036\n",
            "Epoch 52/500\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 1.8273 - accuracy: 0.4228 - val_loss: 1.9339 - val_accuracy: 0.3999\n",
            "Epoch 53/500\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 1.8168 - accuracy: 0.4264 - val_loss: 1.9326 - val_accuracy: 0.4019\n",
            "Epoch 54/500\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 1.8448 - accuracy: 0.4209 - val_loss: 1.9278 - val_accuracy: 0.4007\n",
            "Epoch 55/500\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 1.8373 - accuracy: 0.4161 - val_loss: 1.9353 - val_accuracy: 0.3983\n",
            "Epoch 56/500\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 1.8310 - accuracy: 0.4233 - val_loss: 1.9354 - val_accuracy: 0.3987\n",
            "Epoch 57/500\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 1.8337 - accuracy: 0.4206 - val_loss: 1.9268 - val_accuracy: 0.3991\n",
            "Epoch 58/500\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 1.8297 - accuracy: 0.4203 - val_loss: 1.9314 - val_accuracy: 0.4019\n",
            "Epoch 59/500\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 1.8451 - accuracy: 0.4198 - val_loss: 1.9324 - val_accuracy: 0.3999\n",
            "Epoch 60/500\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 1.8109 - accuracy: 0.4230 - val_loss: 1.9274 - val_accuracy: 0.3999\n",
            "Epoch 61/500\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 1.8114 - accuracy: 0.4256 - val_loss: 1.9253 - val_accuracy: 0.4007\n",
            "Epoch 62/500\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 1.8149 - accuracy: 0.4229 - val_loss: 1.9239 - val_accuracy: 0.4019\n",
            "Epoch 63/500\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 1.8467 - accuracy: 0.4113 - val_loss: 1.9255 - val_accuracy: 0.4019\n",
            "Epoch 64/500\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 1.8386 - accuracy: 0.4145 - val_loss: 1.9289 - val_accuracy: 0.3987\n",
            "Epoch 65/500\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 1.8431 - accuracy: 0.4157 - val_loss: 1.9292 - val_accuracy: 0.4003\n",
            "Epoch 66/500\n",
            "58/58 [==============================] - 1s 12ms/step - loss: 1.8220 - accuracy: 0.4178 - val_loss: 1.9332 - val_accuracy: 0.4003\n",
            "Epoch 67/500\n",
            "58/58 [==============================] - 1s 12ms/step - loss: 1.8111 - accuracy: 0.4248 - val_loss: 1.9295 - val_accuracy: 0.4011\n",
            "Epoch 68/500\n",
            "58/58 [==============================] - 1s 12ms/step - loss: 1.8386 - accuracy: 0.4150 - val_loss: 1.9276 - val_accuracy: 0.3955\n",
            "Epoch 69/500\n",
            "58/58 [==============================] - 1s 12ms/step - loss: 1.8170 - accuracy: 0.4231 - val_loss: 1.9319 - val_accuracy: 0.3959\n",
            "Epoch 70/500\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 1.8209 - accuracy: 0.4200 - val_loss: 1.9331 - val_accuracy: 0.4007\n",
            "Epoch 71/500\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 1.8017 - accuracy: 0.4233 - val_loss: 1.9343 - val_accuracy: 0.3975\n",
            "Epoch 72/500\n",
            "58/58 [==============================] - 1s 12ms/step - loss: 1.8127 - accuracy: 0.4274 - val_loss: 1.9220 - val_accuracy: 0.4003\n",
            "Epoch 73/500\n",
            "58/58 [==============================] - 1s 12ms/step - loss: 1.7975 - accuracy: 0.4229 - val_loss: 1.9234 - val_accuracy: 0.3947\n",
            "Epoch 74/500\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 1.8119 - accuracy: 0.4197 - val_loss: 1.9225 - val_accuracy: 0.3991\n",
            "Epoch 75/500\n",
            "58/58 [==============================] - 1s 12ms/step - loss: 1.8037 - accuracy: 0.4247 - val_loss: 1.9350 - val_accuracy: 0.3975\n",
            "Epoch 76/500\n",
            "58/58 [==============================] - 1s 13ms/step - loss: 1.7839 - accuracy: 0.4251 - val_loss: 1.9230 - val_accuracy: 0.4007\n",
            "Epoch 77/500\n",
            "58/58 [==============================] - 1s 12ms/step - loss: 1.7877 - accuracy: 0.4330 - val_loss: 1.9189 - val_accuracy: 0.3971\n",
            "Epoch 78/500\n",
            "58/58 [==============================] - 1s 12ms/step - loss: 1.7914 - accuracy: 0.4245 - val_loss: 1.9203 - val_accuracy: 0.3971\n",
            "Epoch 79/500\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 1.8006 - accuracy: 0.4275 - val_loss: 1.9184 - val_accuracy: 0.3959\n",
            "Epoch 80/500\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 1.8039 - accuracy: 0.4233 - val_loss: 1.9208 - val_accuracy: 0.3922\n",
            "Epoch 81/500\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 1.7841 - accuracy: 0.4289 - val_loss: 1.9157 - val_accuracy: 0.3987\n",
            "Epoch 82/500\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 1.7868 - accuracy: 0.4210 - val_loss: 1.9151 - val_accuracy: 0.3967\n",
            "Epoch 83/500\n",
            "58/58 [==============================] - 1s 12ms/step - loss: 1.7937 - accuracy: 0.4292 - val_loss: 1.9168 - val_accuracy: 0.3967\n",
            "Epoch 84/500\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 1.7682 - accuracy: 0.4291 - val_loss: 1.9143 - val_accuracy: 0.3959\n",
            "Epoch 85/500\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 1.7763 - accuracy: 0.4306 - val_loss: 1.9180 - val_accuracy: 0.3947\n",
            "Epoch 86/500\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 1.7961 - accuracy: 0.4156 - val_loss: 1.9179 - val_accuracy: 0.3987\n",
            "Epoch 87/500\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 1.7683 - accuracy: 0.4290 - val_loss: 1.9095 - val_accuracy: 0.3955\n",
            "Epoch 88/500\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 1.7832 - accuracy: 0.4240 - val_loss: 1.9094 - val_accuracy: 0.3995\n",
            "Epoch 89/500\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 1.7725 - accuracy: 0.4245 - val_loss: 1.9106 - val_accuracy: 0.3987\n",
            "Epoch 90/500\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 1.7482 - accuracy: 0.4362 - val_loss: 1.9016 - val_accuracy: 0.3942\n",
            "Epoch 91/500\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 1.7667 - accuracy: 0.4316 - val_loss: 1.9020 - val_accuracy: 0.3959\n",
            "Epoch 92/500\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 1.7631 - accuracy: 0.4304 - val_loss: 1.9088 - val_accuracy: 0.4032\n",
            "Epoch 93/500\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 1.7714 - accuracy: 0.4278 - val_loss: 1.9028 - val_accuracy: 0.4003\n",
            "Epoch 94/500\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 1.7731 - accuracy: 0.4254 - val_loss: 1.8982 - val_accuracy: 0.4028\n",
            "Epoch 95/500\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 1.7685 - accuracy: 0.4181 - val_loss: 1.9011 - val_accuracy: 0.4007\n",
            "Epoch 96/500\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 1.7568 - accuracy: 0.4254 - val_loss: 1.9237 - val_accuracy: 0.3983\n",
            "Epoch 97/500\n",
            "58/58 [==============================] - 1s 12ms/step - loss: 1.7363 - accuracy: 0.4401 - val_loss: 1.8942 - val_accuracy: 0.4003\n",
            "Epoch 98/500\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 1.7431 - accuracy: 0.4339 - val_loss: 1.8990 - val_accuracy: 0.4019\n",
            "Epoch 99/500\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 1.7312 - accuracy: 0.4388 - val_loss: 1.8960 - val_accuracy: 0.3983\n",
            "Epoch 100/500\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 1.7628 - accuracy: 0.4210 - val_loss: 1.9002 - val_accuracy: 0.3995\n",
            "Epoch 101/500\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 1.7414 - accuracy: 0.4350 - val_loss: 1.8946 - val_accuracy: 0.4024\n",
            "Epoch 102/500\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 1.7580 - accuracy: 0.4270 - val_loss: 1.8984 - val_accuracy: 0.3979\n",
            "Epoch 103/500\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 1.7370 - accuracy: 0.4403 - val_loss: 1.8937 - val_accuracy: 0.4007\n",
            "Epoch 104/500\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 1.7424 - accuracy: 0.4350 - val_loss: 1.8976 - val_accuracy: 0.4011\n",
            "Epoch 105/500\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 1.7540 - accuracy: 0.4271 - val_loss: 1.9049 - val_accuracy: 0.4048\n",
            "Epoch 106/500\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 1.7506 - accuracy: 0.4224 - val_loss: 1.8891 - val_accuracy: 0.4007\n",
            "Epoch 107/500\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 1.7481 - accuracy: 0.4313 - val_loss: 1.8890 - val_accuracy: 0.4019\n",
            "Epoch 108/500\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 1.7409 - accuracy: 0.4297 - val_loss: 1.8893 - val_accuracy: 0.3951\n",
            "Epoch 109/500\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 1.7370 - accuracy: 0.4325 - val_loss: 1.8953 - val_accuracy: 0.3995\n",
            "Epoch 110/500\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 1.7244 - accuracy: 0.4308 - val_loss: 1.8930 - val_accuracy: 0.3995\n",
            "Epoch 111/500\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 1.7385 - accuracy: 0.4331 - val_loss: 1.8961 - val_accuracy: 0.3991\n",
            "Epoch 112/500\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 1.7218 - accuracy: 0.4357 - val_loss: 1.8898 - val_accuracy: 0.3999\n",
            "Epoch 113/500\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 1.7447 - accuracy: 0.4322 - val_loss: 1.8884 - val_accuracy: 0.4024\n",
            "Epoch 114/500\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 1.7158 - accuracy: 0.4376 - val_loss: 1.8955 - val_accuracy: 0.3999\n",
            "Epoch 115/500\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 1.7392 - accuracy: 0.4238 - val_loss: 1.8922 - val_accuracy: 0.3991\n",
            "Epoch 116/500\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 1.7526 - accuracy: 0.4292 - val_loss: 1.8901 - val_accuracy: 0.4007\n",
            "Epoch 117/500\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 1.7391 - accuracy: 0.4296 - val_loss: 1.8902 - val_accuracy: 0.4028\n",
            "Epoch 118/500\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 1.7415 - accuracy: 0.4286 - val_loss: 1.8920 - val_accuracy: 0.4003\n",
            "Epoch 119/500\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 1.7384 - accuracy: 0.4290 - val_loss: 1.8998 - val_accuracy: 0.4044\n",
            "Epoch 120/500\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 1.7355 - accuracy: 0.4381 - val_loss: 1.8901 - val_accuracy: 0.4028\n",
            "Epoch 121/500\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 1.7117 - accuracy: 0.4413 - val_loss: 1.8977 - val_accuracy: 0.4048\n",
            "Epoch 122/500\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 1.7245 - accuracy: 0.4355 - val_loss: 1.8986 - val_accuracy: 0.3975\n",
            "Epoch 123/500\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 1.7398 - accuracy: 0.4338 - val_loss: 1.8909 - val_accuracy: 0.4011\n",
            "Epoch 124/500\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 1.7422 - accuracy: 0.4324 - val_loss: 1.8945 - val_accuracy: 0.3963\n",
            "Epoch 125/500\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 1.7298 - accuracy: 0.4372 - val_loss: 1.8978 - val_accuracy: 0.3995\n",
            "Epoch 126/500\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 1.7372 - accuracy: 0.4305 - val_loss: 1.8958 - val_accuracy: 0.3999\n",
            "Epoch 127/500\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 1.7306 - accuracy: 0.4260 - val_loss: 1.8947 - val_accuracy: 0.4015\n",
            "Epoch 128/500\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 1.7309 - accuracy: 0.4341 - val_loss: 1.8986 - val_accuracy: 0.3951\n",
            "Epoch 129/500\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 1.7236 - accuracy: 0.4354 - val_loss: 1.8928 - val_accuracy: 0.3979\n",
            "Epoch 130/500\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 1.7207 - accuracy: 0.4349 - val_loss: 1.8947 - val_accuracy: 0.3955\n",
            "Epoch 131/500\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 1.7496 - accuracy: 0.4285 - val_loss: 1.9007 - val_accuracy: 0.4024\n",
            "Epoch 132/500\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 1.7233 - accuracy: 0.4364 - val_loss: 1.8935 - val_accuracy: 0.4007\n",
            "Epoch 133/500\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 1.7036 - accuracy: 0.4410 - val_loss: 1.8919 - val_accuracy: 0.3991\n",
            "Epoch 134/500\n",
            "58/58 [==============================] - 1s 12ms/step - loss: 1.7327 - accuracy: 0.4385 - val_loss: 1.8960 - val_accuracy: 0.4011\n",
            "Epoch 135/500\n",
            "58/58 [==============================] - 1s 12ms/step - loss: 1.7148 - accuracy: 0.4417 - val_loss: 1.9026 - val_accuracy: 0.4003\n",
            "Epoch 136/500\n",
            "58/58 [==============================] - 1s 12ms/step - loss: 1.7322 - accuracy: 0.4336 - val_loss: 1.8965 - val_accuracy: 0.4007\n",
            "Epoch 137/500\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 1.7171 - accuracy: 0.4365 - val_loss: 1.8980 - val_accuracy: 0.3995\n",
            "Epoch 138/500\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 1.7362 - accuracy: 0.4243 - val_loss: 1.8994 - val_accuracy: 0.4056\n",
            "Epoch 139/500\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 1.7107 - accuracy: 0.4375 - val_loss: 1.9002 - val_accuracy: 0.4036\n",
            "Epoch 140/500\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 1.7239 - accuracy: 0.4365 - val_loss: 1.9009 - val_accuracy: 0.3975\n",
            "Epoch 141/500\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 1.7228 - accuracy: 0.4345 - val_loss: 1.8966 - val_accuracy: 0.4036\n",
            "Epoch 142/500\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 1.7329 - accuracy: 0.4391 - val_loss: 1.9016 - val_accuracy: 0.3991\n",
            "Epoch 143/500\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 1.7292 - accuracy: 0.4322 - val_loss: 1.9020 - val_accuracy: 0.3971\n",
            "Epoch 144/500\n",
            "58/58 [==============================] - 1s 12ms/step - loss: 1.7254 - accuracy: 0.4323 - val_loss: 1.9040 - val_accuracy: 0.3967\n",
            "Epoch 145/500\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 1.6981 - accuracy: 0.4420 - val_loss: 1.9069 - val_accuracy: 0.4007\n",
            "Epoch 146/500\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 1.7432 - accuracy: 0.4303 - val_loss: 1.9229 - val_accuracy: 0.4011\n",
            "Epoch 147/500\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 1.7098 - accuracy: 0.4440 - val_loss: 1.9050 - val_accuracy: 0.4019\n",
            "Epoch 148/500\n",
            "58/58 [==============================] - 1s 13ms/step - loss: 1.7266 - accuracy: 0.4302 - val_loss: 1.9059 - val_accuracy: 0.4015\n",
            "Epoch 149/500\n",
            "58/58 [==============================] - 1s 12ms/step - loss: 1.7244 - accuracy: 0.4357 - val_loss: 1.9046 - val_accuracy: 0.4015\n",
            "Epoch 150/500\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 1.7269 - accuracy: 0.4334 - val_loss: 1.9023 - val_accuracy: 0.3987\n",
            "Epoch 151/500\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 1.7107 - accuracy: 0.4394 - val_loss: 1.9054 - val_accuracy: 0.4011\n",
            "Epoch 152/500\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 1.7397 - accuracy: 0.4331 - val_loss: 1.9121 - val_accuracy: 0.4015\n",
            "Epoch 153/500\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 1.7165 - accuracy: 0.4299 - val_loss: 1.9083 - val_accuracy: 0.4007\n",
            "Epoch 154/500\n",
            "58/58 [==============================] - 1s 12ms/step - loss: 1.7319 - accuracy: 0.4336 - val_loss: 1.9074 - val_accuracy: 0.4011\n",
            "Epoch 155/500\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 1.6940 - accuracy: 0.4390 - val_loss: 1.8997 - val_accuracy: 0.3963\n",
            "Epoch 156/500\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 1.7085 - accuracy: 0.4427 - val_loss: 1.9029 - val_accuracy: 0.3983\n",
            "Epoch 157/500\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 1.7018 - accuracy: 0.4325 - val_loss: 1.9072 - val_accuracy: 0.3959\n",
            "Epoch 158/500\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 1.7083 - accuracy: 0.4326 - val_loss: 1.9029 - val_accuracy: 0.3967\n",
            "Epoch 159/500\n",
            "58/58 [==============================] - 1s 12ms/step - loss: 1.7194 - accuracy: 0.4364 - val_loss: 1.9077 - val_accuracy: 0.4052\n",
            "Epoch 160/500\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 1.7513 - accuracy: 0.4249 - val_loss: 1.9085 - val_accuracy: 0.3938\n",
            "Epoch 161/500\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 1.7264 - accuracy: 0.4293 - val_loss: 1.9118 - val_accuracy: 0.4003\n",
            "Epoch 162/500\n",
            "58/58 [==============================] - 1s 12ms/step - loss: 1.7131 - accuracy: 0.4375 - val_loss: 1.9102 - val_accuracy: 0.4040\n",
            "Epoch 163/500\n",
            "58/58 [==============================] - 1s 12ms/step - loss: 1.7113 - accuracy: 0.4360 - val_loss: 1.9056 - val_accuracy: 0.3979\n",
            "Model Accuracy on test: 43.27%, Loss: 1.82\n",
            "保存模型：./model/phpbb_7.h5\n",
            "TensorBoard 日志：./logs/phpbb_7210312062605\n",
            "************************************************完成训练LSTM模型************************************************\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGCOWm_2Exfk"
      },
      "source": [
        "## acc-loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqWIYlsDE1bQ"
      },
      "source": [
        "%load_ext tensorboard\r\n",
        "%tensorboard --logdir './logs/phpbb_7210312062605'"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}