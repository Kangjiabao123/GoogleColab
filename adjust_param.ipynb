{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "adjust_param.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOG9/AYmMu+t5Cs5Wxwn8Ex",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YapingWu/GoogleColab/blob/main/adjust_param.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3sy5ihBb2Mb"
      },
      "source": [
        "# 导入需要的包"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XRkOmObbihX"
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense\r\n",
        "from keras.layers import LSTM\r\n",
        "from keras.layers import Embedding\r\n",
        "from keras.layers import Dropout\r\n",
        "from keras import optimizers\r\n",
        "from keras.callbacks import TensorBoard\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "import time\r\n",
        "import numpy as np"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOH95iUIdUOG"
      },
      "source": [
        "# 加载数据\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdhQN-07lB_a"
      },
      "source": [
        "SEED = 7"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zoRZVQzsdZES",
        "outputId": "7c747797-c2b1-48f8-d11f-477db6706e5c"
      },
      "source": [
        "# 数据相关参数\r\n",
        "data_names = ['myspace', 'phpbb', 'rockyou']\r\n",
        "vocab_sizes = [73, 56, 251]\r\n",
        "max_lengths = [35, 21, 41]\r\n",
        "\r\n",
        "i = 1\r\n",
        "data_name = data_names[i]\r\n",
        "vocab_size = vocab_sizes[i]\r\n",
        "max_length = max_lengths[i]\r\n",
        "print(\"dataname：%s, vocab_size：%d, max_length：%d\" % (data_name, vocab_size, max_length))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dataname：phpbb, vocab_size：56, max_length：21\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbuLmjLHdalz",
        "outputId": "e8251f98-dfa6-444c-dc83-da20c42c81d4"
      },
      "source": [
        "print(\"加载数据：\")\r\n",
        "X = np.loadtxt('/content/' + data_name + 'x.txt')\r\n",
        "y = np.loadtxt('/content/' + data_name + 'y.txt')\r\n",
        "print(\"X Shape: %s, y Shape: %s\" % (X.shape, y.shape))\r\n",
        "\r\n",
        "print(\"划分训练集、验证集和测试集：\")\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED)\r\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=SEED)\r\n",
        "print(\"X_train Shape: %s, y_train Shape: %s\" % (X_train.shape, y_train.shape))\r\n",
        "print(\"X_val Shape: %s, y_val Shape: %s\" % (X_val.shape, y_val.shape))\r\n",
        "print(\"X_test Shape: %s, y_test Shape: %s\" % (X_test.shape, y_test.shape))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "加载数据：\n",
            "X Shape: (15322, 20), y Shape: (15322, 56)\n",
            "划分训练集、验证集和测试集：\n",
            "X_train Shape: (12257, 20), y_train Shape: (12257, 56)\n",
            "X_val Shape: (1532, 20), y_val Shape: (1532, 56)\n",
            "X_test Shape: (1533, 20), y_test Shape: (1533, 56)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xL3eLnuyce_y"
      },
      "source": [
        "# 调整网络参数"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHWJUXNSfnlG"
      },
      "source": [
        "## 调整模型参数\r\n",
        "全连接层个数、lstm层个数和每层神经元个数"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ucyz1O3Ctje3"
      },
      "source": [
        "### 设置参数"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oG_X8HRAf4ko"
      },
      "source": [
        "# 设置参数\r\n",
        "epochs = 30\r\n",
        "batch_size = 128\r\n",
        "# 全连接层个数\r\n",
        "dense_layers = [1, 2]\r\n",
        "# 每层神经元个数\r\n",
        "layer_sizes = [32, 64, 128]\r\n",
        "# lstm层数\r\n",
        "lstm_layers = [1, 2, 3]\r\n",
        "\r\n",
        "log_dir = '/content/logs/' + data_name +'/'"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20PIlTlltmXt"
      },
      "source": [
        "### 建立和训练模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGDZxrDpcpTA"
      },
      "source": [
        "# 建立和训练模型\r\n",
        "for dense_layer in dense_layers:\r\n",
        "  for layer_size in layer_sizes:\r\n",
        "    for lstm_layer in lstm_layers:\r\n",
        "      \r\n",
        "      NAME = log_dir + \"{}-lstm-{}-notes-{}-dense\".format(lstm_layer, layer_size, dense_layer)\r\n",
        "      tensorboard = TensorBoard(log_dir=NAME)\r\n",
        "      print(NAME)\r\n",
        "      \r\n",
        "      model = Sequential()\r\n",
        "      model.add(Embedding(input_dim=vocab_size, output_dim=10, input_length=max_length-1))\r\n",
        "      \r\n",
        "      for l in range(lstm_layer - 1):\r\n",
        "        model.add(LSTM(layer_size, return_sequences=True))\r\n",
        "      model.add(LSTM(layer_size, return_sequences=False))\r\n",
        "      \r\n",
        "      for l in range(dense_layer - 1):\r\n",
        "        model.add(Dense(units=layer_size, activation='relu'))\r\n",
        "      model.add(Dense(vocab_size, activation='softmax'))\r\n",
        "\r\n",
        "      model.summary()\r\n",
        "      \r\n",
        "      adam = optimizers.Adam(lr = 0.01)\r\n",
        "      model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\r\n",
        "      \r\n",
        "      model.fit(X_train, y_train, \r\n",
        "                validation_data=(X_val, y_val), \r\n",
        "                epochs=epochs, \r\n",
        "                batch_size=batch_size, \r\n",
        "                verbose=1,\r\n",
        "                callbacks=[tensorboard])\r\n",
        "      loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\r\n",
        "      print(\"Model Accuracy: %.2f%%, Loss: %.2f\" % (accuracy * 100, loss))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ezb6yYYgtwDw"
      },
      "source": [
        "### tensorboard中查看"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xS39LztAtzTv"
      },
      "source": [
        "%tensorboard --logdir /content/logs/phpbb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkn4Q-szgTIe"
      },
      "source": [
        "## 调整batch_size、epoch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNK0787AgusO"
      },
      "source": [
        "### [1, 32, 1]\r\n",
        "dense_layer、layer_size和lstm_layer的组合为[1, 32, 1]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-AdhGSog3U4"
      },
      "source": [
        "# 设置参数\r\n",
        "epochs = 150\r\n",
        "\r\n",
        "dense_layer = 1\r\n",
        "layer_size = 256\r\n",
        "lstm_layer = 1\r\n",
        "log_dir = '/content/logs/' + data_name +'/1-256-1/'\r\n",
        "\r\n",
        "batch_sizes = [128, 256]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UrC0LSaLimGw",
        "outputId": "fcad101b-d4ec-47db-fee8-4463ddea93c2"
      },
      "source": [
        "# 建立和训练模型\r\n",
        "for batch_size in batch_sizes:\r\n",
        "\r\n",
        "  NAME = log_dir + str(batch_size) + '-2'\r\n",
        "  tensorboard = TensorBoard(log_dir=NAME)\r\n",
        "  print(NAME)\r\n",
        "  \r\n",
        "  model = Sequential()\r\n",
        "  model.add(Embedding(input_dim=vocab_size, output_dim=10, input_length=max_length-1))\r\n",
        "  model.add(Dropout(0.2))\r\n",
        "  \r\n",
        "  for l in range(lstm_layer - 1):\r\n",
        "    model.add(LSTM(layer_size, return_sequences=True))\r\n",
        "    model.add(Dropout(0.2))\r\n",
        "  model.add(LSTM(layer_size, return_sequences=False))\r\n",
        "  model.add(Dropout(0.2))\r\n",
        "  \r\n",
        "  for l in range(dense_layer - 1):\r\n",
        "    model.add(Dense(units=layer_size, activation='relu'))\r\n",
        "    model.add(Dropout(0.2))\r\n",
        "  model.add(Dense(vocab_size, activation='softmax'))\r\n",
        "\r\n",
        "  model.summary()\r\n",
        "  \r\n",
        "  adam = optimizers.Adam(lr = 0.01)\r\n",
        "  model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\r\n",
        "  \r\n",
        "  model.fit(X_train, y_train, \r\n",
        "            validation_data=(X_val, y_val), \r\n",
        "            epochs=epochs, \r\n",
        "            batch_size=batch_size, \r\n",
        "            verbose=1,\r\n",
        "            callbacks=[tensorboard])\r\n",
        "  loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\r\n",
        "  print(\"Model Accuracy: %.2f%%, Loss: %.2f\" % (accuracy * 100, loss))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/logs/phpbb/1-256-1/128-2\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, 20, 10)            560       \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 20, 10)            0         \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 256)               273408    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 56)                14392     \n",
            "=================================================================\n",
            "Total params: 288,360\n",
            "Trainable params: 288,360\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/150\n",
            "96/96 [==============================] - 15s 133ms/step - loss: 2.6160 - accuracy: 0.1951 - val_loss: 1.9801 - val_accuracy: 0.3753\n",
            "Epoch 2/150\n",
            "96/96 [==============================] - 13s 132ms/step - loss: 1.9537 - accuracy: 0.3765 - val_loss: 1.9150 - val_accuracy: 0.3982\n",
            "Epoch 3/150\n",
            "96/96 [==============================] - 13s 133ms/step - loss: 1.9061 - accuracy: 0.3798 - val_loss: 1.8838 - val_accuracy: 0.4034\n",
            "Epoch 4/150\n",
            "96/96 [==============================] - 13s 135ms/step - loss: 1.8581 - accuracy: 0.3993 - val_loss: 1.8728 - val_accuracy: 0.4027\n",
            "Epoch 5/150\n",
            "96/96 [==============================] - 13s 134ms/step - loss: 1.8514 - accuracy: 0.4002 - val_loss: 1.8649 - val_accuracy: 0.4178\n",
            "Epoch 6/150\n",
            "96/96 [==============================] - 13s 132ms/step - loss: 1.8470 - accuracy: 0.3958 - val_loss: 1.8673 - val_accuracy: 0.4034\n",
            "Epoch 7/150\n",
            "96/96 [==============================] - 13s 133ms/step - loss: 1.8416 - accuracy: 0.4041 - val_loss: 1.8659 - val_accuracy: 0.4073\n",
            "Epoch 8/150\n",
            "96/96 [==============================] - 13s 132ms/step - loss: 1.8340 - accuracy: 0.3973 - val_loss: 1.8573 - val_accuracy: 0.4138\n",
            "Epoch 9/150\n",
            "96/96 [==============================] - 13s 133ms/step - loss: 1.8422 - accuracy: 0.3994 - val_loss: 1.8603 - val_accuracy: 0.4119\n",
            "Epoch 10/150\n",
            "96/96 [==============================] - 13s 132ms/step - loss: 1.8185 - accuracy: 0.4068 - val_loss: 1.8637 - val_accuracy: 0.4067\n",
            "Epoch 11/150\n",
            "96/96 [==============================] - 13s 133ms/step - loss: 1.8190 - accuracy: 0.4045 - val_loss: 1.8648 - val_accuracy: 0.4112\n",
            "Epoch 12/150\n",
            "96/96 [==============================] - 13s 133ms/step - loss: 1.8019 - accuracy: 0.4064 - val_loss: 1.8555 - val_accuracy: 0.4112\n",
            "Epoch 13/150\n",
            "96/96 [==============================] - 13s 134ms/step - loss: 1.7998 - accuracy: 0.4085 - val_loss: 1.8530 - val_accuracy: 0.4132\n",
            "Epoch 14/150\n",
            "96/96 [==============================] - 13s 135ms/step - loss: 1.8207 - accuracy: 0.4099 - val_loss: 1.8724 - val_accuracy: 0.4034\n",
            "Epoch 15/150\n",
            "96/96 [==============================] - 13s 133ms/step - loss: 1.7960 - accuracy: 0.4154 - val_loss: 1.8712 - val_accuracy: 0.4054\n",
            "Epoch 16/150\n",
            "96/96 [==============================] - 13s 134ms/step - loss: 1.7876 - accuracy: 0.4138 - val_loss: 1.8533 - val_accuracy: 0.4138\n",
            "Epoch 17/150\n",
            "96/96 [==============================] - 13s 133ms/step - loss: 1.7884 - accuracy: 0.4025 - val_loss: 1.8563 - val_accuracy: 0.4158\n",
            "Epoch 18/150\n",
            "96/96 [==============================] - 13s 134ms/step - loss: 1.8093 - accuracy: 0.4105 - val_loss: 1.8641 - val_accuracy: 0.4145\n",
            "Epoch 19/150\n",
            "96/96 [==============================] - 13s 133ms/step - loss: 1.7922 - accuracy: 0.4050 - val_loss: 1.8560 - val_accuracy: 0.4112\n",
            "Epoch 20/150\n",
            "96/96 [==============================] - 13s 133ms/step - loss: 1.7853 - accuracy: 0.4039 - val_loss: 1.8576 - val_accuracy: 0.4080\n",
            "Epoch 21/150\n",
            "96/96 [==============================] - 13s 133ms/step - loss: 1.7787 - accuracy: 0.4105 - val_loss: 1.8547 - val_accuracy: 0.4132\n",
            "Epoch 22/150\n",
            "96/96 [==============================] - 13s 132ms/step - loss: 1.7795 - accuracy: 0.4150 - val_loss: 1.8468 - val_accuracy: 0.4138\n",
            "Epoch 23/150\n",
            "96/96 [==============================] - 13s 134ms/step - loss: 1.7721 - accuracy: 0.4110 - val_loss: 1.8618 - val_accuracy: 0.4047\n",
            "Epoch 24/150\n",
            "96/96 [==============================] - 13s 133ms/step - loss: 1.7766 - accuracy: 0.4098 - val_loss: 1.8578 - val_accuracy: 0.4093\n",
            "Epoch 25/150\n",
            "96/96 [==============================] - 13s 134ms/step - loss: 1.7659 - accuracy: 0.4083 - val_loss: 1.8601 - val_accuracy: 0.4125\n",
            "Epoch 26/150\n",
            "96/96 [==============================] - 13s 134ms/step - loss: 1.7661 - accuracy: 0.4119 - val_loss: 1.8650 - val_accuracy: 0.4067\n",
            "Epoch 27/150\n",
            "96/96 [==============================] - 13s 135ms/step - loss: 1.7535 - accuracy: 0.4182 - val_loss: 1.8682 - val_accuracy: 0.4060\n",
            "Epoch 28/150\n",
            "96/96 [==============================] - 13s 136ms/step - loss: 1.7584 - accuracy: 0.4188 - val_loss: 1.8821 - val_accuracy: 0.4021\n",
            "Epoch 29/150\n",
            "96/96 [==============================] - 13s 135ms/step - loss: 1.7304 - accuracy: 0.4222 - val_loss: 1.8786 - val_accuracy: 0.4027\n",
            "Epoch 30/150\n",
            "96/96 [==============================] - 13s 134ms/step - loss: 1.7500 - accuracy: 0.4203 - val_loss: 1.8839 - val_accuracy: 0.4080\n",
            "Epoch 31/150\n",
            "96/96 [==============================] - 13s 133ms/step - loss: 1.7414 - accuracy: 0.4190 - val_loss: 1.8885 - val_accuracy: 0.4027\n",
            "Epoch 32/150\n",
            "96/96 [==============================] - 13s 133ms/step - loss: 1.7331 - accuracy: 0.4130 - val_loss: 1.8872 - val_accuracy: 0.4080\n",
            "Epoch 33/150\n",
            "96/96 [==============================] - 13s 133ms/step - loss: 1.7509 - accuracy: 0.4233 - val_loss: 1.8906 - val_accuracy: 0.3982\n",
            "Epoch 34/150\n",
            "96/96 [==============================] - 13s 135ms/step - loss: 1.7451 - accuracy: 0.4176 - val_loss: 1.8906 - val_accuracy: 0.4073\n",
            "Epoch 35/150\n",
            "96/96 [==============================] - 13s 136ms/step - loss: 1.7388 - accuracy: 0.4124 - val_loss: 1.8928 - val_accuracy: 0.4021\n",
            "Epoch 36/150\n",
            "96/96 [==============================] - 13s 134ms/step - loss: 1.7144 - accuracy: 0.4205 - val_loss: 1.9149 - val_accuracy: 0.3956\n",
            "Epoch 37/150\n",
            "96/96 [==============================] - 13s 134ms/step - loss: 1.7291 - accuracy: 0.4233 - val_loss: 1.9180 - val_accuracy: 0.4086\n",
            "Epoch 38/150\n",
            "96/96 [==============================] - 13s 134ms/step - loss: 1.7265 - accuracy: 0.4172 - val_loss: 1.9010 - val_accuracy: 0.4034\n",
            "Epoch 39/150\n",
            "96/96 [==============================] - 13s 134ms/step - loss: 1.7123 - accuracy: 0.4219 - val_loss: 1.9189 - val_accuracy: 0.3982\n",
            "Epoch 40/150\n",
            "96/96 [==============================] - 13s 133ms/step - loss: 1.7066 - accuracy: 0.4281 - val_loss: 1.9116 - val_accuracy: 0.4008\n",
            "Epoch 41/150\n",
            "96/96 [==============================] - 13s 134ms/step - loss: 1.7099 - accuracy: 0.4292 - val_loss: 1.9240 - val_accuracy: 0.4080\n",
            "Epoch 42/150\n",
            "96/96 [==============================] - 13s 135ms/step - loss: 1.7177 - accuracy: 0.4186 - val_loss: 1.9325 - val_accuracy: 0.3936\n",
            "Epoch 43/150\n",
            "96/96 [==============================] - 13s 133ms/step - loss: 1.7065 - accuracy: 0.4283 - val_loss: 1.9152 - val_accuracy: 0.4054\n",
            "Epoch 44/150\n",
            "96/96 [==============================] - 13s 132ms/step - loss: 1.7117 - accuracy: 0.4173 - val_loss: 1.9241 - val_accuracy: 0.3962\n",
            "Epoch 45/150\n",
            "96/96 [==============================] - 13s 134ms/step - loss: 1.7054 - accuracy: 0.4223 - val_loss: 1.9347 - val_accuracy: 0.3969\n",
            "Epoch 46/150\n",
            "96/96 [==============================] - 13s 133ms/step - loss: 1.7012 - accuracy: 0.4306 - val_loss: 1.9383 - val_accuracy: 0.3923\n",
            "Epoch 47/150\n",
            "96/96 [==============================] - 13s 134ms/step - loss: 1.6910 - accuracy: 0.4288 - val_loss: 1.9263 - val_accuracy: 0.3923\n",
            "Epoch 48/150\n",
            "96/96 [==============================] - 13s 134ms/step - loss: 1.7039 - accuracy: 0.4296 - val_loss: 1.9500 - val_accuracy: 0.3975\n",
            "Epoch 49/150\n",
            "96/96 [==============================] - 13s 134ms/step - loss: 1.6775 - accuracy: 0.4373 - val_loss: 1.9582 - val_accuracy: 0.3969\n",
            "Epoch 50/150\n",
            "96/96 [==============================] - 13s 134ms/step - loss: 1.6912 - accuracy: 0.4361 - val_loss: 1.9480 - val_accuracy: 0.4014\n",
            "Epoch 51/150\n",
            "96/96 [==============================] - 13s 133ms/step - loss: 1.6966 - accuracy: 0.4328 - val_loss: 1.9639 - val_accuracy: 0.3982\n",
            "Epoch 52/150\n",
            "96/96 [==============================] - 13s 134ms/step - loss: 1.6994 - accuracy: 0.4234 - val_loss: 1.9665 - val_accuracy: 0.3701\n",
            "Epoch 53/150\n",
            "96/96 [==============================] - 13s 133ms/step - loss: 1.6903 - accuracy: 0.4254 - val_loss: 1.9782 - val_accuracy: 0.3916\n",
            "Epoch 54/150\n",
            "96/96 [==============================] - 13s 133ms/step - loss: 1.6843 - accuracy: 0.4346 - val_loss: 1.9832 - val_accuracy: 0.3916\n",
            "Epoch 55/150\n",
            "96/96 [==============================] - 13s 133ms/step - loss: 1.6988 - accuracy: 0.4242 - val_loss: 1.9803 - val_accuracy: 0.3975\n",
            "Epoch 56/150\n",
            "96/96 [==============================] - 13s 134ms/step - loss: 1.6537 - accuracy: 0.4435 - val_loss: 1.9776 - val_accuracy: 0.3988\n",
            "Epoch 57/150\n",
            "96/96 [==============================] - 13s 135ms/step - loss: 1.6752 - accuracy: 0.4386 - val_loss: 1.9843 - val_accuracy: 0.3949\n",
            "Epoch 58/150\n",
            "96/96 [==============================] - 13s 134ms/step - loss: 1.6758 - accuracy: 0.4311 - val_loss: 1.9845 - val_accuracy: 0.3845\n",
            "Epoch 59/150\n",
            "96/96 [==============================] - 13s 134ms/step - loss: 1.6797 - accuracy: 0.4332 - val_loss: 1.9910 - val_accuracy: 0.3832\n",
            "Epoch 60/150\n",
            "96/96 [==============================] - 13s 135ms/step - loss: 1.6656 - accuracy: 0.4424 - val_loss: 1.9971 - val_accuracy: 0.3805\n",
            "Epoch 61/150\n",
            "96/96 [==============================] - 13s 134ms/step - loss: 1.6637 - accuracy: 0.4343 - val_loss: 2.0038 - val_accuracy: 0.3936\n",
            "Epoch 62/150\n",
            "96/96 [==============================] - 13s 134ms/step - loss: 1.6584 - accuracy: 0.4398 - val_loss: 1.9990 - val_accuracy: 0.3988\n",
            "Epoch 63/150\n",
            "96/96 [==============================] - 13s 135ms/step - loss: 1.6891 - accuracy: 0.4313 - val_loss: 2.0089 - val_accuracy: 0.3864\n",
            "Epoch 64/150\n",
            "96/96 [==============================] - 13s 135ms/step - loss: 1.6795 - accuracy: 0.4320 - val_loss: 2.0141 - val_accuracy: 0.3890\n",
            "Epoch 65/150\n",
            "96/96 [==============================] - 13s 134ms/step - loss: 1.6525 - accuracy: 0.4375 - val_loss: 2.0001 - val_accuracy: 0.3884\n",
            "Epoch 66/150\n",
            "96/96 [==============================] - 13s 137ms/step - loss: 1.6524 - accuracy: 0.4392 - val_loss: 2.0056 - val_accuracy: 0.3877\n",
            "Epoch 67/150\n",
            "96/96 [==============================] - 13s 135ms/step - loss: 1.6592 - accuracy: 0.4429 - val_loss: 2.0189 - val_accuracy: 0.3864\n",
            "Epoch 68/150\n",
            "96/96 [==============================] - 13s 134ms/step - loss: 1.6529 - accuracy: 0.4396 - val_loss: 2.0557 - val_accuracy: 0.3812\n",
            "Epoch 69/150\n",
            "96/96 [==============================] - 13s 134ms/step - loss: 1.6529 - accuracy: 0.4347 - val_loss: 2.0321 - val_accuracy: 0.3943\n",
            "Epoch 70/150\n",
            "96/96 [==============================] - 13s 135ms/step - loss: 1.6664 - accuracy: 0.4407 - val_loss: 2.0561 - val_accuracy: 0.3838\n",
            "Epoch 71/150\n",
            "96/96 [==============================] - 13s 135ms/step - loss: 1.6373 - accuracy: 0.4446 - val_loss: 2.0525 - val_accuracy: 0.3812\n",
            "Epoch 72/150\n",
            "96/96 [==============================] - 13s 134ms/step - loss: 1.6522 - accuracy: 0.4403 - val_loss: 2.0431 - val_accuracy: 0.3805\n",
            "Epoch 73/150\n",
            "96/96 [==============================] - 13s 135ms/step - loss: 1.6508 - accuracy: 0.4375 - val_loss: 2.0425 - val_accuracy: 0.3884\n",
            "Epoch 74/150\n",
            "96/96 [==============================] - 13s 135ms/step - loss: 1.6154 - accuracy: 0.4505 - val_loss: 2.0395 - val_accuracy: 0.3832\n",
            "Epoch 75/150\n",
            "96/96 [==============================] - 13s 136ms/step - loss: 1.6566 - accuracy: 0.4353 - val_loss: 2.0378 - val_accuracy: 0.3819\n",
            "Epoch 76/150\n",
            "96/96 [==============================] - 13s 135ms/step - loss: 1.6398 - accuracy: 0.4354 - val_loss: 2.0535 - val_accuracy: 0.3884\n",
            "Epoch 77/150\n",
            "96/96 [==============================] - 13s 135ms/step - loss: 1.6414 - accuracy: 0.4426 - val_loss: 2.0557 - val_accuracy: 0.3838\n",
            "Epoch 78/150\n",
            "96/96 [==============================] - 13s 135ms/step - loss: 1.6521 - accuracy: 0.4430 - val_loss: 2.0578 - val_accuracy: 0.3799\n",
            "Epoch 79/150\n",
            "96/96 [==============================] - 13s 135ms/step - loss: 1.6223 - accuracy: 0.4495 - val_loss: 2.0680 - val_accuracy: 0.3838\n",
            "Epoch 80/150\n",
            "96/96 [==============================] - 13s 135ms/step - loss: 1.6450 - accuracy: 0.4389 - val_loss: 2.0575 - val_accuracy: 0.3792\n",
            "Epoch 81/150\n",
            "96/96 [==============================] - 13s 135ms/step - loss: 1.6359 - accuracy: 0.4468 - val_loss: 2.0776 - val_accuracy: 0.3871\n",
            "Epoch 82/150\n",
            "96/96 [==============================] - 13s 136ms/step - loss: 1.6357 - accuracy: 0.4481 - val_loss: 2.1059 - val_accuracy: 0.3786\n",
            "Epoch 83/150\n",
            "96/96 [==============================] - 13s 134ms/step - loss: 1.6176 - accuracy: 0.4481 - val_loss: 2.0945 - val_accuracy: 0.3858\n",
            "Epoch 84/150\n",
            "96/96 [==============================] - 13s 135ms/step - loss: 1.6219 - accuracy: 0.4501 - val_loss: 2.1036 - val_accuracy: 0.3747\n",
            "Epoch 85/150\n",
            "96/96 [==============================] - 13s 135ms/step - loss: 1.6436 - accuracy: 0.4430 - val_loss: 2.1102 - val_accuracy: 0.3714\n",
            "Epoch 86/150\n",
            "96/96 [==============================] - 13s 135ms/step - loss: 1.6455 - accuracy: 0.4403 - val_loss: 2.1122 - val_accuracy: 0.3805\n",
            "Epoch 87/150\n",
            "96/96 [==============================] - 13s 136ms/step - loss: 1.6205 - accuracy: 0.4461 - val_loss: 2.1003 - val_accuracy: 0.3766\n",
            "Epoch 88/150\n",
            "96/96 [==============================] - 13s 136ms/step - loss: 1.6163 - accuracy: 0.4511 - val_loss: 2.1354 - val_accuracy: 0.3747\n",
            "Epoch 89/150\n",
            "96/96 [==============================] - 13s 137ms/step - loss: 1.6238 - accuracy: 0.4529 - val_loss: 2.1256 - val_accuracy: 0.3675\n",
            "Epoch 90/150\n",
            "96/96 [==============================] - 13s 135ms/step - loss: 1.6332 - accuracy: 0.4487 - val_loss: 2.1184 - val_accuracy: 0.3714\n",
            "Epoch 91/150\n",
            "96/96 [==============================] - 13s 134ms/step - loss: 1.6329 - accuracy: 0.4460 - val_loss: 2.1491 - val_accuracy: 0.3766\n",
            "Epoch 92/150\n",
            "96/96 [==============================] - 13s 134ms/step - loss: 1.6238 - accuracy: 0.4462 - val_loss: 2.1337 - val_accuracy: 0.3760\n",
            "Epoch 93/150\n",
            "96/96 [==============================] - 13s 135ms/step - loss: 1.6347 - accuracy: 0.4439 - val_loss: 2.1435 - val_accuracy: 0.3721\n",
            "Epoch 94/150\n",
            "96/96 [==============================] - 13s 135ms/step - loss: 1.6275 - accuracy: 0.4469 - val_loss: 2.1435 - val_accuracy: 0.3779\n",
            "Epoch 95/150\n",
            "96/96 [==============================] - 13s 134ms/step - loss: 1.6175 - accuracy: 0.4463 - val_loss: 2.1530 - val_accuracy: 0.3714\n",
            "Epoch 96/150\n",
            "96/96 [==============================] - 13s 135ms/step - loss: 1.6031 - accuracy: 0.4521 - val_loss: 2.1177 - val_accuracy: 0.3766\n",
            "Epoch 97/150\n",
            "96/96 [==============================] - 13s 136ms/step - loss: 1.6239 - accuracy: 0.4492 - val_loss: 2.1171 - val_accuracy: 0.3832\n",
            "Epoch 98/150\n",
            "96/96 [==============================] - 13s 135ms/step - loss: 1.6349 - accuracy: 0.4436 - val_loss: 2.1189 - val_accuracy: 0.3766\n",
            "Epoch 99/150\n",
            "96/96 [==============================] - 13s 134ms/step - loss: 1.6183 - accuracy: 0.4529 - val_loss: 2.1391 - val_accuracy: 0.3714\n",
            "Epoch 100/150\n",
            "96/96 [==============================] - 13s 134ms/step - loss: 1.6187 - accuracy: 0.4402 - val_loss: 2.1456 - val_accuracy: 0.3747\n",
            "Epoch 101/150\n",
            "96/96 [==============================] - 13s 134ms/step - loss: 1.6575 - accuracy: 0.4479 - val_loss: 2.0423 - val_accuracy: 0.3923\n",
            "Epoch 102/150\n",
            "96/96 [==============================] - 13s 134ms/step - loss: 1.7739 - accuracy: 0.4115 - val_loss: 2.0653 - val_accuracy: 0.3825\n",
            "Epoch 103/150\n",
            "96/96 [==============================] - 13s 136ms/step - loss: 1.6757 - accuracy: 0.4316 - val_loss: 2.0683 - val_accuracy: 0.3753\n",
            "Epoch 104/150\n",
            "96/96 [==============================] - 13s 134ms/step - loss: 1.6441 - accuracy: 0.4401 - val_loss: 2.0945 - val_accuracy: 0.3681\n",
            "Epoch 105/150\n",
            "96/96 [==============================] - 13s 135ms/step - loss: 1.6453 - accuracy: 0.4408 - val_loss: 2.1016 - val_accuracy: 0.3695\n",
            "Epoch 106/150\n",
            "96/96 [==============================] - 13s 135ms/step - loss: 1.6242 - accuracy: 0.4449 - val_loss: 2.1184 - val_accuracy: 0.3825\n",
            "Epoch 107/150\n",
            "96/96 [==============================] - 13s 135ms/step - loss: 1.6439 - accuracy: 0.4418 - val_loss: 2.1270 - val_accuracy: 0.3792\n",
            "Epoch 108/150\n",
            "96/96 [==============================] - 13s 135ms/step - loss: 1.6409 - accuracy: 0.4398 - val_loss: 2.1363 - val_accuracy: 0.3747\n",
            "Epoch 109/150\n",
            "96/96 [==============================] - 13s 135ms/step - loss: 1.6211 - accuracy: 0.4437 - val_loss: 2.1214 - val_accuracy: 0.3766\n",
            "Epoch 110/150\n",
            "96/96 [==============================] - 13s 136ms/step - loss: 1.6239 - accuracy: 0.4533 - val_loss: 2.1374 - val_accuracy: 0.3734\n",
            "Epoch 111/150\n",
            "96/96 [==============================] - 13s 136ms/step - loss: 1.6170 - accuracy: 0.4451 - val_loss: 2.1351 - val_accuracy: 0.3766\n",
            "Epoch 112/150\n",
            "96/96 [==============================] - 13s 136ms/step - loss: 1.6180 - accuracy: 0.4539 - val_loss: 2.1394 - val_accuracy: 0.3701\n",
            "Epoch 113/150\n",
            "96/96 [==============================] - 13s 136ms/step - loss: 1.6159 - accuracy: 0.4479 - val_loss: 2.1483 - val_accuracy: 0.3688\n",
            "Epoch 114/150\n",
            "96/96 [==============================] - 13s 135ms/step - loss: 1.5938 - accuracy: 0.4549 - val_loss: 2.1680 - val_accuracy: 0.3688\n",
            "Epoch 115/150\n",
            "96/96 [==============================] - 13s 135ms/step - loss: 1.6172 - accuracy: 0.4580 - val_loss: 2.1834 - val_accuracy: 0.3675\n",
            "Epoch 116/150\n",
            "96/96 [==============================] - 13s 136ms/step - loss: 1.6280 - accuracy: 0.4443 - val_loss: 2.1451 - val_accuracy: 0.3695\n",
            "Epoch 117/150\n",
            "96/96 [==============================] - 13s 137ms/step - loss: 1.5984 - accuracy: 0.4582 - val_loss: 2.1610 - val_accuracy: 0.3753\n",
            "Epoch 118/150\n",
            "96/96 [==============================] - 13s 135ms/step - loss: 1.6119 - accuracy: 0.4493 - val_loss: 2.1740 - val_accuracy: 0.3721\n",
            "Epoch 119/150\n",
            "96/96 [==============================] - 13s 135ms/step - loss: 1.6035 - accuracy: 0.4509 - val_loss: 2.1840 - val_accuracy: 0.3675\n",
            "Epoch 120/150\n",
            "96/96 [==============================] - 13s 136ms/step - loss: 1.6021 - accuracy: 0.4551 - val_loss: 2.1777 - val_accuracy: 0.3747\n",
            "Epoch 121/150\n",
            "96/96 [==============================] - 13s 138ms/step - loss: 1.5913 - accuracy: 0.4595 - val_loss: 2.1857 - val_accuracy: 0.3708\n",
            "Epoch 122/150\n",
            "96/96 [==============================] - 13s 138ms/step - loss: 1.6084 - accuracy: 0.4518 - val_loss: 2.1960 - val_accuracy: 0.3721\n",
            "Epoch 123/150\n",
            "96/96 [==============================] - 13s 137ms/step - loss: 1.6076 - accuracy: 0.4564 - val_loss: 2.1840 - val_accuracy: 0.3636\n",
            "Epoch 124/150\n",
            "96/96 [==============================] - 13s 136ms/step - loss: 1.5993 - accuracy: 0.4502 - val_loss: 2.1907 - val_accuracy: 0.3740\n",
            "Epoch 125/150\n",
            "96/96 [==============================] - 13s 136ms/step - loss: 1.6087 - accuracy: 0.4488 - val_loss: 2.1994 - val_accuracy: 0.3773\n",
            "Epoch 126/150\n",
            "96/96 [==============================] - 13s 137ms/step - loss: 1.5937 - accuracy: 0.4531 - val_loss: 2.1879 - val_accuracy: 0.3786\n",
            "Epoch 127/150\n",
            "96/96 [==============================] - 13s 138ms/step - loss: 1.5883 - accuracy: 0.4568 - val_loss: 2.1854 - val_accuracy: 0.3668\n",
            "Epoch 128/150\n",
            "96/96 [==============================] - 13s 137ms/step - loss: 1.5977 - accuracy: 0.4559 - val_loss: 2.2297 - val_accuracy: 0.3727\n",
            "Epoch 129/150\n",
            "96/96 [==============================] - 13s 137ms/step - loss: 1.6288 - accuracy: 0.4409 - val_loss: 2.2126 - val_accuracy: 0.3727\n",
            "Epoch 130/150\n",
            "96/96 [==============================] - 13s 137ms/step - loss: 1.5909 - accuracy: 0.4521 - val_loss: 2.2250 - val_accuracy: 0.3708\n",
            "Epoch 131/150\n",
            "96/96 [==============================] - 13s 138ms/step - loss: 1.6479 - accuracy: 0.4410 - val_loss: 2.2061 - val_accuracy: 0.3760\n",
            "Epoch 132/150\n",
            "96/96 [==============================] - 13s 138ms/step - loss: 1.5953 - accuracy: 0.4495 - val_loss: 2.2084 - val_accuracy: 0.3727\n",
            "Epoch 133/150\n",
            "96/96 [==============================] - 13s 138ms/step - loss: 1.6076 - accuracy: 0.4514 - val_loss: 2.2020 - val_accuracy: 0.3766\n",
            "Epoch 134/150\n",
            "96/96 [==============================] - 13s 137ms/step - loss: 1.5898 - accuracy: 0.4583 - val_loss: 2.2354 - val_accuracy: 0.3649\n",
            "Epoch 135/150\n",
            "96/96 [==============================] - 13s 138ms/step - loss: 1.6114 - accuracy: 0.4464 - val_loss: 2.2284 - val_accuracy: 0.3701\n",
            "Epoch 136/150\n",
            "96/96 [==============================] - 13s 137ms/step - loss: 1.6060 - accuracy: 0.4453 - val_loss: 2.2077 - val_accuracy: 0.3721\n",
            "Epoch 137/150\n",
            "96/96 [==============================] - 13s 136ms/step - loss: 1.5976 - accuracy: 0.4572 - val_loss: 2.2154 - val_accuracy: 0.3701\n",
            "Epoch 138/150\n",
            "96/96 [==============================] - 13s 135ms/step - loss: 1.6079 - accuracy: 0.4463 - val_loss: 2.2187 - val_accuracy: 0.3688\n",
            "Epoch 139/150\n",
            "96/96 [==============================] - 13s 136ms/step - loss: 1.5699 - accuracy: 0.4604 - val_loss: 2.1958 - val_accuracy: 0.3668\n",
            "Epoch 140/150\n",
            "96/96 [==============================] - 13s 135ms/step - loss: 1.5823 - accuracy: 0.4612 - val_loss: 2.2189 - val_accuracy: 0.3727\n",
            "Epoch 141/150\n",
            "96/96 [==============================] - 13s 136ms/step - loss: 1.6121 - accuracy: 0.4495 - val_loss: 2.2169 - val_accuracy: 0.3649\n",
            "Epoch 142/150\n",
            "96/96 [==============================] - 13s 136ms/step - loss: 1.5812 - accuracy: 0.4582 - val_loss: 2.2330 - val_accuracy: 0.3708\n",
            "Epoch 143/150\n",
            "96/96 [==============================] - 13s 135ms/step - loss: 1.6022 - accuracy: 0.4545 - val_loss: 2.2215 - val_accuracy: 0.3721\n",
            "Epoch 144/150\n",
            "96/96 [==============================] - 13s 134ms/step - loss: 1.6084 - accuracy: 0.4501 - val_loss: 2.2284 - val_accuracy: 0.3734\n",
            "Epoch 145/150\n",
            "96/96 [==============================] - 13s 135ms/step - loss: 1.5922 - accuracy: 0.4493 - val_loss: 2.2524 - val_accuracy: 0.3616\n",
            "Epoch 146/150\n",
            "96/96 [==============================] - 13s 134ms/step - loss: 1.5733 - accuracy: 0.4654 - val_loss: 2.2495 - val_accuracy: 0.3681\n",
            "Epoch 147/150\n",
            "96/96 [==============================] - 13s 134ms/step - loss: 1.6151 - accuracy: 0.4545 - val_loss: 2.2314 - val_accuracy: 0.3681\n",
            "Epoch 148/150\n",
            "96/96 [==============================] - 13s 134ms/step - loss: 1.5796 - accuracy: 0.4621 - val_loss: 2.2513 - val_accuracy: 0.3662\n",
            "Epoch 149/150\n",
            "96/96 [==============================] - 13s 134ms/step - loss: 1.6033 - accuracy: 0.4501 - val_loss: 2.2509 - val_accuracy: 0.3655\n",
            "Epoch 150/150\n",
            "96/96 [==============================] - 13s 134ms/step - loss: 1.6017 - accuracy: 0.4538 - val_loss: 2.2629 - val_accuracy: 0.3649\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-6767ca8f483a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             callbacks=[tensorboard])\n\u001b[0;32m---> 34\u001b[0;31m   \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Model Accuracy: %.2f%%, Loss: %.2f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'self' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8CBAV5dgwtt"
      },
      "source": [
        "### [2, 128, 3]\r\n",
        "dense_layer、layer_size和lstm_layer的组合为[2, 128, 3]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvdZ29FMgtEv"
      },
      "source": [
        "# 设置参数\r\n",
        "epochs = 50\r\n",
        "\r\n",
        "dense_layer = 2\r\n",
        "layer_size = 128\r\n",
        "lstm_layer = 3\r\n",
        "log_dir = '/content/logs/' + data_name +'/2-128-3/'\r\n",
        "\r\n",
        "batch_sizes = [32, 64, 128, 256, 512]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpyyPECNhbwr"
      },
      "source": [
        "# 建立和训练模型\r\n",
        "for batch_size in batch_sizes:\r\n",
        "  NAME = log_dir + str(batch_size)\r\n",
        "  tensorboard = TensorBoard(log_dir=NAME)\r\n",
        "  print(NAME)\r\n",
        "  \r\n",
        "  model = Sequential()\r\n",
        "  model.add(Embedding(input_dim=vocab_size, output_dim=10, input_length=max_length-1))\r\n",
        "  \r\n",
        "  for l in range(lstm_layer - 1):\r\n",
        "    model.add(LSTM(layer_size, return_sequences=True))\r\n",
        "  model.add(LSTM(layer_size, return_sequences=False))\r\n",
        "  \r\n",
        "  for l in range(dense_layer - 1):\r\n",
        "    model.add(Dense(units=layer_size, activation='relu'))\r\n",
        "  model.add(Dense(vocab_size, activation='softmax'))\r\n",
        "\r\n",
        "  model.summary()\r\n",
        "  \r\n",
        "  adam = optimizers.Adam(lr = 0.01)\r\n",
        "  model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\r\n",
        "  \r\n",
        "  model.fit(X_train, y_train, \r\n",
        "            validation_data=(X_val, y_val), \r\n",
        "            epochs=epochs, \r\n",
        "            batch_size=batch_size, \r\n",
        "            verbose=1,\r\n",
        "            callbacks=[tensorboard])\r\n",
        "  loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\r\n",
        "  print(\"Model Accuracy: %.2f%%, Loss: %.2f\" % (accuracy * 100, loss))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1I7qgGdAcx6x"
      },
      "source": [
        "# 需要的命令"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXc86eUOc1Uf"
      },
      "source": [
        "## 解压文件"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPaNWCs2c0g7",
        "outputId": "cbe3e3bb-20d5-44c3-f451-8ac70f5859b1"
      },
      "source": [
        "!unzip /content/myspace.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/myspace.zip\n",
            "  inflating: myspacey.txt            \n",
            "  inflating: myspacex.txt            \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1YViDcwj7Vp",
        "outputId": "88b6aedb-e7d7-4032-f0c9-965accede774"
      },
      "source": [
        "!unzip /content/phpbb.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/phpbb.zip\n",
            "  inflating: phpbby.txt              \n",
            "  inflating: phpbbx.txt              \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9jT4RLBj7FY",
        "outputId": "f7238635-0d9f-45f2-96f5-91d4a4fa974e"
      },
      "source": [
        "!unzip /content/rockyou.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/rockyou.zip\n",
            "  inflating: rockyouy.txt            \n",
            "  inflating: rockyoux.txt            \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IiyIZlsHc5Fl"
      },
      "source": [
        "## 使用tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vm0MGYjc9Ty"
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUCkl67xc-Qp"
      },
      "source": [
        "%tensorboard --logdir logs"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}