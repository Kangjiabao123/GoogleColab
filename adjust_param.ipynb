{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "adjust_param.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNPBHzJzlLpsHg0N0vZJcMg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YapingWu/GoogleColab/blob/main/adjust_param.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3sy5ihBb2Mb"
      },
      "source": [
        "# 导入需要的包"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XRkOmObbihX"
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense\r\n",
        "from keras.layers import LSTM\r\n",
        "from keras.layers import Embedding\r\n",
        "from keras import optimizers\r\n",
        "from keras.callbacks import TensorBoard\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "import time\r\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOH95iUIdUOG"
      },
      "source": [
        "# 加载数据\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoRZVQzsdZES"
      },
      "source": [
        "# 数据相关参数\r\n",
        "data_names = ['myspace', 'phpbb', 'rockyou']\r\n",
        "vocab_sizes = [73， 56， 251]\r\n",
        "max_lengths = [35， 21， 41]\r\n",
        "\r\n",
        "i = 0\r\n",
        "data_name = data_names[i]\r\n",
        "vocab_size = vocab_sizes[i]\r\n",
        "max_length = max_lengths[i]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbuLmjLHdalz"
      },
      "source": [
        "print(\"加载数据：\")\r\n",
        "X = np.loadtxt('/content/' + data_name + 'x.txt')\r\n",
        "y = np.loadtxt('/content/' + data_name + 'y.txt')\r\n",
        "\r\n",
        "print(\"划分训练集、验证集和测试集：\")\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.8, random_state=SEED)\r\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=SEED)\r\n",
        "print(\"X_train Shape: %s, y_train Shape: %s\" % (X_train.shape, y_train.shape))\r\n",
        "print(\"X_val Shape: %s, y_val Shape: %s\" % (X_val.shape, y_val.shape))\r\n",
        "print(\"X_test Shape: %s, y_test Shape: %s\" % (X_test.shape, y_test.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xL3eLnuyce_y"
      },
      "source": [
        "# 调整网络参数"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHWJUXNSfnlG"
      },
      "source": [
        "## 调整全连接层个数、lstm层个数和每层神经元个数"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oG_X8HRAf4ko"
      },
      "source": [
        "# 设置参数\r\n",
        "epochs = 30\r\n",
        "batch_size = 128\r\n",
        "# 全连接层个数\r\n",
        "dense_layers = [1, 2]\r\n",
        "# 每层神经元个数\r\n",
        "layer_sizes = [32, 64, 128]\r\n",
        "# lstm层数\r\n",
        "lstm_layers = [1, 2, 3]\r\n",
        "\r\n",
        "log_dir = '/content/logs/' + data_name +'/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGDZxrDpcpTA"
      },
      "source": [
        "# 建立和训练模型\r\n",
        "for dense_layer in dense_layers:\r\n",
        "  for layer_size in layer_sizes:\r\n",
        "    for lstm_layer in lstm_layers:\r\n",
        "      \r\n",
        "      NAME = \"{}-lstm-{}-notes-{}-dense\".format(lstm_layer, layer_size, dense_layer)\r\n",
        "      tensorboard = TensorBoard(log_dir=log_dir+NAME)\r\n",
        "      print(NAME)\r\n",
        "      \r\n",
        "      model = Sequential()\r\n",
        "      model.add(Embedding(input_dim=vocab_size, output_dim=10, input_length=max_length-1))\r\n",
        "      \r\n",
        "      for l in range(lstm_layer - 1):\r\n",
        "        model.add(LSTM(layer_size, return_sequences=True))\r\n",
        "      model.add(LSTM(layer_size, return_sequences=False))\r\n",
        "      \r\n",
        "      for l in range(dense_layer - 1):\r\n",
        "        model.add(Dense(units=layer_size, activation='relu'))\r\n",
        "      model.add(Dense(vocab_size, activation='softmax'))\r\n",
        "\r\n",
        "      model.summary()\r\n",
        "      \r\n",
        "      adam = optimizers.Adam(lr = 0.01)\r\n",
        "      model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\r\n",
        "      \r\n",
        "      model.fit(X_train, y_train, \r\n",
        "                validation_data=(X_val, y_val), \r\n",
        "                epochs=epochs, \r\n",
        "                batch_size=batch_size, \r\n",
        "                verbose=1,\r\n",
        "                callbacks=[tensorboard])\r\n",
        "      loss, accuracy = model.evaluate(self.X_test, self.y_test, verbose=0)\r\n",
        "      print(\"Model Accuracy: %.2f%%, Loss: %.2f\" % (accuracy * 100, loss))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkn4Q-szgTIe"
      },
      "source": [
        "## 调整batch_size、epoch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNK0787AgusO"
      },
      "source": [
        "### [1, 32, 1]\r\n",
        "dense_layer、layer_size和lstm_layer的组合为[1, 32, 1]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-AdhGSog3U4"
      },
      "source": [
        "# 设置参数\r\n",
        "epochs = 100\r\n",
        "\r\n",
        "dense_layer = 1\r\n",
        "layer_size = 32\r\n",
        "lstm_layer = 1\r\n",
        "log_dir = '/content/logs/1-32-1/' + data_name +'/'\r\n",
        "\r\n",
        "batch_sizes = [32, 64, 128, 256, 512]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrC0LSaLimGw"
      },
      "source": [
        "# 建立和训练模型\r\n",
        "for batch_size in batch_sizes:\r\n",
        "\r\n",
        "  NAME = log_dir + batch_size\r\n",
        "  tensorboard = TensorBoard(log_dir=NAME)\r\n",
        "  print(NAME)\r\n",
        "  \r\n",
        "  model = Sequential()\r\n",
        "  model.add(Embedding(input_dim=vocab_size, output_dim=10, input_length=max_length-1))\r\n",
        "  \r\n",
        "  for l in range(lstm_layer - 1):\r\n",
        "    model.add(LSTM(layer_size, return_sequences=True))\r\n",
        "  model.add(LSTM(layer_size, return_sequences=False))\r\n",
        "  \r\n",
        "  for l in range(dense_layer - 1):\r\n",
        "    model.add(Dense(units=layer_size, activation='relu'))\r\n",
        "  model.add(Dense(vocab_size, activation='softmax'))\r\n",
        "\r\n",
        "  model.summary()\r\n",
        "  \r\n",
        "  adam = optimizers.Adam(lr = 0.01)\r\n",
        "  model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\r\n",
        "  \r\n",
        "  model.fit(X_train, y_train, \r\n",
        "            validation_data=(X_val, y_val), \r\n",
        "            epochs=epochs, \r\n",
        "            batch_size=batch_size, \r\n",
        "            verbose=1,\r\n",
        "            callbacks=[tensorboard])\r\n",
        "  loss, accuracy = model.evaluate(self.X_test, self.y_test, verbose=0)\r\n",
        "  print(\"Model Accuracy: %.2f%%, Loss: %.2f\" % (accuracy * 100, loss))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8CBAV5dgwtt"
      },
      "source": [
        "### [2, 128, 3]\r\n",
        "dense_layer、layer_size和lstm_layer的组合为[2, 128, 3]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvdZ29FMgtEv"
      },
      "source": [
        "# 设置参数\r\n",
        "epochs = 50\r\n",
        "\r\n",
        "dense_layer = 2\r\n",
        "layer_size = 128\r\n",
        "lstm_layer = 3\r\n",
        "log_dir = '/content/logs/2-128-3/' + data_name +'/'\r\n",
        "\r\n",
        "batch_sizes = [32, 64, 128, 256, 512]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpyyPECNhbwr"
      },
      "source": [
        "# 建立和训练模型\r\n",
        "for batch_size in batch_sizes:\r\n",
        "  NAME = log_dir + batch_size\r\n",
        "  tensorboard = TensorBoard(log_dir=NAME)\r\n",
        "  print(NAME)\r\n",
        "  \r\n",
        "  model = Sequential()\r\n",
        "  model.add(Embedding(input_dim=vocab_size, output_dim=10, input_length=max_length-1))\r\n",
        "  \r\n",
        "  for l in range(lstm_layer - 1):\r\n",
        "    model.add(LSTM(layer_size, return_sequences=True))\r\n",
        "  model.add(LSTM(layer_size, return_sequences=False))\r\n",
        "  \r\n",
        "  for l in range(dense_layer - 1):\r\n",
        "    model.add(Dense(units=layer_size, activation='relu'))\r\n",
        "  model.add(Dense(vocab_size, activation='softmax'))\r\n",
        "\r\n",
        "  model.summary()\r\n",
        "  \r\n",
        "  adam = optimizers.Adam(lr = 0.01)\r\n",
        "  model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\r\n",
        "  \r\n",
        "  model.fit(X_train, y_train, \r\n",
        "            validation_data=(X_val, y_val), \r\n",
        "            epochs=epochs, \r\n",
        "            batch_size=batch_size, \r\n",
        "            verbose=1,\r\n",
        "            callbacks=[tensorboard])\r\n",
        "  loss, accuracy = model.evaluate(self.X_test, self.y_test, verbose=0)\r\n",
        "  print(\"Model Accuracy: %.2f%%, Loss: %.2f\" % (accuracy * 100, loss))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1I7qgGdAcx6x"
      },
      "source": [
        "# 需要的命令"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXc86eUOc1Uf"
      },
      "source": [
        "## 解压文件"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPaNWCs2c0g7",
        "outputId": "cbe3e3bb-20d5-44c3-f451-8ac70f5859b1"
      },
      "source": [
        "!unzip /content/myspace.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/myspace.zip\n",
            "  inflating: myspacey.txt            \n",
            "  inflating: myspacex.txt            \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1YViDcwj7Vp",
        "outputId": "9d0f22c1-f81d-4c48-c418-94ee72c26c31"
      },
      "source": [
        "!unzip /content/phpbb.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/phpbb.zip\n",
            "  inflating: phpbby.txt              \n",
            "  inflating: phpbbx.txt              \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9jT4RLBj7FY",
        "outputId": "f7238635-0d9f-45f2-96f5-91d4a4fa974e"
      },
      "source": [
        "!unzip /content/rockyou.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/rockyou.zip\n",
            "  inflating: rockyouy.txt            \n",
            "  inflating: rockyoux.txt            \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IiyIZlsHc5Fl"
      },
      "source": [
        "## 使用tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vm0MGYjc9Ty"
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUCkl67xc-Qp"
      },
      "source": [
        "%tensorboard --logdir logs"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}