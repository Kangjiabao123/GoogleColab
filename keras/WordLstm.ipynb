{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WordLstm.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOKbJ7Ltgkg4d2Y+DR6Z0fd",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YapingWu/GoogleColab/blob/main/keras/WordLstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXgA5Sy0sz4K"
      },
      "source": [
        "# Word-Level LSTM实现文本生成"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvCapV82uauY"
      },
      "source": [
        "## 准备工作"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhpeLvPQudIX"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\r\n",
        "from keras.utils import to_categorical\r\n",
        "from keras.preprocessing.sequence import pad_sequences\r\n",
        "from keras.models import Sequential, load_model\r\n",
        "from keras.layers import Embedding, LSTM, Dense, TimeDistributed, AlphaDropout\r\n",
        "from keras import optimizers\r\n",
        "from keras.callbacks import TensorBoard\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import time\r\n",
        "import pickle"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ud4pYF6v_7b"
      },
      "source": [
        "data_name = 'rockyou'\r\n",
        "max_lengths = {\r\n",
        "    'myspace': 35,\r\n",
        "    'phpbb': 21,\r\n",
        "    'rockyou': 41,\r\n",
        "}\r\n",
        "SEED = 7"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spwLPnT2zIUu",
        "outputId": "e8d4b38e-6073-4263-dc4b-af4e9ce6e457"
      },
      "source": [
        "word_list_file = '{}{}.txt'.format('/content/', data_name)\r\n",
        "tokenizer_file = '{}{}.pkl'.format('/content/', data_name)\r\n",
        "print(word_list_file)\r\n",
        "print(tokenizer_file)\r\n",
        "with open(tokenizer_file, 'rb') as file:\r\n",
        "  tokenizer = pickle.load(file)\r\n",
        "vocab_size = len(tokenizer.word_index) + 1\r\n",
        "max_length = max_lengths[data_name]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/rockyou.txt\n",
            "/content/rockyou.pkl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1KDL7IzuWdV"
      },
      "source": [
        "## 加载数据"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQRYQQDqvjS0"
      },
      "source": [
        "word_list = pd.read_csv(word_list_file)['grammar']\r\n",
        "word_list = word_list.values.tolist()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DixuqvVnsrDt",
        "outputId": "7d071300-7be1-40e3-b3a6-70397be388d7"
      },
      "source": [
        "# 将编码后的密码转换为整数序列\r\n",
        "print(\"将编码后的密码转换为（整数）序列\")\r\n",
        "sequences = list()\r\n",
        "for line in word_list:  # 'L8 D1 '\r\n",
        "    line += '<END>'\r\n",
        "    # 将文本转换为（整数）序列\r\n",
        "    encoded = tokenizer.texts_to_sequences([line])[0]\r\n",
        "    # 过滤掉长度大于 MAX_SEQ_LEN 的序列\r\n",
        "    if len(encoded) > max_length:\r\n",
        "        continue\r\n",
        "    for i in range(1, len(encoded) + 1):\r\n",
        "        sequence = encoded[:i]\r\n",
        "        sequences.append(sequence)\r\n",
        "\r\n",
        "print('Total Sequences: %d' % len(sequences))\r\n",
        "\r\n",
        "# pad input sequences\r\n",
        "max_length = max([len(seq) for seq in sequences])\r\n",
        "sequences = pad_sequences(sequences, max_length, padding='pre')  # 左边填充0\r\n",
        "print('Max Sequence Length: %d' % max_length)\r\n",
        "\r\n",
        "# 创建输入输出\r\n",
        "print(\"创建LSTM模型的输入输出\")\r\n",
        "sequences = np.array(sequences)\r\n",
        "x, y = sequences[:, :-1], sequences[:, -1]\r\n",
        "print(\"X Shape: %s, y Shape: %s\" % (x.shape, y.shape))\r\n",
        "y = to_categorical(y, num_classes=vocab_size)  # 对输出进行one-hot编码"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "将编码后的密码转换为（整数）序列\n",
            "Total Sequences: 528028\n",
            "Max Sequence Length: 41\n",
            "创建LSTM模型的输入输出\n",
            "X Shape: (528028, 40), y Shape: (528028,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TUEWv6WuKoD"
      },
      "source": [
        "### 划分训练集、验证集和测试集"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0WoOhHPtgXn",
        "outputId": "e92de394-d162-4a5f-a68c-c202fcb16e98"
      },
      "source": [
        "def split_xy(x, y):\r\n",
        "\r\n",
        "    ratio = 0.6  # 训练集比例\r\n",
        "    if len(x) > 100000:\r\n",
        "        ratio = 0.9\r\n",
        "\r\n",
        "    print(\"划分训练集、验证集和测试集\")\r\n",
        "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=1 - ratio, random_state=SEED)\r\n",
        "    x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=0.5, random_state=SEED)\r\n",
        "\r\n",
        "    print(\"x_train Shape: %s, y_train Shape: %s\" % (x_train.shape, y_train.shape))\r\n",
        "    print(\"x_val Shape: %s, y_val Shape: %s\" % (x_val.shape, y_val.shape))\r\n",
        "    print(\"x_test Shape: %s, y_test Shape: %s\" % (x_test.shape, y_test.shape))\r\n",
        "\r\n",
        "    return x_train, x_val, x_test, y_train, y_val, y_test\r\n",
        "\r\n",
        "x_train, x_val, x_test, y_train, y_val, y_test = split_xy(x, y)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "划分训练集、验证集和测试集\n",
            "x_train Shape: (475225, 40), y_train Shape: (475225, 251)\n",
            "x_val Shape: (26401, 40), y_val Shape: (26401, 251)\n",
            "x_test Shape: (26402, 40), y_test Shape: (26402, 251)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0T3gxLZotMyn"
      },
      "source": [
        "## 创建和训练模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqdB5-XExJ5Q"
      },
      "source": [
        "epochs = 30\r\n",
        "batch_size = 128\r\n",
        "lstm_layers = [[32, True], [32, True], [32, False]]\r\n",
        "fully_layers = [32]\r\n",
        "dropout_p = 0.5"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50x1Oy07to6y"
      },
      "source": [
        "### 创建模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKKkrDyRtta-",
        "outputId": "7370d694-73f4-4e49-8b6d-9d8b274de650"
      },
      "source": [
        "print('{:*^106}'.format('创建LSTM模型'))\r\n",
        "model = Sequential()\r\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=10, input_length=max_length - 1))\r\n",
        "\r\n",
        "for hidden_size, rs in lstm_layers:\r\n",
        "    model.add(LSTM(hidden_size, return_sequences=rs))\r\n",
        "\r\n",
        "for hidden_size in fully_layers:\r\n",
        "    model.add(Dense(units=hidden_size, activation='relu'))\r\n",
        "    # model.add(AlphaDropout(dropout_p))\r\n",
        "model.add(Dense(vocab_size, activation='softmax'))\r\n",
        "\r\n",
        "model.summary()\r\n",
        "\r\n",
        "adam = optimizers.Adam(lr=0.01)\r\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*************************************************创建LSTM模型*************************************************\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 40, 10)            2510      \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 40, 32)            5504      \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, 40, 32)            8320      \n",
            "_________________________________________________________________\n",
            "lstm_5 (LSTM)                (None, 32)                8320      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 251)               8283      \n",
            "=================================================================\n",
            "Total params: 33,993\n",
            "Trainable params: 33,993\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPb-yQt1uCvE"
      },
      "source": [
        "### 训练模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oeDnxtlvnmec",
        "outputId": "dca63e44-8bde-435e-b906-3be875aac556"
      },
      "source": [
        "cur_time = time.strftime(\"%y%m%d%H%M%S\", time.localtime())\r\n",
        "log_name = '{}{}{}'.format('./logs/', data_name, cur_time)\r\n",
        "model_file = '{}{}.h5'.format('./model/', data_name)\r\n",
        "log_name, model_file"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./logs/rockyou210303013255', './model/rockyou.h5')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1sJnXlPtPpc",
        "outputId": "7217a323-a639-4f3c-aee8-dbaabd9bbb0e"
      },
      "source": [
        "tensorboard = TensorBoard(log_dir=log_name)\r\n",
        "\r\n",
        "print('{:*^106}'.format('开始训练LSTM模型'))\r\n",
        "model.fit(x_train, y_train,\r\n",
        "          validation_data=(x_val, y_val),\r\n",
        "          epochs=epochs,\r\n",
        "          batch_size=batch_size,\r\n",
        "          verbose=1,\r\n",
        "          callbacks=[tensorboard])\r\n",
        "loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\r\n",
        "print(\"Model Accuracy on test: %.2f%%, Loss: %.2f\" % (accuracy * 100, loss))\r\n",
        "print('{:*^106}'.format('完成训练LSTM模型'))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "************************************************开始训练LSTM模型************************************************\n",
            "Epoch 1/30\n",
            "3713/3713 [==============================] - 238s 63ms/step - loss: 2.4578 - accuracy: 0.2585 - val_loss: 2.0258 - val_accuracy: 0.3819\n",
            "Epoch 2/30\n",
            "3713/3713 [==============================] - 234s 63ms/step - loss: 2.0281 - accuracy: 0.3751 - val_loss: 2.0059 - val_accuracy: 0.3855\n",
            "Epoch 3/30\n",
            "3713/3713 [==============================] - 233s 63ms/step - loss: 2.0193 - accuracy: 0.3779 - val_loss: 2.0041 - val_accuracy: 0.3859\n",
            "Epoch 4/30\n",
            "3713/3713 [==============================] - 235s 63ms/step - loss: 2.0089 - accuracy: 0.3808 - val_loss: 2.0020 - val_accuracy: 0.3851\n",
            "Epoch 5/30\n",
            "3713/3713 [==============================] - 235s 63ms/step - loss: 2.0058 - accuracy: 0.3821 - val_loss: 1.9997 - val_accuracy: 0.3874\n",
            "Epoch 6/30\n",
            "3713/3713 [==============================] - 234s 63ms/step - loss: 2.0018 - accuracy: 0.3834 - val_loss: 2.0111 - val_accuracy: 0.3833\n",
            "Epoch 7/30\n",
            "3713/3713 [==============================] - 234s 63ms/step - loss: 2.0017 - accuracy: 0.3837 - val_loss: 2.0011 - val_accuracy: 0.3864\n",
            "Epoch 8/30\n",
            "3713/3713 [==============================] - 234s 63ms/step - loss: 1.9989 - accuracy: 0.3837 - val_loss: 2.0132 - val_accuracy: 0.3815\n",
            "Epoch 9/30\n",
            "3713/3713 [==============================] - 234s 63ms/step - loss: 1.9973 - accuracy: 0.3841 - val_loss: 1.9994 - val_accuracy: 0.3850\n",
            "Epoch 10/30\n",
            "3713/3713 [==============================] - 235s 63ms/step - loss: 1.9992 - accuracy: 0.3837 - val_loss: 2.0001 - val_accuracy: 0.3883\n",
            "Epoch 11/30\n",
            "3713/3713 [==============================] - 239s 64ms/step - loss: 1.9982 - accuracy: 0.3836 - val_loss: 2.0024 - val_accuracy: 0.3865\n",
            "Epoch 12/30\n",
            "3713/3713 [==============================] - 235s 63ms/step - loss: 2.0059 - accuracy: 0.3811 - val_loss: 2.0010 - val_accuracy: 0.3862\n",
            "Epoch 13/30\n",
            "3713/3713 [==============================] - 235s 63ms/step - loss: 1.9968 - accuracy: 0.3844 - val_loss: 2.0049 - val_accuracy: 0.3877\n",
            "Epoch 14/30\n",
            "3713/3713 [==============================] - 235s 63ms/step - loss: 1.9919 - accuracy: 0.3847 - val_loss: 1.9984 - val_accuracy: 0.3888\n",
            "Epoch 15/30\n",
            "3713/3713 [==============================] - 234s 63ms/step - loss: 1.9966 - accuracy: 0.3846 - val_loss: 1.9986 - val_accuracy: 0.3871\n",
            "Epoch 16/30\n",
            "3713/3713 [==============================] - 234s 63ms/step - loss: 1.9921 - accuracy: 0.3858 - val_loss: 2.0023 - val_accuracy: 0.3892\n",
            "Epoch 17/30\n",
            "3713/3713 [==============================] - 234s 63ms/step - loss: 1.9932 - accuracy: 0.3859 - val_loss: 2.0017 - val_accuracy: 0.3877\n",
            "Epoch 18/30\n",
            "3713/3713 [==============================] - 235s 63ms/step - loss: 1.9931 - accuracy: 0.3851 - val_loss: 1.9987 - val_accuracy: 0.3892\n",
            "Epoch 19/30\n",
            "3713/3713 [==============================] - 240s 65ms/step - loss: 1.9944 - accuracy: 0.3855 - val_loss: 2.0038 - val_accuracy: 0.3870\n",
            "Epoch 20/30\n",
            "3713/3713 [==============================] - 235s 63ms/step - loss: 1.9924 - accuracy: 0.3864 - val_loss: 1.9997 - val_accuracy: 0.3890\n",
            "Epoch 21/30\n",
            "3713/3713 [==============================] - 235s 63ms/step - loss: 1.9947 - accuracy: 0.3856 - val_loss: 2.0026 - val_accuracy: 0.3867\n",
            "Epoch 22/30\n",
            "3713/3713 [==============================] - 236s 63ms/step - loss: 1.9931 - accuracy: 0.3861 - val_loss: 2.0037 - val_accuracy: 0.3872\n",
            "Epoch 23/30\n",
            "3713/3713 [==============================] - 234s 63ms/step - loss: 1.9956 - accuracy: 0.3849 - val_loss: 2.0060 - val_accuracy: 0.3881\n",
            "Epoch 24/30\n",
            "3713/3713 [==============================] - 234s 63ms/step - loss: 1.9928 - accuracy: 0.3872 - val_loss: 2.0047 - val_accuracy: 0.3890\n",
            "Epoch 25/30\n",
            "3713/3713 [==============================] - 235s 63ms/step - loss: 1.9937 - accuracy: 0.3861 - val_loss: 2.0204 - val_accuracy: 0.3855\n",
            "Epoch 26/30\n",
            "3713/3713 [==============================] - 235s 63ms/step - loss: 1.9952 - accuracy: 0.3863 - val_loss: 2.0016 - val_accuracy: 0.3857\n",
            "Epoch 27/30\n",
            "3713/3713 [==============================] - 236s 64ms/step - loss: 1.9948 - accuracy: 0.3855 - val_loss: 2.0001 - val_accuracy: 0.3886\n",
            "Epoch 28/30\n",
            "3713/3713 [==============================] - 236s 64ms/step - loss: 1.9947 - accuracy: 0.3855 - val_loss: 2.0046 - val_accuracy: 0.3845\n",
            "Epoch 29/30\n",
            "3713/3713 [==============================] - 236s 64ms/step - loss: 1.9933 - accuracy: 0.3857 - val_loss: 2.0012 - val_accuracy: 0.3890\n",
            "Epoch 30/30\n",
            "3713/3713 [==============================] - 237s 64ms/step - loss: 1.9916 - accuracy: 0.3860 - val_loss: 2.0007 - val_accuracy: 0.3889\n",
            "Model Accuracy on test: 38.10%, Loss: 2.01\n",
            "************************************************完成训练LSTM模型************************************************\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vb61k6azuEXI"
      },
      "source": [
        "### 保存模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wf93Al9PuBMJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55f895c3-6435-426c-a9ae-c48c190618d7"
      },
      "source": [
        "print(\"保存模型：%s\" % model_file)\r\n",
        "model.save(model_file)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "保存模型：./model/rockyou.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cio0kQzJxZvy"
      },
      "source": [
        "# 其他命令"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9UiUkJhxZZo",
        "outputId": "e8b2a37e-eba1-46dc-ad92-8582333625e4"
      },
      "source": [
        "!unzip '/content/wordlist.zip'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/wordlist.zip\n",
            "  inflating: myspace.txt             \n",
            "  inflating: phpbb.txt               \n",
            "  inflating: rockyou.txt             \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYE2I-0TyaPu",
        "outputId": "16c5fbf6-51cb-4eb9-b259-df98e11a1a34"
      },
      "source": [
        "!unzip '/content/tokenizer.zip'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/tokenizer.zip\n",
            "  inflating: phpbb.pkl               \n",
            "  inflating: rockyou.pkl             \n",
            "  inflating: myspace.pkl             \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqDA8YlT0KiY"
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41jNXoRi0OaH"
      },
      "source": [
        "%tensorboard --logdir '/content/logs/rockyou210303013255'"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}