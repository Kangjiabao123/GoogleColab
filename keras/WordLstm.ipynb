{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "WordLstm.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YapingWu/GoogleColab/blob/main/keras/WordLstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXgA5Sy0sz4K"
      },
      "source": [
        "# Word-Level LSTM实现文本生成"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvCapV82uauY"
      },
      "source": [
        "## 准备工作"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhpeLvPQudIX"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\r\n",
        "from keras.utils import to_categorical\r\n",
        "from keras.preprocessing.sequence import pad_sequences\r\n",
        "from keras.models import Sequential, load_model\r\n",
        "from keras.layers import Embedding, LSTM, Dense, TimeDistributed, AlphaDropout\r\n",
        "from keras import optimizers\r\n",
        "from keras.callbacks import TensorBoard, EarlyStopping\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import time\r\n",
        "import pickle"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ud4pYF6v_7b"
      },
      "source": [
        "data_name = 'myspace'\r\n",
        "max_lengths = {\r\n",
        "    'myspace': 35,\r\n",
        "    'phpbb': 21,\r\n",
        "    'rockyou': 41,\r\n",
        "}\r\n",
        "SEED = 7"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spwLPnT2zIUu",
        "outputId": "f896329e-62e3-44de-c019-acaa2ce9da97"
      },
      "source": [
        "# word_list_file = '{}{}.txt'.format('/content/', data_name)\r\n",
        "word_list_file = '{}{}_train.txt'.format('/content/', data_name)\r\n",
        "tokenizer_file = '{}{}.pkl'.format('/content/', data_name)\r\n",
        "print(word_list_file)\r\n",
        "print(tokenizer_file)\r\n",
        "with open(tokenizer_file, 'rb') as file:\r\n",
        "  tokenizer = pickle.load(file)\r\n",
        "vocab_size = len(tokenizer.word_index) + 1\r\n",
        "max_length = max_lengths[data_name]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/phpbb_train.txt\n",
            "/content/phpbb.pkl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1KDL7IzuWdV"
      },
      "source": [
        "## 加载数据"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQRYQQDqvjS0"
      },
      "source": [
        "word_list = pd.read_csv(word_list_file)['grammar']\r\n",
        "word_list = word_list.values.tolist()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DixuqvVnsrDt",
        "outputId": "04a404a5-080b-4ca1-e316-5c1948929607"
      },
      "source": [
        "# 将编码后的密码转换为整数序列\r\n",
        "print(\"将编码后的密码转换为（整数）序列\")\r\n",
        "sequences = list()\r\n",
        "for line in word_list:  # 'L8 D1 '\r\n",
        "    line += '<END>'\r\n",
        "    # 将文本转换为（整数）序列\r\n",
        "    encoded = tokenizer.texts_to_sequences([line])[0]\r\n",
        "    # 过滤掉长度大于 MAX_SEQ_LEN 的序列\r\n",
        "    if len(encoded) > max_length:\r\n",
        "        continue\r\n",
        "    for i in range(1, len(encoded) + 1):\r\n",
        "        sequence = encoded[:i]\r\n",
        "        sequences.append(sequence)\r\n",
        "\r\n",
        "print('Total Sequences: %d' % len(sequences))\r\n",
        "\r\n",
        "# pad input sequences\r\n",
        "max_length = max([len(seq) for seq in sequences])\r\n",
        "sequences = pad_sequences(sequences, max_length, padding='pre')  # 左边填充0\r\n",
        "print('Max Sequence Length: %d' % max_length)\r\n",
        "\r\n",
        "# 创建输入输出\r\n",
        "print(\"创建LSTM模型的输入输出\")\r\n",
        "sequences = np.array(sequences)\r\n",
        "x, y = sequences[:, :-1], sequences[:, -1]\r\n",
        "print(\"X Shape: %s, y Shape: %s\" % (x.shape, y.shape))\r\n",
        "y = to_categorical(y, num_classes=vocab_size)  # 对输出进行one-hot编码"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "将编码后的密码转换为（整数）序列\n",
            "Total Sequences: 12278\n",
            "Max Sequence Length: 21\n",
            "创建LSTM模型的输入输出\n",
            "X Shape: (12278, 20), y Shape: (12278,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TUEWv6WuKoD"
      },
      "source": [
        "### 划分训练集、验证集和测试集"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0WoOhHPtgXn",
        "outputId": "f75d1085-4317-48e1-f2d4-aeadb198c4a4"
      },
      "source": [
        "def split_xy(x, y):\r\n",
        "\r\n",
        "    ratio = 0.6  # 训练集比例\r\n",
        "    if len(x) > 100000:\r\n",
        "        ratio = 0.9\r\n",
        "\r\n",
        "    print(\"划分训练集、验证集和测试集\")\r\n",
        "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=1 - ratio, random_state=SEED)\r\n",
        "    x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=0.5, random_state=SEED)\r\n",
        "\r\n",
        "    print(\"x_train Shape: %s, y_train Shape: %s\" % (x_train.shape, y_train.shape))\r\n",
        "    print(\"x_val Shape: %s, y_val Shape: %s\" % (x_val.shape, y_val.shape))\r\n",
        "    print(\"x_test Shape: %s, y_test Shape: %s\" % (x_test.shape, y_test.shape))\r\n",
        "\r\n",
        "    return x_train, x_val, x_test, y_train, y_val, y_test\r\n",
        "\r\n",
        "x_train, x_val, x_test, y_train, y_val, y_test = split_xy(x, y)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "划分训练集、验证集和测试集\n",
            "x_train Shape: (7366, 20), y_train Shape: (7366, 56)\n",
            "x_val Shape: (2456, 20), y_val Shape: (2456, 56)\n",
            "x_test Shape: (2456, 20), y_test Shape: (2456, 56)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0T3gxLZotMyn"
      },
      "source": [
        "## 创建和训练模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqdB5-XExJ5Q"
      },
      "source": [
        "epochs = 200\r\n",
        "batch_size = 128\r\n",
        "lstm_layers = [[32, True], [32, True], [32, False]]\r\n",
        "fully_layers = [32]\r\n",
        "lr = 0.001\r\n",
        "dropout_p = 0.0\r\n",
        "optimizer = optimizers.Adam(lr=lr)\r\n",
        "# optimizer = optimizers.RMSprop()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50x1Oy07to6y"
      },
      "source": [
        "### 创建模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKKkrDyRtta-",
        "outputId": "bf2927a1-b7c3-4dc2-940d-653b44eddd2c"
      },
      "source": [
        "print('{:*^106}'.format('创建LSTM模型'))\r\n",
        "model = Sequential()\r\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=10, input_length=max_length - 1))\r\n",
        "\r\n",
        "for hidden_size, rs in lstm_layers:\r\n",
        "    model.add(LSTM(hidden_size, return_sequences=rs))\r\n",
        "\r\n",
        "for hidden_size in fully_layers:\r\n",
        "    model.add(Dense(units=hidden_size, activation='relu'))\r\n",
        "    # model.add(AlphaDropout(dropout_p))\r\n",
        "model.add(Dense(vocab_size, activation='softmax'))\r\n",
        "\r\n",
        "model.summary()\r\n",
        "\r\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*************************************************创建LSTM模型*************************************************\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 20, 10)            560       \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 20, 32)            5504      \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 20, 32)            8320      \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 32)                8320      \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 56)                1848      \n",
            "=================================================================\n",
            "Total params: 25,608\n",
            "Trainable params: 25,608\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPb-yQt1uCvE"
      },
      "source": [
        "### 训练模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdLJK-mZ88MZ"
      },
      "source": [
        "num_batch = int(x_train.shape[0] / batch_size)\r\n",
        "def generate_train_data():  \r\n",
        "    i = 0\r\n",
        "    while True:\r\n",
        "        i = i % num_batch\r\n",
        "        x_ = x_train[batch_size * i: batch_size * (i + 1)]  # 筛选出一个批次的数据\r\n",
        "        y_ = y_train[batch_size * i: batch_size * (i + 1)]  # 筛选出一个批次的数据\r\n",
        "        i += 1\r\n",
        "        yield x_, y_"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oeDnxtlvnmec",
        "outputId": "7ba4d447-7a7a-4f00-ba8a-01ddd307d87a"
      },
      "source": [
        "cur_time = time.strftime(\"%y%m%d%H%M%S\", time.localtime())\r\n",
        "log_name = '{}{}{}'.format('./logs/', data_name, cur_time)\r\n",
        "# model_file = '{}{}.h5'.format('./model/', data_name)\r\n",
        "model_file = '{}{}_part.h5'.format('./model/', data_name)\r\n",
        "log_name, model_file"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./logs/phpbb210305070002', './model/phpbb_part.h5')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1sJnXlPtPpc",
        "outputId": "f2387fb5-8531-4973-9b00-834f6bb8ddcd"
      },
      "source": [
        "tensorboard = TensorBoard(log_dir=log_name)\r\n",
        "early_stopping = EarlyStopping(monitor='val_loss',patience=10)\r\n",
        "\r\n",
        "print('{:*^106}'.format('开始训练LSTM模型'))\r\n",
        "model.fit(generate_train_data(),\r\n",
        "          validation_data=(x_val, y_val),\r\n",
        "          steps_per_epoch=num_batch,\r\n",
        "          epochs=epochs,\r\n",
        "          verbose=1,\r\n",
        "          callbacks=[tensorboard, early_stopping])\r\n",
        "\r\n",
        "loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\r\n",
        "print(\"Model Accuracy on test: %.2f%%, Loss: %.2f\" % (accuracy * 100, loss))\r\n",
        "print('{:*^106}'.format('完成训练LSTM模型'))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "************************************************开始训练LSTM模型************************************************\n",
            "Epoch 1/200\n",
            "57/57 [==============================] - 8s 47ms/step - loss: 3.5738 - accuracy: 0.1748 - val_loss: 2.4978 - val_accuracy: 0.1612\n",
            "Epoch 2/200\n",
            "57/57 [==============================] - 1s 13ms/step - loss: 2.5287 - accuracy: 0.1688 - val_loss: 2.4467 - val_accuracy: 0.1938\n",
            "Epoch 3/200\n",
            "57/57 [==============================] - 1s 13ms/step - loss: 2.4965 - accuracy: 0.1808 - val_loss: 2.4408 - val_accuracy: 0.1938\n",
            "Epoch 4/200\n",
            "57/57 [==============================] - 1s 13ms/step - loss: 2.4918 - accuracy: 0.1808 - val_loss: 2.4394 - val_accuracy: 0.1938\n",
            "Epoch 5/200\n",
            "57/57 [==============================] - 1s 13ms/step - loss: 2.4901 - accuracy: 0.1808 - val_loss: 2.4388 - val_accuracy: 0.1938\n",
            "Epoch 6/200\n",
            "57/57 [==============================] - 1s 13ms/step - loss: 2.4892 - accuracy: 0.1808 - val_loss: 2.4385 - val_accuracy: 0.1938\n",
            "Epoch 7/200\n",
            "57/57 [==============================] - 1s 13ms/step - loss: 2.4887 - accuracy: 0.1808 - val_loss: 2.4383 - val_accuracy: 0.1938\n",
            "Epoch 8/200\n",
            "57/57 [==============================] - 1s 13ms/step - loss: 2.4883 - accuracy: 0.1808 - val_loss: 2.4382 - val_accuracy: 0.1938\n",
            "Epoch 9/200\n",
            "57/57 [==============================] - 1s 14ms/step - loss: 2.4880 - accuracy: 0.1809 - val_loss: 2.4380 - val_accuracy: 0.1938\n",
            "Epoch 10/200\n",
            "57/57 [==============================] - 1s 13ms/step - loss: 2.4877 - accuracy: 0.1809 - val_loss: 2.4377 - val_accuracy: 0.1938\n",
            "Epoch 11/200\n",
            "57/57 [==============================] - 1s 13ms/step - loss: 2.4869 - accuracy: 0.1827 - val_loss: 2.4359 - val_accuracy: 0.1938\n",
            "Epoch 12/200\n",
            "57/57 [==============================] - 1s 13ms/step - loss: 2.4828 - accuracy: 0.1892 - val_loss: 2.4075 - val_accuracy: 0.2060\n",
            "Epoch 13/200\n",
            "57/57 [==============================] - 1s 13ms/step - loss: 2.4160 - accuracy: 0.2336 - val_loss: 2.1856 - val_accuracy: 0.3408\n",
            "Epoch 14/200\n",
            "57/57 [==============================] - 1s 13ms/step - loss: 2.1989 - accuracy: 0.3238 - val_loss: 2.0562 - val_accuracy: 0.3717\n",
            "Epoch 15/200\n",
            "57/57 [==============================] - 1s 12ms/step - loss: 2.0993 - accuracy: 0.3404 - val_loss: 2.0071 - val_accuracy: 0.3852\n",
            "Epoch 16/200\n",
            "57/57 [==============================] - 1s 13ms/step - loss: 2.0541 - accuracy: 0.3613 - val_loss: 1.9729 - val_accuracy: 0.3929\n",
            "Epoch 17/200\n",
            "57/57 [==============================] - 1s 13ms/step - loss: 2.0243 - accuracy: 0.3719 - val_loss: 1.9489 - val_accuracy: 0.4039\n",
            "Epoch 18/200\n",
            "57/57 [==============================] - 1s 13ms/step - loss: 2.0016 - accuracy: 0.3780 - val_loss: 1.9309 - val_accuracy: 0.4088\n",
            "Epoch 19/200\n",
            "57/57 [==============================] - 1s 13ms/step - loss: 1.9843 - accuracy: 0.3858 - val_loss: 1.9161 - val_accuracy: 0.4121\n",
            "Epoch 20/200\n",
            "57/57 [==============================] - 1s 13ms/step - loss: 1.9724 - accuracy: 0.3885 - val_loss: 1.9026 - val_accuracy: 0.4165\n",
            "Epoch 21/200\n",
            "57/57 [==============================] - 1s 13ms/step - loss: 1.9626 - accuracy: 0.3891 - val_loss: 1.8934 - val_accuracy: 0.4173\n",
            "Epoch 22/200\n",
            "57/57 [==============================] - 1s 13ms/step - loss: 1.9536 - accuracy: 0.3897 - val_loss: 1.8859 - val_accuracy: 0.4198\n",
            "Epoch 23/200\n",
            "57/57 [==============================] - 1s 13ms/step - loss: 1.9463 - accuracy: 0.3907 - val_loss: 1.8803 - val_accuracy: 0.4198\n",
            "Epoch 24/200\n",
            "57/57 [==============================] - 1s 13ms/step - loss: 1.9405 - accuracy: 0.3920 - val_loss: 1.8764 - val_accuracy: 0.4218\n",
            "Epoch 25/200\n",
            "57/57 [==============================] - 1s 13ms/step - loss: 1.9366 - accuracy: 0.3927 - val_loss: 1.8720 - val_accuracy: 0.4218\n",
            "Epoch 26/200\n",
            "57/57 [==============================] - 1s 13ms/step - loss: 1.9322 - accuracy: 0.3933 - val_loss: 1.8686 - val_accuracy: 0.4218\n",
            "Epoch 27/200\n",
            "57/57 [==============================] - 1s 14ms/step - loss: 1.9284 - accuracy: 0.3935 - val_loss: 1.8659 - val_accuracy: 0.4218\n",
            "Epoch 28/200\n",
            "57/57 [==============================] - 1s 13ms/step - loss: 1.9251 - accuracy: 0.3931 - val_loss: 1.8633 - val_accuracy: 0.4214\n",
            "Epoch 29/200\n",
            "57/57 [==============================] - 1s 13ms/step - loss: 1.9221 - accuracy: 0.3937 - val_loss: 1.8613 - val_accuracy: 0.4214\n",
            "Epoch 30/200\n",
            "57/57 [==============================] - 1s 13ms/step - loss: 1.9198 - accuracy: 0.3933 - val_loss: 1.8585 - val_accuracy: 0.4218\n",
            "Epoch 31/200\n",
            "57/57 [==============================] - 1s 13ms/step - loss: 1.9164 - accuracy: 0.3942 - val_loss: 1.8569 - val_accuracy: 0.4230\n",
            "Epoch 32/200\n",
            "57/57 [==============================] - 1s 13ms/step - loss: 1.9143 - accuracy: 0.3935 - val_loss: 1.8552 - val_accuracy: 0.4239\n",
            "Epoch 33/200\n",
            "57/57 [==============================] - 1s 13ms/step - loss: 1.9117 - accuracy: 0.3943 - val_loss: 1.8539 - val_accuracy: 0.4235\n",
            "Epoch 34/200\n",
            "57/57 [==============================] - 1s 13ms/step - loss: 1.9092 - accuracy: 0.3940 - val_loss: 1.8525 - val_accuracy: 0.4247\n",
            "Epoch 35/200\n",
            "57/57 [==============================] - 1s 13ms/step - loss: 1.9072 - accuracy: 0.3942 - val_loss: 1.8510 - val_accuracy: 0.4251\n",
            "Epoch 36/200\n",
            "57/57 [==============================] - 1s 13ms/step - loss: 1.9051 - accuracy: 0.3946 - val_loss: 1.8500 - val_accuracy: 0.4235\n",
            "Epoch 37/200\n",
            "57/57 [==============================] - 1s 12ms/step - loss: 1.9036 - accuracy: 0.3946 - val_loss: 1.8494 - val_accuracy: 0.4235\n",
            "Epoch 38/200\n",
            "57/57 [==============================] - 1s 13ms/step - loss: 1.9015 - accuracy: 0.3951 - val_loss: 1.8491 - val_accuracy: 0.4230\n",
            "Epoch 39/200\n",
            "57/57 [==============================] - 1s 13ms/step - loss: 1.8997 - accuracy: 0.3954 - val_loss: 1.8486 - val_accuracy: 0.4239\n",
            "Epoch 40/200\n",
            "57/57 [==============================] - 1s 13ms/step - loss: 1.8976 - accuracy: 0.3965 - val_loss: 1.8476 - val_accuracy: 0.4239\n",
            "Epoch 41/200\n",
            "57/57 [==============================] - 1s 13ms/step - loss: 1.8960 - accuracy: 0.3959 - val_loss: 1.8475 - val_accuracy: 0.4226\n",
            "Epoch 42/200\n",
            "57/57 [==============================] - 1s 13ms/step - loss: 1.8943 - accuracy: 0.3965 - val_loss: 1.8468 - val_accuracy: 0.4222\n",
            "Epoch 43/200\n",
            "57/57 [==============================] - 1s 13ms/step - loss: 1.8926 - accuracy: 0.3974 - val_loss: 1.8465 - val_accuracy: 0.4226\n",
            "Epoch 44/200\n",
            "57/57 [==============================] - 1s 13ms/step - loss: 1.8909 - accuracy: 0.3986 - val_loss: 1.8463 - val_accuracy: 0.4226\n",
            "Epoch 45/200\n",
            "57/57 [==============================] - 1s 12ms/step - loss: 1.8895 - accuracy: 0.3993 - val_loss: 1.8456 - val_accuracy: 0.4222\n",
            "Epoch 46/200\n",
            "57/57 [==============================] - 1s 13ms/step - loss: 1.8876 - accuracy: 0.3980 - val_loss: 1.8452 - val_accuracy: 0.4190\n",
            "Epoch 47/200\n",
            "57/57 [==============================] - 1s 13ms/step - loss: 1.8861 - accuracy: 0.3964 - val_loss: 1.8448 - val_accuracy: 0.4190\n",
            "Epoch 48/200\n",
            "57/57 [==============================] - 1s 13ms/step - loss: 1.8844 - accuracy: 0.3966 - val_loss: 1.8449 - val_accuracy: 0.4202\n",
            "Epoch 49/200\n",
            "57/57 [==============================] - 1s 13ms/step - loss: 1.8832 - accuracy: 0.3952 - val_loss: 1.8447 - val_accuracy: 0.4210\n",
            "Epoch 50/200\n",
            "57/57 [==============================] - 1s 12ms/step - loss: 1.8820 - accuracy: 0.3958 - val_loss: 1.8447 - val_accuracy: 0.4206\n",
            "Epoch 51/200\n",
            "57/57 [==============================] - 1s 13ms/step - loss: 1.8810 - accuracy: 0.3964 - val_loss: 1.8447 - val_accuracy: 0.4214\n",
            "Epoch 52/200\n",
            "57/57 [==============================] - 1s 12ms/step - loss: 1.8797 - accuracy: 0.3962 - val_loss: 1.8447 - val_accuracy: 0.4218\n",
            "Epoch 53/200\n",
            "57/57 [==============================] - 1s 13ms/step - loss: 1.8789 - accuracy: 0.3962 - val_loss: 1.8447 - val_accuracy: 0.4218\n",
            "Epoch 54/200\n",
            "57/57 [==============================] - 1s 13ms/step - loss: 1.8780 - accuracy: 0.3963 - val_loss: 1.8448 - val_accuracy: 0.4214\n",
            "Epoch 55/200\n",
            "57/57 [==============================] - 1s 13ms/step - loss: 1.8767 - accuracy: 0.3961 - val_loss: 1.8448 - val_accuracy: 0.4214\n",
            "Epoch 56/200\n",
            "57/57 [==============================] - 1s 13ms/step - loss: 1.8758 - accuracy: 0.3967 - val_loss: 1.8447 - val_accuracy: 0.4210\n",
            "Epoch 57/200\n",
            "57/57 [==============================] - 1s 13ms/step - loss: 1.8749 - accuracy: 0.3971 - val_loss: 1.8448 - val_accuracy: 0.4202\n",
            "Epoch 58/200\n",
            "57/57 [==============================] - 1s 13ms/step - loss: 1.8740 - accuracy: 0.3976 - val_loss: 1.8450 - val_accuracy: 0.4206\n",
            "Epoch 59/200\n",
            "57/57 [==============================] - 1s 13ms/step - loss: 1.8730 - accuracy: 0.3980 - val_loss: 1.8452 - val_accuracy: 0.4206\n",
            "Epoch 60/200\n",
            "57/57 [==============================] - 1s 13ms/step - loss: 1.8722 - accuracy: 0.3985 - val_loss: 1.8453 - val_accuracy: 0.4202\n",
            "Epoch 61/200\n",
            "57/57 [==============================] - 1s 13ms/step - loss: 1.8712 - accuracy: 0.3989 - val_loss: 1.8455 - val_accuracy: 0.4210\n",
            "Epoch 62/200\n",
            "57/57 [==============================] - 1s 13ms/step - loss: 1.8703 - accuracy: 0.3976 - val_loss: 1.8457 - val_accuracy: 0.4218\n",
            "Epoch 63/200\n",
            "57/57 [==============================] - 1s 13ms/step - loss: 1.8694 - accuracy: 0.3975 - val_loss: 1.8457 - val_accuracy: 0.4222\n",
            "Epoch 64/200\n",
            "57/57 [==============================] - 1s 13ms/step - loss: 1.8685 - accuracy: 0.3981 - val_loss: 1.8455 - val_accuracy: 0.4226\n",
            "Epoch 65/200\n",
            "57/57 [==============================] - 1s 13ms/step - loss: 1.8675 - accuracy: 0.3982 - val_loss: 1.8454 - val_accuracy: 0.4222\n",
            "Epoch 66/200\n",
            "57/57 [==============================] - 1s 13ms/step - loss: 1.8664 - accuracy: 0.3978 - val_loss: 1.8454 - val_accuracy: 0.4222\n",
            "Model Accuracy on test: 41.04%, Loss: 1.86\n",
            "************************************************完成训练LSTM模型************************************************\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vb61k6azuEXI"
      },
      "source": [
        "### 保存模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wf93Al9PuBMJ",
        "outputId": "f09274b7-5a0a-42af-c352-ca7f07434bf4"
      },
      "source": [
        "print(\"保存模型：%s\" % model_file)\r\n",
        "model.save(model_file)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "保存模型：./model/phpbb_part.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cio0kQzJxZvy"
      },
      "source": [
        "# 其他命令"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3CplBdexFho7"
      },
      "source": [
        "## 解压文件"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9UiUkJhxZZo",
        "outputId": "e4cc0a13-becc-40a8-8b49-249a0256462f"
      },
      "source": [
        "!unzip '/content/wordlist.zip'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/wordlist.zip\n",
            "  inflating: phpbb_test.txt          \n",
            "  inflating: phpbb_train.txt         \n",
            "  inflating: myspace.txt             \n",
            "  inflating: myspace_test.txt        \n",
            "  inflating: myspace_train.txt       \n",
            "  inflating: phpbb.txt               \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYE2I-0TyaPu",
        "outputId": "669fca7c-59c0-4238-8d7c-7d8d18dc914d"
      },
      "source": [
        "!unzip '/content/tokenizer.zip'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/tokenizer.zip\n",
            "  inflating: phpbb.pkl               \n",
            "  inflating: rockyou.pkl             \n",
            "  inflating: myspace.pkl             \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44bHaLNWFli-"
      },
      "source": [
        "## 使用tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqDA8YlT0KiY"
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41jNXoRi0OaH"
      },
      "source": [
        "%tensorboard --logdir '/content/logs/phpbb210305064918'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5pdS0jeFPLm"
      },
      "source": [
        "## 查看GPU、CPU情况\r\n",
        "参考资料：https://blog.csdn.net/qq_38410428/article/details/89963503"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3iyL8uTE5bw"
      },
      "source": [
        "查看GPU是否在colab中，如果结果为空，则不能使用GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsT5BYcWE2pu"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6olWRMmxFFuX"
      },
      "source": [
        "如果结果为/device:GPU:0，使用```!/opt/bin/nvidia-smi```查看显存情况"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEqviylMFHDk"
      },
      "source": [
        "!/opt/bin/nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}