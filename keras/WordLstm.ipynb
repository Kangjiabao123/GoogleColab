{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WordLstm.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN6uMWEKjseabQfTaUyfs+S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YapingWu/GoogleColab/blob/main/keras/WordLstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXgA5Sy0sz4K"
      },
      "source": [
        "# Word-Level LSTM实现文本生成"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvCapV82uauY"
      },
      "source": [
        "## 准备工作"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhpeLvPQudIX"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\r\n",
        "from keras.utils import to_categorical\r\n",
        "from keras.preprocessing.sequence import pad_sequences\r\n",
        "from keras.models import Sequential, load_model\r\n",
        "from keras.layers import Embedding, LSTM, Dense, TimeDistributed\r\n",
        "from keras import optimizers\r\n",
        "from keras.callbacks import TensorBoard\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import time\r\n",
        "import pickle"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ud4pYF6v_7b"
      },
      "source": [
        "data_name = 'myspace'\r\n",
        "max_lengths = {\r\n",
        "    'myspace': 35,\r\n",
        "    'phpbb': 21,\r\n",
        "    'rockyou': 41,\r\n",
        "}\r\n",
        "SEED = 7"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spwLPnT2zIUu",
        "outputId": "4fe5c1a5-f660-4721-c1a0-ce53cc7c4964"
      },
      "source": [
        "word_list_file = '{}{}.txt'.format('/content/', data_name)\r\n",
        "tokenizer_file = '{}{}.pkl'.format('/content/', data_name)\r\n",
        "print(word_list_file)\r\n",
        "print(tokenizer_file)\r\n",
        "with open(tokenizer_file, 'rb') as file:\r\n",
        "  tokenizer = pickle.load(file)\r\n",
        "vocab_size = len(tokenizer.word_index) + 1\r\n",
        "max_length = max_lengths[data_name]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/myspace.txt\n",
            "/content/myspace.pkl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1KDL7IzuWdV"
      },
      "source": [
        "## 加载数据"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQRYQQDqvjS0"
      },
      "source": [
        "word_list = pd.read_csv(word_list_file)['grammar']\r\n",
        "word_list = word_list.values.tolist()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DixuqvVnsrDt",
        "outputId": "4fc46b07-bc9a-4bbd-e506-9dcd15c72a0a"
      },
      "source": [
        "# 将编码后的密码转换为整数序列\r\n",
        "print(\"将编码后的密码转换为（整数）序列\")\r\n",
        "sequences = list()\r\n",
        "for line in word_list:  # 'L8 D1 '\r\n",
        "    line += '<END>'\r\n",
        "    # 将文本转换为（整数）序列\r\n",
        "    encoded = tokenizer.texts_to_sequences([line])[0]\r\n",
        "    # 过滤掉长度大于 MAX_SEQ_LEN 的序列\r\n",
        "    if len(encoded) > max_length:\r\n",
        "        continue\r\n",
        "    for i in range(1, len(encoded) + 1):\r\n",
        "        sequence = encoded[:i]\r\n",
        "        sequences.append(sequence)\r\n",
        "\r\n",
        "print('Total Sequences: %d' % len(sequences))\r\n",
        "\r\n",
        "# pad input sequences\r\n",
        "max_length = max([len(seq) for seq in sequences])\r\n",
        "sequences = pad_sequences(sequences, max_length, padding='pre')  # 左边填充0\r\n",
        "print('Max Sequence Length: %d' % max_length)\r\n",
        "\r\n",
        "# 创建输入输出\r\n",
        "print(\"创建LSTM模型的输入输出\")\r\n",
        "sequences = np.array(sequences)\r\n",
        "x, y = sequences[:, :-1], sequences[:, -1]\r\n",
        "print(\"X Shape: %s, y Shape: %s\" % (x.shape, y.shape))\r\n",
        "y = to_categorical(y, num_classes=vocab_size)  # 对输出进行one-hot编码"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "将编码后的密码转换为（整数）序列\n",
            "Total Sequences: 8976\n",
            "Max Sequence Length: 35\n",
            "创建LSTM模型的输入输出\n",
            "X Shape: (8976, 34), y Shape: (8976,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TUEWv6WuKoD"
      },
      "source": [
        "### 划分训练集、验证集和测试集"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0WoOhHPtgXn",
        "outputId": "7cd48057-138d-4b11-ff56-26a63024ba03"
      },
      "source": [
        "def split_xy(x, y):\r\n",
        "\r\n",
        "    ratio = 0.6  # 训练集比例\r\n",
        "    if len(x) > 100000:\r\n",
        "        ratio = 0.9\r\n",
        "\r\n",
        "    print(\"划分训练集、验证集和测试集\")\r\n",
        "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=1 - ratio, random_state=SEED)\r\n",
        "    x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=0.5, random_state=SEED)\r\n",
        "\r\n",
        "    print(\"x_train Shape: %s, y_train Shape: %s\" % (x_train.shape, y_train.shape))\r\n",
        "    print(\"x_val Shape: %s, y_val Shape: %s\" % (x_val.shape, y_val.shape))\r\n",
        "    print(\"x_test Shape: %s, y_test Shape: %s\" % (x_test.shape, y_test.shape))\r\n",
        "\r\n",
        "    return x_train, x_val, x_test, y_train, y_val, y_test\r\n",
        "\r\n",
        "x_train, x_val, x_test, y_train, y_val, y_test = split_xy(x, y)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "划分训练集、验证集和测试集\n",
            "x_train Shape: (5385, 34), y_train Shape: (5385, 73)\n",
            "x_val Shape: (1795, 34), y_val Shape: (1795, 73)\n",
            "x_test Shape: (1796, 34), y_test Shape: (1796, 73)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0T3gxLZotMyn"
      },
      "source": [
        "## 创建和训练模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqdB5-XExJ5Q"
      },
      "source": [
        "cur_time = time.strftime(\"%y%m%d%H%M%S\", time.localtime())\r\n",
        "log_name = '{}{}{}'.format('./logs/', data_name, cur_time)\r\n",
        "model_file = '{}{}.h5'.format('./model/', data_name)\r\n",
        "\r\n",
        "epochs = 30\r\n",
        "batch_size = 128\r\n",
        "lstm_layers = [[256, True], [256, True], [256, False]]\r\n",
        "fully_layers = [512]"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50x1Oy07to6y"
      },
      "source": [
        "### 创建模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKKkrDyRtta-",
        "outputId": "3ddd88cc-9276-4af5-9ae6-05af7a7b210c"
      },
      "source": [
        "print('{:*^106}'.format('创建LSTM模型'))\r\n",
        "model = Sequential()\r\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=10, input_length=max_length - 1))\r\n",
        "\r\n",
        "for hidden_size, rs in lstm_layers:\r\n",
        "    model.add(LSTM(hidden_size, return_sequences=rs))\r\n",
        "\r\n",
        "for hidden_size in fully_layers:\r\n",
        "    model.add(Dense(units=hidden_size, activation='relu'))\r\n",
        "model.add(Dense(vocab_size, activation='softmax'))\r\n",
        "\r\n",
        "model.summary()\r\n",
        "\r\n",
        "adam = optimizers.Adam(lr=0.001)\r\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*************************************************创建LSTM模型*************************************************\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_7 (Embedding)      (None, 34, 10)            730       \n",
            "_________________________________________________________________\n",
            "lstm_21 (LSTM)               (None, 34, 256)           273408    \n",
            "_________________________________________________________________\n",
            "lstm_22 (LSTM)               (None, 34, 256)           525312    \n",
            "_________________________________________________________________\n",
            "lstm_23 (LSTM)               (None, 256)               525312    \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 512)               131584    \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 73)                37449     \n",
            "=================================================================\n",
            "Total params: 1,493,795\n",
            "Trainable params: 1,493,795\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPb-yQt1uCvE"
      },
      "source": [
        "### 训练模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1sJnXlPtPpc",
        "outputId": "0b9a2c68-8d96-4c66-9a64-cddf591ceded"
      },
      "source": [
        "tensorboard = TensorBoard(log_dir=log_name)\r\n",
        "\r\n",
        "print('{:*^106}'.format('开始训练LSTM模型'))\r\n",
        "model.fit(x_train, y_train,\r\n",
        "          validation_data=(x_val, y_val),\r\n",
        "          epochs=epochs,\r\n",
        "          batch_size=batch_size,\r\n",
        "          verbose=1,\r\n",
        "          callbacks=[tensorboard])\r\n",
        "loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\r\n",
        "print(\"Model Accuracy on test: %.2f%%, Loss: %.2f\" % (accuracy * 100, loss))\r\n",
        "print('{:*^106}'.format('完成训练LSTM模型'))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "************************************************开始训练LSTM模型************************************************\n",
            "Epoch 1/30\n",
            "43/43 [==============================] - 45s 1s/step - loss: 2.6538 - accuracy: 0.1783 - val_loss: 2.6287 - val_accuracy: 0.1894\n",
            "Epoch 2/30\n",
            "43/43 [==============================] - 44s 1s/step - loss: 2.6612 - accuracy: 0.1835 - val_loss: 2.6254 - val_accuracy: 0.1894\n",
            "Epoch 3/30\n",
            "43/43 [==============================] - 44s 1s/step - loss: 2.6588 - accuracy: 0.1842 - val_loss: 2.6166 - val_accuracy: 0.1727\n",
            "Epoch 4/30\n",
            "43/43 [==============================] - 44s 1s/step - loss: 2.6416 - accuracy: 0.1853 - val_loss: 2.6132 - val_accuracy: 0.1727\n",
            "Epoch 5/30\n",
            "43/43 [==============================] - 44s 1s/step - loss: 2.5861 - accuracy: 0.2178 - val_loss: 2.5450 - val_accuracy: 0.2490\n",
            "Epoch 6/30\n",
            "43/43 [==============================] - 44s 1s/step - loss: 2.5352 - accuracy: 0.2494 - val_loss: 2.4681 - val_accuracy: 0.2696\n",
            "Epoch 7/30\n",
            "43/43 [==============================] - 44s 1s/step - loss: 2.4824 - accuracy: 0.2700 - val_loss: 2.4338 - val_accuracy: 0.2652\n",
            "Epoch 8/30\n",
            "43/43 [==============================] - 44s 1s/step - loss: 2.4494 - accuracy: 0.2852 - val_loss: 2.4310 - val_accuracy: 0.2468\n",
            "Epoch 9/30\n",
            "43/43 [==============================] - 44s 1s/step - loss: 2.3992 - accuracy: 0.2856 - val_loss: 2.3306 - val_accuracy: 0.3014\n",
            "Epoch 10/30\n",
            "43/43 [==============================] - 44s 1s/step - loss: 2.2964 - accuracy: 0.3255 - val_loss: 2.2228 - val_accuracy: 0.3348\n",
            "Epoch 11/30\n",
            "43/43 [==============================] - 44s 1s/step - loss: 2.2151 - accuracy: 0.3257 - val_loss: 2.1520 - val_accuracy: 0.3365\n",
            "Epoch 12/30\n",
            "43/43 [==============================] - 44s 1s/step - loss: 2.1545 - accuracy: 0.3253 - val_loss: 2.1022 - val_accuracy: 0.3304\n",
            "Epoch 13/30\n",
            "43/43 [==============================] - 44s 1s/step - loss: 2.1140 - accuracy: 0.3341 - val_loss: 2.1086 - val_accuracy: 0.3209\n",
            "Epoch 14/30\n",
            "43/43 [==============================] - 44s 1s/step - loss: 2.0964 - accuracy: 0.3302 - val_loss: 2.0707 - val_accuracy: 0.3270\n",
            "Epoch 15/30\n",
            "43/43 [==============================] - 44s 1s/step - loss: 2.0751 - accuracy: 0.3434 - val_loss: 2.0585 - val_accuracy: 0.3515\n",
            "Epoch 16/30\n",
            "43/43 [==============================] - 44s 1s/step - loss: 2.0535 - accuracy: 0.3493 - val_loss: 2.0841 - val_accuracy: 0.3304\n",
            "Epoch 17/30\n",
            "43/43 [==============================] - 44s 1s/step - loss: 2.0699 - accuracy: 0.3411 - val_loss: 2.0500 - val_accuracy: 0.3577\n",
            "Epoch 18/30\n",
            "43/43 [==============================] - 45s 1s/step - loss: 2.0321 - accuracy: 0.3554 - val_loss: 2.0252 - val_accuracy: 0.3694\n",
            "Epoch 19/30\n",
            "43/43 [==============================] - 44s 1s/step - loss: 2.0111 - accuracy: 0.3684 - val_loss: 2.0631 - val_accuracy: 0.3426\n",
            "Epoch 20/30\n",
            "43/43 [==============================] - 44s 1s/step - loss: 1.9986 - accuracy: 0.3742 - val_loss: 1.9969 - val_accuracy: 0.3694\n",
            "Epoch 21/30\n",
            "43/43 [==============================] - 44s 1s/step - loss: 1.9863 - accuracy: 0.3694 - val_loss: 2.0006 - val_accuracy: 0.3538\n",
            "Epoch 22/30\n",
            "43/43 [==============================] - 44s 1s/step - loss: 1.9725 - accuracy: 0.3751 - val_loss: 1.9956 - val_accuracy: 0.3671\n",
            "Epoch 23/30\n",
            "43/43 [==============================] - 44s 1s/step - loss: 1.9725 - accuracy: 0.3742 - val_loss: 1.9835 - val_accuracy: 0.3738\n",
            "Epoch 24/30\n",
            "43/43 [==============================] - 44s 1s/step - loss: 1.9511 - accuracy: 0.3794 - val_loss: 1.9857 - val_accuracy: 0.3727\n",
            "Epoch 25/30\n",
            "43/43 [==============================] - 45s 1s/step - loss: 1.9456 - accuracy: 0.3844 - val_loss: 1.9759 - val_accuracy: 0.3861\n",
            "Epoch 26/30\n",
            "43/43 [==============================] - 44s 1s/step - loss: 1.9481 - accuracy: 0.3785 - val_loss: 2.0043 - val_accuracy: 0.3649\n",
            "Epoch 27/30\n",
            "43/43 [==============================] - 44s 1s/step - loss: 1.9449 - accuracy: 0.3807 - val_loss: 1.9714 - val_accuracy: 0.3833\n",
            "Epoch 28/30\n",
            "43/43 [==============================] - 44s 1s/step - loss: 1.9231 - accuracy: 0.3825 - val_loss: 1.9803 - val_accuracy: 0.3699\n",
            "Epoch 29/30\n",
            "43/43 [==============================] - 44s 1s/step - loss: 1.9219 - accuracy: 0.3887 - val_loss: 1.9801 - val_accuracy: 0.3755\n",
            "Epoch 30/30\n",
            "43/43 [==============================] - 44s 1s/step - loss: 1.9183 - accuracy: 0.3885 - val_loss: 1.9698 - val_accuracy: 0.3766\n",
            "Model Accuracy on test: 38.92%, Loss: 1.96\n",
            "************************************************完成训练LSTM模型************************************************\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vb61k6azuEXI"
      },
      "source": [
        "### 保存模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wf93Al9PuBMJ"
      },
      "source": [
        "print(\"保存模型：%s\" % model_file)\r\n",
        "model.save(model_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cio0kQzJxZvy"
      },
      "source": [
        "# 其他命令"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9UiUkJhxZZo",
        "outputId": "7bd9255b-76c1-4b68-da09-984eb544f59f"
      },
      "source": [
        "!unzip '/content/wordlist.zip'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/wordlist.zip\n",
            "  inflating: myspace.txt             \n",
            "  inflating: phpbb.txt               \n",
            "  inflating: rockyou.txt             \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYE2I-0TyaPu",
        "outputId": "4991c62e-8cfa-4b50-8ebb-c51be42ad81b"
      },
      "source": [
        "!unzip '/content/tokenizer.zip'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/tokenizer.zip\n",
            "  inflating: phpbb.pkl               \n",
            "  inflating: rockyou.pkl             \n",
            "  inflating: myspace.pkl             \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqDA8YlT0KiY"
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41jNXoRi0OaH"
      },
      "source": [
        "%tensorboard --logdir '/content/logs/myspace210301071211'"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}