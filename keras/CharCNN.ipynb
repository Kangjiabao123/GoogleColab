{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CharCNN.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOeu+a3soBYsh1/bIiV+FO6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YapingWu/GoogleColab/blob/main/keras/CharCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0S2f_CZ0i48t"
      },
      "source": [
        "# 加载数据"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxS0BAwmiCa-"
      },
      "source": [
        "from keras.models import Sequential, load_model\r\n",
        "from keras.layers import Embedding, Dense, Conv1D, MaxPool1D, AlphaDropout, Flatten\r\n",
        "from keras.initializers import RandomNormal\r\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fg49eJyQiU8T"
      },
      "source": [
        "SEED = 7"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCEciInNmo_F"
      },
      "source": [
        "import numpy as np\r\n",
        "x = np.loadtxt('/content/x.txt')\r\n",
        "y = np.loadtxt('/content/y.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBLGE1iFislV"
      },
      "source": [
        "logger.info(\"划分训练集、验证集和测试集\")\r\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=SEED)\r\n",
        "x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=0.5, random_state=SEED)\r\n",
        "\r\n",
        "print(\"x_train Shape: %s, y_train Shape: %s\" % (x_train.shape, y_train.shape))\r\n",
        "print(\"x_val Shape: %s, y_val Shape: %s\" % (x_val.shape, y_val.shape))\r\n",
        "print(\"x_test Shape: %s, y_test Shape: %s\" % (x_test.shape, y_test.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlpQ6ECGjpxg"
      },
      "source": [
        "# 创建和训练模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvro-91JjzPt"
      },
      "source": [
        "# 超參數\r\n",
        "data_names = ['myspace,' 'phpbb,' 'rockyou']\r\n",
        "alphabet = \"abcdefghijklmnopqrstuvwxyz0123456789-;.!?:'\\\"/\\\\|_@#$%^&*~`+-=<>()[]{}\"\r\n",
        "alphabet_size = len(alphabet)\r\n",
        "length = 100\r\n",
        "no_of_classes = 3\r\n",
        "batch_size = 128\r\n",
        "epochs = 2\r\n",
        "conv_layers = [\r\n",
        "                  [256, 7, 3],\r\n",
        "                  [256, 7, 3],\r\n",
        "                  [256, 3, None],\r\n",
        "                  [256, 3, None],\r\n",
        "                  [256, 3, None],\r\n",
        "                  [256, 3, 3]\r\n",
        "              ]\r\n",
        "fully_layers = [1024, 1024]\r\n",
        "embedding_size = 50\r\n",
        "th = 1e-6\r\n",
        "dropout_p = 0.5\r\n",
        "optimizer = 'adam'\r\n",
        "initializer_stddev = 0.05\r\n",
        "loss = 'categorical_crossentropy'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTMz4IcXih9Y"
      },
      "source": [
        "print('创建CNN模型...')\r\n",
        "model = Sequential()\r\n",
        "# Embedding layers\r\n",
        "model.add(Embedding(input_dim=alphabet_size + 1, output_dim=embedding_size, input_length=length))\r\n",
        "# Convolution layers\r\n",
        "for num_filters, filter_width, pool_size in conv_layers:\r\n",
        "    model.add(Conv1D(filters=num_filters,\r\n",
        "                      kernel_size=filter_width,\r\n",
        "                      kernel_initializer=RandomNormal(mean=0, stddev=initializer_stddev),\r\n",
        "                      activation='tanh'))\r\n",
        "    if pool_size is not None:\r\n",
        "        model.add(MaxPool1D(pool_size))\r\n",
        "# Fully connected layers\r\n",
        "model.add(Flatten())\r\n",
        "for units in fully_layers:\r\n",
        "    model.add(Dense(units, activation='selu', kernel_initializer='lecun_normal'))\r\n",
        "    model.add(AlphaDropout(dropout_p))\r\n",
        "model.add(Dense(no_of_classes, activation='softmax'))\r\n",
        "\r\n",
        "# Build and compile model\r\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\r\n",
        "print('创建模型：\\n')\r\n",
        "model.summary()\r\n",
        "\r\n",
        "print('开始训练CNN模型')\r\n",
        "model.fit(x_train, y_train,\r\n",
        "          validation_data=(x_val, y_val),\r\n",
        "          epochs=epochs,\r\n",
        "          batch_size=batch_size,\r\n",
        "          verbose=1)\r\n",
        "loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\r\n",
        "print(\"Model Accuracy on test: %.2f%%, Loss: %.2f\" % (accuracy * 100, loss))\r\n",
        "model_file = './model/cnn.h5'\r\n",
        "print(\"保存模型：%s\" % model_file)\r\n",
        "model.save(model_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gdfpQ5CmuTi"
      },
      "source": [
        "# 其他命令"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rju4gL4Mmw7V"
      },
      "source": [
        "!unzip cnn.zip"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}