{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CharCNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNutQiuuPFfCuQCXLwVLWrb",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YapingWu/GoogleColab/blob/main/keras/CharCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42paDaE9tMSj"
      },
      "source": [
        "参考资料：\r\n",
        "1.   https://blog.csdn.net/liuchonge/article/details/70947995\r\n",
        "2.   https://github.com/mhjabreel/CharCnn_Keras\r\n",
        "\r\n",
        "论文：Character-level Convolutional Networks for Text Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0S2f_CZ0i48t"
      },
      "source": [
        "# 加载数据"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxS0BAwmiCa-"
      },
      "source": [
        "from keras.models import Sequential, load_model\r\n",
        "from keras.layers import Embedding, Dense, Conv1D, MaxPool1D, AlphaDropout, Flatten\r\n",
        "from keras.initializers import RandomNormal\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from keras.utils import to_categorical\r\n",
        "from keras.preprocessing.sequence import pad_sequences\r\n",
        "from keras.callbacks import TensorBoard\r\n",
        "import time\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "SEED = 7\r\n",
        "data_names = ['myspace', 'phpbb', 'rockyou']\r\n",
        "alphabet = \"abcdefghijklmnopqrstuvwxyz0123456789-;.!?:'\\\"/\\\\|_@#$%^&*~`+-=<>()[]{}\"\r\n",
        "alphabet_size = len(alphabet)\r\n",
        "length = 100\r\n",
        "no_of_classes = 3\r\n",
        "char_to_int = dict((c, i+1) for i, c in enumerate(alphabet))  # 索引0保留\r\n",
        "int_to_char = dict((i+1, c) for i, c in enumerate(alphabet))\r\n",
        "data_size = 40000"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCEciInNmo_F"
      },
      "source": [
        "\r\n",
        "def encode_xy(x, y):\r\n",
        "    x_ = x.apply(lambda s: [char_to_int[char] if char in alphabet else 0\r\n",
        "                            for char in str(s).lower()])  # 对x进行编码\r\n",
        "    x_ = pad_sequences(x_, length, padding='post')\r\n",
        "    y_ = to_categorical(y, num_classes=no_of_classes, dtype='int32')\r\n",
        "    return x_, y_\r\n",
        "\r\n",
        "def generate_data(data, data_ratio=0.6):\r\n",
        "    print('生成数据...')\r\n",
        "    n = int(data.shape[0] * data_ratio)\r\n",
        "    data = data[:n]\r\n",
        "    num_batch = int(data.shape[0] / batch_size) + 1\r\n",
        "    i = 0\r\n",
        "    while True:\r\n",
        "        i = i % num_batch\r\n",
        "        cur_data = data[batch_size * i: batch_size * (i + 1)]\r\n",
        "        # 对输入输出数据进行编码\r\n",
        "        x, y = encode_xy(cur_data['pwd'], cur_data['category'])\r\n",
        "        i += 1\r\n",
        "        yield x, y\r\n",
        "\r\n",
        "def load_data():\r\n",
        "    print('开始加载数据...')\r\n",
        "    data_list = []\r\n",
        "    for index, data_name in enumerate(data_names):\r\n",
        "        file_name = '/content/{}.txt'.format(data_name)\r\n",
        "        df_tmp = pd.read_csv(file_name, header=None, names=['pwd'])\r\n",
        "        df_tmp['category'] = index\r\n",
        "        data_list.append(df_tmp[:data_size])  # 加载指定大小的数据\r\n",
        "        print('{}：{}'.format(data_name, df_tmp.shape[0]))\r\n",
        "\r\n",
        "    data = pd.concat(data_list, ignore_index=True)  # 合并数据\r\n",
        "    data = data.sample(frac=1.0, random_state=SEED)  # 打乱数据\r\n",
        "    print('训练模型的总数据量：{}'.format(data.shape[0]))\r\n",
        "    return data"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlpQ6ECGjpxg"
      },
      "source": [
        "# 创建和训练模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvro-91JjzPt"
      },
      "source": [
        "# 超参数\r\n",
        "batch_size = 128\r\n",
        "epochs = 10\r\n",
        "conv_layers = [\r\n",
        "                  [256, 7, 3],\r\n",
        "                  [256, 7, 3],\r\n",
        "                  [256, 3, None],\r\n",
        "                  [256, 3, None],\r\n",
        "                  [256, 3, None],\r\n",
        "                  [256, 3, 3]\r\n",
        "              ]\r\n",
        "fully_layers = [1024, 1024]\r\n",
        "embedding_size = 50\r\n",
        "th = 1e-6\r\n",
        "dropout_p = 0.5\r\n",
        "optimizer = 'adam'\r\n",
        "initializer_stddev = 0.05\r\n",
        "loss = 'categorical_crossentropy'\r\n",
        "log_name = './logs/{}'.format(time.time())"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dIUQf4kfum0l",
        "outputId": "027e0fc7-c73f-46ef-9a67-686127947467"
      },
      "source": [
        "data = load_data()  # 加载数据\r\n",
        "data.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "开始加载数据...\n",
            "myspace：37144\n",
            "phpbb：184379\n",
            "rockyou：14339373\n",
            "训练模型的总数据量：117144\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(117144, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2NMPa2wu04f",
        "outputId": "e6599200-bb9b-47cf-a946-06431a5fc0eb"
      },
      "source": [
        "# 创建和训练模型\r\n",
        "train_ratio = 0.8\r\n",
        "# 划分测试集和训练集\r\n",
        "print(\"划分验证集和测试集\")\r\n",
        "train_size = int(data.shape[0] * train_ratio)\r\n",
        "test_size = int(data.shape[0] * (1 - train_ratio) / 2)\r\n",
        "val_data = data[train_size: train_size + test_size]\r\n",
        "test_data = data[-test_size:]\r\n",
        "x_val, y_val = encode_xy(val_data['pwd'], val_data['category'])\r\n",
        "x_test, y_test = encode_xy(test_data['pwd'], test_data['category'])\r\n",
        "print(\"x_val Shape: %s, y_val Shape: %s\" % (x_val.shape, y_val.shape))\r\n",
        "print(\"x_test Shape: %s, y_test Shape: %s\" % (x_test.shape, y_test.shape))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "划分验证集和测试集\n",
            "x_val Shape: (11714, 100), y_val Shape: (11714, 3)\n",
            "x_test Shape: (11714, 100), y_test Shape: (11714, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTMz4IcXih9Y",
        "outputId": "1e62a4c4-a404-4149-b241-b1b2a63db7cb"
      },
      "source": [
        "print('创建CNN模型...')\r\n",
        "model = Sequential()\r\n",
        "# Embedding layers\r\n",
        "model.add(Embedding(input_dim=alphabet_size + 1, output_dim=embedding_size, input_length=length))\r\n",
        "# Convolution layers\r\n",
        "initializer = RandomNormal(0, 0.05)\r\n",
        "for num_filters, filter_width, pool_size in conv_layers:\r\n",
        "    model.add(Conv1D(filters=num_filters,\r\n",
        "                     kernel_size=filter_width,\r\n",
        "                     kernel_initializer=initializer,\r\n",
        "                     activation='tanh',\r\n",
        "                     padding='same'))\r\n",
        "    if pool_size is not None:\r\n",
        "        model.add(MaxPool1D(pool_size))\r\n",
        "# Fully connected layers\r\n",
        "model.add(Flatten())\r\n",
        "for units in fully_layers:\r\n",
        "    model.add(Dense(units, activation='selu', kernel_initializer='lecun_normal'))\r\n",
        "    model.add(AlphaDropout(dropout_p))\r\n",
        "model.add(Dense(no_of_classes, activation='softmax'))\r\n",
        "\r\n",
        "# Build and compile model\r\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\r\n",
        "print('创建模型：')\r\n",
        "model.summary()\r\n",
        "\r\n",
        "print('开始训练CNN模型')\r\n",
        "tensorboard = TensorBoard(log_dir=log_name)\r\n",
        "num_batch = int(data.shape[0] / batch_size)\r\n",
        "# 开始训练\r\n",
        "model.fit(generate_data(data, data_ratio=train_ratio),\r\n",
        "          validation_data=(x_val, y_val),\r\n",
        "          steps_per_epoch=num_batch,\r\n",
        "          epochs=epochs,\r\n",
        "          verbose=1,\r\n",
        "          callbacks=[tensorboard])\r\n",
        "loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\r\n",
        "print(\"Model Accuracy on test: %.2f%%, Loss: %.2f\" % (accuracy * 100, loss))\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "创建CNN模型...\n",
            "创建模型：\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 100, 50)           3450      \n",
            "_________________________________________________________________\n",
            "conv1d_12 (Conv1D)           (None, 100, 256)          89856     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_6 (MaxPooling1 (None, 33, 256)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_13 (Conv1D)           (None, 33, 256)           459008    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_7 (MaxPooling1 (None, 11, 256)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_14 (Conv1D)           (None, 11, 256)           196864    \n",
            "_________________________________________________________________\n",
            "conv1d_15 (Conv1D)           (None, 11, 256)           196864    \n",
            "_________________________________________________________________\n",
            "conv1d_16 (Conv1D)           (None, 11, 256)           196864    \n",
            "_________________________________________________________________\n",
            "conv1d_17 (Conv1D)           (None, 11, 256)           196864    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_8 (MaxPooling1 (None, 3, 256)            0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 768)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1024)              787456    \n",
            "_________________________________________________________________\n",
            "alpha_dropout_4 (AlphaDropou (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1024)              1049600   \n",
            "_________________________________________________________________\n",
            "alpha_dropout_5 (AlphaDropou (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 3)                 3075      \n",
            "=================================================================\n",
            "Total params: 3,179,901\n",
            "Trainable params: 3,179,901\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "开始训练CNN模型\n",
            "生成数据...\n",
            "Epoch 1/10\n",
            " 78/915 [=>............................] - ETA: 12:04 - loss: 1.5858 - accuracy: 0.3512"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9xWelvrBOuY"
      },
      "source": [
        "model_file = './model/cnn.h5'\r\n",
        "print(\"保存模型：%s\" % model_file)\r\n",
        "model.save(model_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JR2FsK7ysn4i"
      },
      "source": [
        "# 其他命令"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6AFZTd_sqJY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54abf970-ba1f-4147-983f-8e7acfc3fcfc"
      },
      "source": [
        "!unzip '/content/raw_data.zip'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/raw_data.zip\n",
            "  inflating: phpbb.txt               \n",
            "  inflating: rockyou.txt             \n",
            "  inflating: myspace.txt             \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}