{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CharCNN.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO+CvuZicrOlCumBTwmtin6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YapingWu/GoogleColab/blob/main/keras/CharCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42paDaE9tMSj"
      },
      "source": [
        "参考资料：\r\n",
        "1.   https://blog.csdn.net/liuchonge/article/details/70947995\r\n",
        "2.   https://github.com/mhjabreel/CharCnn_Keras\r\n",
        "\r\n",
        "论文：Character-level Convolutional Networks for Text Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0S2f_CZ0i48t"
      },
      "source": [
        "# 加载数据"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxS0BAwmiCa-"
      },
      "source": [
        "from keras.models import Sequential, load_model\r\n",
        "from keras.layers import Embedding, Dense, Conv1D, MaxPool1D, AlphaDropout, Flatten\r\n",
        "from keras.initializers import RandomNormal\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from keras.utils import to_categorical\r\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fg49eJyQiU8T"
      },
      "source": [
        "SEED = 7\r\n",
        "data_names = ['myspace', 'phpbb', 'rockyou']\r\n",
        "alphabet = \"abcdefghijklmnopqrstuvwxyz0123456789-;.!?:'\\\"/\\\\|_@#$%^&*~`+-=<>()[]{}\"\r\n",
        "alphabet_size = len(alphabet)\r\n",
        "length = 100\r\n",
        "no_of_classes = 3\r\n",
        "char_to_int = dict((c, i+1) for i, c in enumerate(alphabet))  # 索引0保留\r\n",
        "int_to_char = dict((i+1, c) for i, c in enumerate(alphabet))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCEciInNmo_F"
      },
      "source": [
        "# 加载数据\r\n",
        "import pandas as pd\r\n",
        "data_list = []\r\n",
        "for index, data_name in enumerate(data_names):\r\n",
        "    print('数据集名称：%s' % data_name)\r\n",
        "    file_name = '/content/' + data_name + '.txt'\r\n",
        "    for df_tmp in pd.read_csv(file_name, header=None, names=['pwd'], chunksize=5000000):\r\n",
        "        df_tmp['category'] = index\r\n",
        "        print('loading... %s' % df_tmp.shape[0])\r\n",
        "        data_list.append(df_tmp)\r\n",
        "data = pd.concat(data_list, ignore_index=True)\r\n",
        "\r\n",
        "print('对输入输出进行编码...')\r\n",
        "x = data['pwd'].apply(lambda s: [char_to_int[char] if char in alphabet else 0\r\n",
        "                                  for char in str(s).lower()])  # 对x进行编码\r\n",
        "x = pad_sequences(x, length, padding='post')\r\n",
        "y = to_categorical(data['category'], num_classes=no_of_classes, dtype='int32')\r\n",
        "print(\"x Shape: %s, y Shape: %s\" % (x.shape, y.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBLGE1iFislV"
      },
      "source": [
        "logger.info(\"划分训练集、验证集和测试集\")\r\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=SEED)\r\n",
        "x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=0.5, random_state=SEED)\r\n",
        "\r\n",
        "print(\"x_train Shape: %s, y_train Shape: %s\" % (x_train.shape, y_train.shape))\r\n",
        "print(\"x_val Shape: %s, y_val Shape: %s\" % (x_val.shape, y_val.shape))\r\n",
        "print(\"x_test Shape: %s, y_test Shape: %s\" % (x_test.shape, y_test.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlpQ6ECGjpxg"
      },
      "source": [
        "# 创建和训练模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvro-91JjzPt"
      },
      "source": [
        "# 超参数\r\n",
        "batch_size = 128\r\n",
        "epochs = 2\r\n",
        "conv_layers = [\r\n",
        "                  [256, 7, 3],\r\n",
        "                  [256, 7, 3],\r\n",
        "                  [256, 3, None],\r\n",
        "                  [256, 3, None],\r\n",
        "                  [256, 3, None],\r\n",
        "                  [256, 3, 3]\r\n",
        "              ]\r\n",
        "fully_layers = [1024, 1024]\r\n",
        "embedding_size = 50\r\n",
        "th = 1e-6\r\n",
        "dropout_p = 0.5\r\n",
        "optimizer = 'adam'\r\n",
        "initializer_stddev = 0.05\r\n",
        "loss = 'categorical_crossentropy'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTMz4IcXih9Y"
      },
      "source": [
        "print('创建CNN模型...')\r\n",
        "model = Sequential()\r\n",
        "# Embedding layers\r\n",
        "model.add(Embedding(input_dim=alphabet_size + 1, output_dim=embedding_size, input_length=length))\r\n",
        "# Convolution layers\r\n",
        "for num_filters, filter_width, pool_size in conv_layers:\r\n",
        "    model.add(Conv1D(filters=num_filters,\r\n",
        "                      kernel_size=filter_width,\r\n",
        "                      kernel_initializer=RandomNormal(mean=0, stddev=initializer_stddev),\r\n",
        "                      activation='tanh'))\r\n",
        "    if pool_size is not None:\r\n",
        "        model.add(MaxPool1D(pool_size))\r\n",
        "# Fully connected layers\r\n",
        "model.add(Flatten())\r\n",
        "for units in fully_layers:\r\n",
        "    model.add(Dense(units, activation='selu', kernel_initializer='lecun_normal'))\r\n",
        "    model.add(AlphaDropout(dropout_p))\r\n",
        "model.add(Dense(no_of_classes, activation='softmax'))\r\n",
        "\r\n",
        "# Build and compile model\r\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\r\n",
        "print('创建模型：\\n')\r\n",
        "model.summary()\r\n",
        "\r\n",
        "print('开始训练CNN模型')\r\n",
        "model.fit(x_train, y_train,\r\n",
        "          validation_data=(x_val, y_val),\r\n",
        "          epochs=epochs,\r\n",
        "          batch_size=batch_size,\r\n",
        "          verbose=1)\r\n",
        "loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\r\n",
        "print(\"Model Accuracy on test: %.2f%%, Loss: %.2f\" % (accuracy * 100, loss))\r\n",
        "model_file = './model/cnn.h5'\r\n",
        "print(\"保存模型：%s\" % model_file)\r\n",
        "model.save(model_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JR2FsK7ysn4i"
      },
      "source": [
        "# 其他命令"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6AFZTd_sqJY"
      },
      "source": [
        "!unzip '/content/raw_data.zip'"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}