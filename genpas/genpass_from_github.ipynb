{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "genpass from github.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyONNxIdfSUyko1N8cGA0m0X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YapingWu/GoogleColab/blob/main/genpas/genpass_from_github.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XG2uyd_S4tEf"
      },
      "source": [
        "# github代码复制到google colab\n",
        "\n",
        "参考资料：\n",
        "1. https://techsupportallbugs.wordpress.com/2018/06/05/using-git-with-colab-via-ssh/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKNtwhnL4zIX"
      },
      "source": [
        "## 配置SSH\n",
        "1. 上传压缩后的密钥对文件和配置文件\n",
        "1. 将密钥对文件和配置文件解压到/root/.ssh文件夹中\n",
        "2. 将私钥加载到本地ssh-agent中\n",
        "3. 设置git账户"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDBqGHhh9TV7",
        "outputId": "dd335556-e91e-43ce-ebb1-3189c6a5059d"
      },
      "source": [
        "!rm -rf ~/.ssh\n",
        "!unzip '/content/ssh-colab.zip' -d ~/.ssh\n",
        "!chmod 700 ~/.ssh\n",
        "\n",
        "# add the ssh server as a hnown host\n",
        "!touch ~/.ssh/known_hosts\n",
        "!ssh-keyscan github.com >> ~/.ssh/known_hosts\n",
        "!chmod 644 ~/.ssh/known_hosts"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/ssh-colab.zip\n",
            "  inflating: /root/.ssh/config       \n",
            "  inflating: /root/.ssh/id_rsa_colab  \n",
            "  inflating: /root/.ssh/id_rsa_colab.pub  \n",
            "# github.com:22 SSH-2.0-babeld-383743ad\n",
            "# github.com:22 SSH-2.0-babeld-383743ad\n",
            "# github.com:22 SSH-2.0-babeld-383743ad\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMTGwhmh_6Xj",
        "outputId": "ea4e5b89-00e5-4505-e102-813f4cee7e62"
      },
      "source": [
        "!ssh-agent /bin/bash \n",
        "\n",
        "# 以下命令在ssh-agent启动的shell中执行\n",
        "# chmod 600 ~/.ssh/id_rsa_colab  # 私钥需要设置仅自己可以访问，才能添加到代理\n",
        "# ssh-add ~/.ssh/id_rsa_colab\n",
        "# ssh-add -l"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bash: cannot set terminal process group (58): Inappropriate ioctl for device\n",
            "bash: no job control in this shell\n",
            "\u001b[01;34m/content\u001b[00m# chmod 600 ~/.ssh/id_rsa_colab\n",
            "\u001b[01;34m/content\u001b[00m# ssh-add ~/.ssh/id_rsa_colab\n",
            "Identity added: /root/.ssh/id_rsa_colab (/root/.ssh/id_rsa_colab)\n",
            "\u001b[01;34m/content\u001b[00m# exit\n",
            "exit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niqZxsQrDAz9"
      },
      "source": [
        "!git config --global user.name 'colab'\n",
        "!git config --global user.email 'vyapings@163.com'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1redRBlVDRVu"
      },
      "source": [
        "## clone私有库\n",
        "1. 安装google云盘\n",
        "2. 将工作目录更改为云端硬盘内的文件夹\n",
        "3. 运行git clone。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgmO9CHC-9M5",
        "outputId": "1fca2e8a-73d9-46b4-8f80-2a48ece4851c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('./drive')\n",
        "\n",
        "import os\n",
        "os.chdir('/content/drive/MyDrive')\n",
        "\n",
        "!pwd\n",
        "!ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at ./drive\n",
            "/content/drive/MyDrive\n",
            "'Colab Notebooks'   gen_pass\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTxxiKQvA-5p",
        "outputId": "ab851492-c540-4ec5-cfb9-61a7d470ab79"
      },
      "source": [
        "!rm -rf gen_pass\n",
        "!git clone git@github.com:YapingWu/gen_pass.git"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'gen_pass'...\n",
            "Warning: Permanently added the RSA host key for IP address '140.82.114.4' to the list of known hosts.\n",
            "remote: Enumerating objects: 192, done.\u001b[K\n",
            "remote: Counting objects: 100% (192/192), done.\u001b[K\n",
            "remote: Compressing objects: 100% (130/130), done.\u001b[K\n",
            "remote: Total 192 (delta 81), reused 169 (delta 58), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (192/192), 69.86 MiB | 14.57 MiB/s, done.\n",
            "Resolving deltas: 100% (81/81), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WecgaSNAD6uE"
      },
      "source": [
        "## 运行genpass项目"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3U3OWhSAEU3V"
      },
      "source": [
        "上传并解压原始密码数据集"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXGvSwK9D4pa",
        "outputId": "3f9b6f7a-d6da-4f23-8909-2238e9bf8d2a"
      },
      "source": [
        "!unzip '/content/dataset.zip' -d '/content/drive/MyDrive/gen_pass/dataset'"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/dataset.zip\n",
            "  inflating: /content/drive/MyDrive/gen_pass/dataset/phpbb.txt  \n",
            "  inflating: /content/drive/MyDrive/gen_pass/dataset/rockyou.txt  \n",
            "  inflating: /content/drive/MyDrive/gen_pass/dataset/myspace.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSeeKLLKEcMU",
        "outputId": "b43c268f-4bf8-4d39-fa0d-4593d7827c8b"
      },
      "source": [
        "import os\n",
        "print(os.getcwd())\n",
        "os.chdir('/content/drive/MyDrive/gen_pass')\n",
        "print(os.getcwd())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n",
            "/content/drive/MyDrive/gen_pass\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhVk3rhRtt8R"
      },
      "source": [
        "## 数据分析"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wz4USzDbFAYg",
        "outputId": "4e0f070e-4625-4724-a38b-6f7318655add"
      },
      "source": [
        "!python main.py \n",
        "  --stats-only \n",
        "  --infile dataset/phpbb.txt dataset/myspace.txt \n",
        "  --outpath figure/"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-03-24 05:30:03.489656: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[1;37m2021-03-24 05:30:05 [INFO] \n",
            "##########################################################################################################\n",
            "# GENPass\n",
            "# 1 PL模型预测。预测密码中的下一个单元（unit）。\n",
            "# 2 权重选择。按照权重选择从3个PL模型的结果中选择权重最高的unit，并根据wordlist随机选择一个密码进行替换。\n",
            "# 3 分类器。使用CNN模型预测上一步生成的密码属于3个数据集的概率。\n",
            "# 4 判定器。选择出在3个数据集概率相差不大的密码作为结果输出。\n",
            "#\n",
            "##########################################################################################################\n",
            "\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:30:05 [INFO] Start...\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:30:06 [INFO] dataset/phpbb.txt数据集中的密码数量：184379\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:30:06 [INFO] 密码长度不在[4, 20]区间的密码个数：1013，占总密码数量的百分比：0.55%\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:30:06 [INFO] dataset/myspace.txt数据集中的密码数量：37144\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:30:06 [INFO] 密码长度不在[4, 20]区间的密码个数：259，占总密码数量的百分比：0.70%\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:30:06 [INFO] 分析结果图保存到文件：figure/password.png\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:30:06 [INFO] End...\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIjqmF5_tyal"
      },
      "source": [
        "## 数据预处理"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYmyHJt2txki",
        "outputId": "cfffacdd-342c-411f-b4bc-39bf27a65843"
      },
      "source": [
        "!python main.py \\\n",
        "  --pre-processing-only \\\n",
        "  --infile dataset/phpbb.txt dataset/myspace.txt"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-03-24 05:31:36.772018: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[1;37m2021-03-24 05:31:38 [INFO] \n",
            "##########################################################################################################\n",
            "# GENPass\n",
            "# 1 PL模型预测。预测密码中的下一个单元（unit）。\n",
            "# 2 权重选择。按照权重选择从3个PL模型的结果中选择权重最高的unit，并根据wordlist随机选择一个密码进行替换。\n",
            "# 3 分类器。使用CNN模型预测上一步生成的密码属于3个数据集的概率。\n",
            "# 4 判定器。选择出在3个数据集概率相差不大的密码作为结果输出。\n",
            "#\n",
            "##########################################################################################################\n",
            "\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:31:38 [INFO] Start...\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:31:38 [INFO] 开始预处理\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:31:38 [INFO] 待处理的文件名称：dataset/phpbb.txt\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:31:38 [INFO] PCFG编码\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:31:39 [INFO] 去重后的编码序列个数：2873， 保存到文件：dataset/wordlist/phpbb.txt\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:31:39 [INFO] 生成两个概率表并保存到文件\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:31:39 [INFO] 每个unit出现的概率保存到文件：dataset/unit_freq/phpbb.txt\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:31:41 [INFO] unit中每个密码出现的概率保存到文件：dataset/pwd_freq/phpbb.txt\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:31:41 [INFO] 待处理的文件名称：dataset/myspace.txt\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:31:41 [INFO] PCFG编码\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:31:41 [INFO] 去重后的编码序列个数：1564， 保存到文件：dataset/wordlist/myspace.txt\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:31:41 [INFO] 生成两个概率表并保存到文件\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:31:41 [INFO] 每个unit出现的概率保存到文件：dataset/unit_freq/myspace.txt\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:31:41 [INFO] unit中每个密码出现的概率保存到文件：dataset/pwd_freq/myspace.txt\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:31:42 [INFO] 组合密码频率表，结果写入文件：dataset/pwd_freq/all.txt\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:31:43 [INFO] 原始密码集划分为测试集和训练集\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:31:43 [INFO] dataset/phpbb.txt：train shape：(147503, 1), test shape：(36876, 1)\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:31:43 [INFO] dataset/myspace.txt：train shape：(29715, 1), test shape：(7429, 1)\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:31:43 [INFO] 开始预处理\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:31:43 [INFO] 待处理的文件名称：dataset/pl/phpbb_part.txt\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:31:43 [INFO] PCFG编码\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:31:44 [INFO] 去重后的编码序列个数：1959， 保存到文件：dataset/pl/wordlist/phpbb_part.txt\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:31:44 [INFO] 生成两个概率表并保存到文件\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:31:44 [INFO] 每个unit出现的概率保存到文件：dataset/pl/unit_freq/phpbb_part.txt\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:31:45 [INFO] unit中每个密码出现的概率保存到文件：dataset/pl/pwd_freq/phpbb_part.txt\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:31:45 [INFO] 待处理的文件名称：dataset/pl/myspace_part.txt\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:31:45 [INFO] PCFG编码\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:31:45 [INFO] 去重后的编码序列个数：1064， 保存到文件：dataset/pl/wordlist/myspace_part.txt\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:31:45 [INFO] 生成两个概率表并保存到文件\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:31:45 [INFO] 每个unit出现的概率保存到文件：dataset/pl/unit_freq/myspace_part.txt\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:31:46 [INFO] unit中每个密码出现的概率保存到文件：dataset/pl/pwd_freq/myspace_part.txt\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:31:46 [INFO] 组合密码频率表，结果写入文件：dataset/pl/pwd_freq/all.txt\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:31:47 [INFO] End...\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXIMmvMduBct"
      },
      "source": [
        "## 训练word-level LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYlf7R2ruFUQ"
      },
      "source": [
        "### 训练分词器"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qdT20rOuBBA",
        "outputId": "df9d81b9-e7b9-48a4-9b5f-900c53a71a2d"
      },
      "source": [
        "!python main.py \\\n",
        "  --train --model tokenizer \\\n",
        "  --infile dataset/wordlist/phpbb.txt \\\n",
        "    dataset/wordlist/myspace.txt \\\n",
        "    dataset/pl/wordlist/myspace_part.txt \\\n",
        "    dataset/pl/wordlist/phpbb_part.txt \\\n",
        "  --outpath model/tokenizer"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-03-24 05:34:18.311610: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[1;37m2021-03-24 05:34:20 [INFO] \n",
            "##########################################################################################################\n",
            "# GENPass\n",
            "# 1 PL模型预测。预测密码中的下一个单元（unit）。\n",
            "# 2 权重选择。按照权重选择从3个PL模型的结果中选择权重最高的unit，并根据wordlist随机选择一个密码进行替换。\n",
            "# 3 分类器。使用CNN模型预测上一步生成的密码属于3个数据集的概率。\n",
            "# 4 判定器。选择出在3个数据集概率相差不大的密码作为结果输出。\n",
            "#\n",
            "##########################################################################################################\n",
            "\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:34:20 [INFO] Start...\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:34:20 [INFO] 加载编码后的密码数据，数据文件：dataset/wordlist/phpbb.txt\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:34:20 [INFO] 开始训练tokenizer模型\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:34:20 [INFO] 将tokenizer模型保存到文件中：model/tokenizer/phpbb.pkl\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:34:20 [INFO] 加载编码后的密码数据，数据文件：dataset/wordlist/myspace.txt\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:34:20 [INFO] 开始训练tokenizer模型\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:34:20 [INFO] 将tokenizer模型保存到文件中：model/tokenizer/myspace.pkl\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:34:20 [INFO] 加载编码后的密码数据，数据文件：dataset/pl/wordlist/myspace_part.txt\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:34:20 [INFO] 开始训练tokenizer模型\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:34:20 [INFO] 将tokenizer模型保存到文件中：model/tokenizer/myspace_part.pkl\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:34:20 [INFO] 加载编码后的密码数据，数据文件：dataset/pl/wordlist/phpbb_part.txt\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:34:20 [INFO] 开始训练tokenizer模型\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:34:20 [INFO] 将tokenizer模型保存到文件中：model/tokenizer/phpbb_part.pkl\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:34:20 [INFO] End...\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z38Jg6u7uvXt"
      },
      "source": [
        "### 使用pcfg编码结果训练LSTM模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilRlmgPIuupJ",
        "outputId": "68c22310-b0fb-429d-acb3-42f054b49d95"
      },
      "source": [
        "!python main.py \\\n",
        "  -e pro \\\n",
        "  --train \\\n",
        "  --model lstm \\\n",
        "  --infile dataset/wordlist/phpbb.txt \\\n",
        "    dataset/wordlist/myspace.txt \\\n",
        "    dataset/pl/wordlist/myspace_part.txt \\\n",
        "    dataset/pl/wordlist/phpbb_part.txt \\\n",
        "  --tokenizer model/tokenizer/phpbb.pkl \\\n",
        "    model/tokenizer/myspace.pkl \\\n",
        "    model/tokenizer/myspace_part.pkl \\\n",
        "    model/tokenizer/phpbb_part.pkl \\\n",
        "  --outpath model/lstm"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-03-24 05:37:01.813214: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[1;37m2021-03-24 05:37:05 [INFO] \n",
            "##########################################################################################################\n",
            "# GENPass\n",
            "# 1 PL模型预测。预测密码中的下一个单元（unit）。\n",
            "# 2 权重选择。按照权重选择从3个PL模型的结果中选择权重最高的unit，并根据wordlist随机选择一个密码进行替换。\n",
            "# 3 分类器。使用CNN模型预测上一步生成的密码属于3个数据集的概率。\n",
            "# 4 判定器。选择出在3个数据集概率相差不大的密码作为结果输出。\n",
            "#\n",
            "##########################################################################################################\n",
            "\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:37:05 [INFO] Start...\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:37:05 [INFO] 开始加载编码后的密码数据：dataset/wordlist/phpbb.txt\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:37:05 [INFO] 开始加载tokenizer模型：model/tokenizer/phpbb.pkl\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:37:05 [INFO] 将编码后的密码转换为（整数）序列\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:37:05 [INFO] Total Sequences: 15108\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:37:05 [INFO] 创建LSTM模型的输入输出\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:37:05 [INFO] X Shape: (15108, 19), y Shape: (15108,)\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:37:05 [INFO] 划分训练集、验证集和测试集\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:37:05 [INFO] x_train Shape: (9064, 19), y_train Shape: (9064, 54)\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:37:05 [INFO] x_val Shape: (3022, 19), y_val Shape: (3022, 54)\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:37:05 [INFO] x_test Shape: (3022, 19), y_test Shape: (3022, 54)\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:37:05 [INFO] *************************************************创建LSTM模型*************************************************\u001b[0m\n",
            "2021-03-24 05:37:05.799107: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2021-03-24 05:37:05.857945: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
            "2021-03-24 05:37:05.965312: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2021-03-24 05:37:05.965442: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (137a59ef31cc): /proc/driver/nvidia/version does not exist\n",
            "2021-03-24 05:37:05.966354: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 19, 10)            540       \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 19, 32)            5504      \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 19, 32)            8320      \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 32)                8320      \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 54)                1782      \n",
            "=================================================================\n",
            "Total params: 25,522\n",
            "Trainable params: 25,522\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\u001b[1;37m2021-03-24 05:37:07 [INFO] 训练日志文件：logs/lstm/phpbb210324053707\u001b[0m\n",
            "2021-03-24 05:37:07.550431: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.\n",
            "2021-03-24 05:37:07.550637: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.\n",
            "2021-03-24 05:37:07.563653: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.\n",
            "\u001b[1;37m2021-03-24 05:37:07 [INFO] ************************************************开始训练LSTM模型************************************************\u001b[0m\n",
            "2021-03-24 05:37:07.785381: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
            "2021-03-24 05:37:07.810754: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2299995000 Hz\n",
            "Epoch 1/500\n",
            " 1/71 [..............................] - ETA: 10:35 - loss: 3.9890 - accuracy: 0.0000e+002021-03-24 05:37:17.305682: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.\n",
            "2021-03-24 05:37:17.305771: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.\n",
            " 2/71 [..............................] - ETA: 26s - loss: 3.9880 - accuracy: 0.0605      2021-03-24 05:37:17.410918: I tensorflow/core/profiler/lib/profiler_session.cc:71] Profiler session collecting data.\n",
            "2021-03-24 05:37:17.480401: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.\n",
            "71/71 [==============================] - 15s 86ms/step - loss: 3.6101 - accuracy: 0.1660 - val_loss: 2.4942 - val_accuracy: 0.1621\n",
            "Epoch 2/500\n",
            "71/71 [==============================] - 3s 49ms/step - loss: 2.5226 - accuracy: 0.1738 - val_loss: 2.4457 - val_accuracy: 0.1985\n",
            "Epoch 3/500\n",
            "71/71 [==============================] - 3s 48ms/step - loss: 2.4806 - accuracy: 0.1781 - val_loss: 2.4408 - val_accuracy: 0.1985\n",
            "Epoch 4/500\n",
            "71/71 [==============================] - 3s 46ms/step - loss: 2.4747 - accuracy: 0.1759 - val_loss: 2.4396 - val_accuracy: 0.1621\n",
            "Epoch 5/500\n",
            "71/71 [==============================] - 3s 46ms/step - loss: 2.4754 - accuracy: 0.1783 - val_loss: 2.4347 - val_accuracy: 0.1985\n",
            "Epoch 6/500\n",
            "71/71 [==============================] - 3s 45ms/step - loss: 2.4864 - accuracy: 0.1876 - val_loss: 2.4361 - val_accuracy: 0.1985\n",
            "Epoch 7/500\n",
            "71/71 [==============================] - 3s 46ms/step - loss: 2.4692 - accuracy: 0.1753 - val_loss: 2.4384 - val_accuracy: 0.1985\n",
            "Epoch 8/500\n",
            "71/71 [==============================] - 3s 44ms/step - loss: 2.4938 - accuracy: 0.1789 - val_loss: 2.4371 - val_accuracy: 0.1985\n",
            "Epoch 9/500\n",
            "71/71 [==============================] - 3s 46ms/step - loss: 2.4604 - accuracy: 0.1804 - val_loss: 2.4365 - val_accuracy: 0.1985\n",
            "Epoch 10/500\n",
            "71/71 [==============================] - 3s 45ms/step - loss: 2.4659 - accuracy: 0.1859 - val_loss: 2.4332 - val_accuracy: 0.1985\n",
            "Epoch 11/500\n",
            "71/71 [==============================] - 3s 47ms/step - loss: 2.4678 - accuracy: 0.1849 - val_loss: 2.3694 - val_accuracy: 0.2631\n",
            "Epoch 12/500\n",
            "71/71 [==============================] - 3s 46ms/step - loss: 2.3932 - accuracy: 0.2551 - val_loss: 2.2454 - val_accuracy: 0.2965\n",
            "Epoch 13/500\n",
            "71/71 [==============================] - 3s 42ms/step - loss: 2.2883 - accuracy: 0.2819 - val_loss: 2.2136 - val_accuracy: 0.3048\n",
            "Epoch 14/500\n",
            "71/71 [==============================] - 3s 43ms/step - loss: 2.2582 - accuracy: 0.2977 - val_loss: 2.2196 - val_accuracy: 0.3011\n",
            "Epoch 15/500\n",
            "71/71 [==============================] - 3s 43ms/step - loss: 2.2432 - accuracy: 0.2981 - val_loss: 2.1923 - val_accuracy: 0.3071\n",
            "Epoch 16/500\n",
            "71/71 [==============================] - 3s 42ms/step - loss: 2.2368 - accuracy: 0.3020 - val_loss: 2.1920 - val_accuracy: 0.2995\n",
            "Epoch 17/500\n",
            "71/71 [==============================] - 3s 42ms/step - loss: 2.2270 - accuracy: 0.2938 - val_loss: 2.1880 - val_accuracy: 0.3084\n",
            "Epoch 18/500\n",
            "71/71 [==============================] - 3s 43ms/step - loss: 2.2322 - accuracy: 0.3038 - val_loss: 2.1833 - val_accuracy: 0.3071\n",
            "Epoch 19/500\n",
            "71/71 [==============================] - 3s 43ms/step - loss: 2.1987 - accuracy: 0.3156 - val_loss: 2.1773 - val_accuracy: 0.3034\n",
            "Epoch 20/500\n",
            "71/71 [==============================] - 3s 45ms/step - loss: 2.1991 - accuracy: 0.3091 - val_loss: 2.1800 - val_accuracy: 0.3087\n",
            "Epoch 21/500\n",
            "71/71 [==============================] - 3s 43ms/step - loss: 2.2093 - accuracy: 0.3131 - val_loss: 2.1710 - val_accuracy: 0.3266\n",
            "Epoch 22/500\n",
            "71/71 [==============================] - 3s 44ms/step - loss: 2.2000 - accuracy: 0.3259 - val_loss: 2.1703 - val_accuracy: 0.3256\n",
            "Epoch 23/500\n",
            "71/71 [==============================] - 3s 43ms/step - loss: 2.1686 - accuracy: 0.3295 - val_loss: 2.1726 - val_accuracy: 0.3276\n",
            "Epoch 24/500\n",
            "71/71 [==============================] - 3s 49ms/step - loss: 2.1658 - accuracy: 0.3484 - val_loss: 2.0795 - val_accuracy: 0.3911\n",
            "Epoch 25/500\n",
            "71/71 [==============================] - 3s 48ms/step - loss: 2.0700 - accuracy: 0.3830 - val_loss: 1.9618 - val_accuracy: 0.3934\n",
            "Epoch 26/500\n",
            "71/71 [==============================] - 3s 46ms/step - loss: 1.9709 - accuracy: 0.3987 - val_loss: 1.9228 - val_accuracy: 0.4040\n",
            "Epoch 27/500\n",
            "71/71 [==============================] - 3s 45ms/step - loss: 1.9325 - accuracy: 0.4007 - val_loss: 1.8945 - val_accuracy: 0.4116\n",
            "Epoch 28/500\n",
            "71/71 [==============================] - 3s 48ms/step - loss: 1.8839 - accuracy: 0.4189 - val_loss: 1.8889 - val_accuracy: 0.4080\n",
            "Epoch 29/500\n",
            "71/71 [==============================] - 4s 51ms/step - loss: 1.8929 - accuracy: 0.4094 - val_loss: 1.8736 - val_accuracy: 0.4103\n",
            "Epoch 30/500\n",
            "71/71 [==============================] - 4s 50ms/step - loss: 1.8790 - accuracy: 0.4121 - val_loss: 1.8767 - val_accuracy: 0.4146\n",
            "Epoch 31/500\n",
            "71/71 [==============================] - 4s 49ms/step - loss: 1.8849 - accuracy: 0.3984 - val_loss: 1.8715 - val_accuracy: 0.4146\n",
            "Epoch 32/500\n",
            "71/71 [==============================] - 3s 49ms/step - loss: 1.8831 - accuracy: 0.4059 - val_loss: 1.8720 - val_accuracy: 0.4120\n",
            "Epoch 33/500\n",
            "71/71 [==============================] - 4s 51ms/step - loss: 1.9012 - accuracy: 0.3989 - val_loss: 1.8789 - val_accuracy: 0.4047\n",
            "Epoch 34/500\n",
            "71/71 [==============================] - 3s 49ms/step - loss: 1.8662 - accuracy: 0.4114 - val_loss: 1.8657 - val_accuracy: 0.4113\n",
            "Epoch 35/500\n",
            "71/71 [==============================] - 4s 50ms/step - loss: 1.8565 - accuracy: 0.4076 - val_loss: 1.8669 - val_accuracy: 0.4146\n",
            "Epoch 36/500\n",
            "71/71 [==============================] - 4s 50ms/step - loss: 1.8664 - accuracy: 0.4059 - val_loss: 1.8642 - val_accuracy: 0.4087\n",
            "Epoch 37/500\n",
            "71/71 [==============================] - 3s 41ms/step - loss: 1.8686 - accuracy: 0.4120 - val_loss: 1.8603 - val_accuracy: 0.4093\n",
            "Epoch 38/500\n",
            "71/71 [==============================] - 3s 39ms/step - loss: 1.9023 - accuracy: 0.3987 - val_loss: 1.8655 - val_accuracy: 0.4097\n",
            "Epoch 39/500\n",
            "71/71 [==============================] - 3s 40ms/step - loss: 1.8788 - accuracy: 0.4040 - val_loss: 1.8597 - val_accuracy: 0.4077\n",
            "Epoch 40/500\n",
            "71/71 [==============================] - 3s 40ms/step - loss: 1.8735 - accuracy: 0.4043 - val_loss: 1.8729 - val_accuracy: 0.4034\n",
            "Epoch 41/500\n",
            "71/71 [==============================] - 3s 41ms/step - loss: 1.8686 - accuracy: 0.4059 - val_loss: 1.8722 - val_accuracy: 0.4083\n",
            "Epoch 42/500\n",
            "71/71 [==============================] - 3s 39ms/step - loss: 1.8769 - accuracy: 0.4069 - val_loss: 1.8580 - val_accuracy: 0.4080\n",
            "Epoch 43/500\n",
            "71/71 [==============================] - 3s 40ms/step - loss: 1.8652 - accuracy: 0.4106 - val_loss: 1.8593 - val_accuracy: 0.4070\n",
            "Epoch 44/500\n",
            "71/71 [==============================] - 3s 40ms/step - loss: 1.8609 - accuracy: 0.4062 - val_loss: 1.8573 - val_accuracy: 0.4136\n",
            "Epoch 45/500\n",
            "71/71 [==============================] - 3s 40ms/step - loss: 1.8539 - accuracy: 0.4127 - val_loss: 1.8557 - val_accuracy: 0.4136\n",
            "Epoch 46/500\n",
            "71/71 [==============================] - 3s 40ms/step - loss: 1.8662 - accuracy: 0.4036 - val_loss: 1.8546 - val_accuracy: 0.4150\n",
            "Epoch 47/500\n",
            "71/71 [==============================] - 3s 40ms/step - loss: 1.8363 - accuracy: 0.4154 - val_loss: 1.8549 - val_accuracy: 0.4110\n",
            "Epoch 48/500\n",
            "71/71 [==============================] - 3s 40ms/step - loss: 1.8356 - accuracy: 0.4160 - val_loss: 1.8510 - val_accuracy: 0.4120\n",
            "Epoch 49/500\n",
            "71/71 [==============================] - 3s 39ms/step - loss: 1.8456 - accuracy: 0.4111 - val_loss: 1.8546 - val_accuracy: 0.4073\n",
            "Epoch 50/500\n",
            "71/71 [==============================] - 3s 40ms/step - loss: 1.8314 - accuracy: 0.4217 - val_loss: 1.8519 - val_accuracy: 0.4140\n",
            "Epoch 51/500\n",
            "71/71 [==============================] - 3s 41ms/step - loss: 1.8650 - accuracy: 0.4053 - val_loss: 1.8495 - val_accuracy: 0.4083\n",
            "Epoch 52/500\n",
            "71/71 [==============================] - 3s 40ms/step - loss: 1.8280 - accuracy: 0.4139 - val_loss: 1.8561 - val_accuracy: 0.4120\n",
            "Epoch 53/500\n",
            "71/71 [==============================] - 3s 40ms/step - loss: 1.8657 - accuracy: 0.4079 - val_loss: 1.8460 - val_accuracy: 0.4150\n",
            "Epoch 54/500\n",
            "71/71 [==============================] - 3s 40ms/step - loss: 1.8406 - accuracy: 0.4182 - val_loss: 1.8429 - val_accuracy: 0.4136\n",
            "Epoch 55/500\n",
            "71/71 [==============================] - 3s 40ms/step - loss: 1.8337 - accuracy: 0.4109 - val_loss: 1.8419 - val_accuracy: 0.4140\n",
            "Epoch 56/500\n",
            "71/71 [==============================] - 3s 40ms/step - loss: 1.8401 - accuracy: 0.4115 - val_loss: 1.8469 - val_accuracy: 0.4113\n",
            "Epoch 57/500\n",
            "71/71 [==============================] - 3s 39ms/step - loss: 1.8402 - accuracy: 0.4138 - val_loss: 1.8410 - val_accuracy: 0.4126\n",
            "Epoch 58/500\n",
            "71/71 [==============================] - 3s 40ms/step - loss: 1.8193 - accuracy: 0.4158 - val_loss: 1.8387 - val_accuracy: 0.4093\n",
            "Epoch 59/500\n",
            "71/71 [==============================] - 3s 40ms/step - loss: 1.8204 - accuracy: 0.4130 - val_loss: 1.8419 - val_accuracy: 0.4083\n",
            "Epoch 60/500\n",
            "71/71 [==============================] - 3s 40ms/step - loss: 1.8459 - accuracy: 0.4067 - val_loss: 1.8398 - val_accuracy: 0.4113\n",
            "Epoch 61/500\n",
            "71/71 [==============================] - 3s 40ms/step - loss: 1.8301 - accuracy: 0.4114 - val_loss: 1.8329 - val_accuracy: 0.4103\n",
            "Epoch 62/500\n",
            "71/71 [==============================] - 3s 41ms/step - loss: 1.8152 - accuracy: 0.4153 - val_loss: 1.8362 - val_accuracy: 0.4116\n",
            "Epoch 63/500\n",
            "71/71 [==============================] - 3s 40ms/step - loss: 1.8092 - accuracy: 0.4226 - val_loss: 1.8277 - val_accuracy: 0.4130\n",
            "Epoch 64/500\n",
            "71/71 [==============================] - 3s 40ms/step - loss: 1.8407 - accuracy: 0.4115 - val_loss: 1.8354 - val_accuracy: 0.4140\n",
            "Epoch 65/500\n",
            "71/71 [==============================] - 3s 39ms/step - loss: 1.8278 - accuracy: 0.4047 - val_loss: 1.8265 - val_accuracy: 0.4113\n",
            "Epoch 66/500\n",
            "71/71 [==============================] - 3s 39ms/step - loss: 1.8213 - accuracy: 0.4116 - val_loss: 1.8246 - val_accuracy: 0.4130\n",
            "Epoch 67/500\n",
            "71/71 [==============================] - 3s 43ms/step - loss: 1.8088 - accuracy: 0.4147 - val_loss: 1.8245 - val_accuracy: 0.4173\n",
            "Epoch 68/500\n",
            "71/71 [==============================] - 3s 45ms/step - loss: 1.7937 - accuracy: 0.4226 - val_loss: 1.8264 - val_accuracy: 0.4169\n",
            "Epoch 69/500\n",
            "71/71 [==============================] - 3s 48ms/step - loss: 1.8112 - accuracy: 0.4181 - val_loss: 1.8232 - val_accuracy: 0.4130\n",
            "Epoch 70/500\n",
            "71/71 [==============================] - 3s 46ms/step - loss: 1.7929 - accuracy: 0.4159 - val_loss: 1.8221 - val_accuracy: 0.4133\n",
            "Epoch 71/500\n",
            "71/71 [==============================] - 3s 45ms/step - loss: 1.8183 - accuracy: 0.4096 - val_loss: 1.8219 - val_accuracy: 0.4150\n",
            "Epoch 72/500\n",
            "71/71 [==============================] - 3s 44ms/step - loss: 1.8100 - accuracy: 0.4152 - val_loss: 1.8284 - val_accuracy: 0.4156\n",
            "Epoch 73/500\n",
            "71/71 [==============================] - 3s 44ms/step - loss: 1.8159 - accuracy: 0.4084 - val_loss: 1.8279 - val_accuracy: 0.4153\n",
            "Epoch 74/500\n",
            "71/71 [==============================] - 3s 42ms/step - loss: 1.7986 - accuracy: 0.4160 - val_loss: 1.8166 - val_accuracy: 0.4159\n",
            "Epoch 75/500\n",
            "71/71 [==============================] - 3s 40ms/step - loss: 1.7949 - accuracy: 0.4135 - val_loss: 1.8277 - val_accuracy: 0.4146\n",
            "Epoch 76/500\n",
            "71/71 [==============================] - 3s 41ms/step - loss: 1.7954 - accuracy: 0.4116 - val_loss: 1.8292 - val_accuracy: 0.4103\n",
            "Epoch 77/500\n",
            "71/71 [==============================] - 3s 43ms/step - loss: 1.8024 - accuracy: 0.4114 - val_loss: 1.8184 - val_accuracy: 0.4120\n",
            "Epoch 78/500\n",
            "71/71 [==============================] - 3s 44ms/step - loss: 1.7992 - accuracy: 0.4161 - val_loss: 1.8188 - val_accuracy: 0.4173\n",
            "Epoch 79/500\n",
            "71/71 [==============================] - 3s 45ms/step - loss: 1.7785 - accuracy: 0.4236 - val_loss: 1.8207 - val_accuracy: 0.4179\n",
            "Epoch 80/500\n",
            "71/71 [==============================] - 3s 44ms/step - loss: 1.7898 - accuracy: 0.4174 - val_loss: 1.8092 - val_accuracy: 0.4159\n",
            "Epoch 81/500\n",
            "71/71 [==============================] - 3s 45ms/step - loss: 1.8025 - accuracy: 0.4156 - val_loss: 1.8147 - val_accuracy: 0.4133\n",
            "Epoch 82/500\n",
            "71/71 [==============================] - 3s 44ms/step - loss: 1.7913 - accuracy: 0.4252 - val_loss: 1.8122 - val_accuracy: 0.4186\n",
            "Epoch 83/500\n",
            "71/71 [==============================] - 3s 43ms/step - loss: 1.7838 - accuracy: 0.4198 - val_loss: 1.8149 - val_accuracy: 0.4169\n",
            "Epoch 84/500\n",
            "71/71 [==============================] - 3s 44ms/step - loss: 1.8190 - accuracy: 0.4026 - val_loss: 1.8270 - val_accuracy: 0.4070\n",
            "Epoch 85/500\n",
            "71/71 [==============================] - 3s 44ms/step - loss: 1.8042 - accuracy: 0.4166 - val_loss: 1.8131 - val_accuracy: 0.4126\n",
            "Epoch 86/500\n",
            "71/71 [==============================] - 3s 44ms/step - loss: 1.7821 - accuracy: 0.4243 - val_loss: 1.8110 - val_accuracy: 0.4169\n",
            "Epoch 87/500\n",
            "71/71 [==============================] - 3s 47ms/step - loss: 1.7886 - accuracy: 0.4171 - val_loss: 1.8145 - val_accuracy: 0.4140\n",
            "Epoch 88/500\n",
            "71/71 [==============================] - 3s 45ms/step - loss: 1.7957 - accuracy: 0.4159 - val_loss: 1.8111 - val_accuracy: 0.4169\n",
            "Epoch 89/500\n",
            "71/71 [==============================] - 3s 46ms/step - loss: 1.7836 - accuracy: 0.4186 - val_loss: 1.8141 - val_accuracy: 0.4173\n",
            "Epoch 90/500\n",
            "71/71 [==============================] - 3s 44ms/step - loss: 1.7900 - accuracy: 0.4157 - val_loss: 1.8133 - val_accuracy: 0.4140\n",
            "Epoch 91/500\n",
            "71/71 [==============================] - 3s 44ms/step - loss: 1.7857 - accuracy: 0.4135 - val_loss: 1.8162 - val_accuracy: 0.4156\n",
            "Epoch 92/500\n",
            "71/71 [==============================] - 3s 44ms/step - loss: 1.7675 - accuracy: 0.4256 - val_loss: 1.8097 - val_accuracy: 0.4150\n",
            "Epoch 93/500\n",
            "71/71 [==============================] - 3s 44ms/step - loss: 1.7728 - accuracy: 0.4248 - val_loss: 1.8135 - val_accuracy: 0.4166\n",
            "Epoch 94/500\n",
            "71/71 [==============================] - 3s 45ms/step - loss: 1.7800 - accuracy: 0.4196 - val_loss: 1.8123 - val_accuracy: 0.4110\n",
            "Epoch 95/500\n",
            "71/71 [==============================] - 3s 46ms/step - loss: 1.7731 - accuracy: 0.4139 - val_loss: 1.8155 - val_accuracy: 0.4140\n",
            "Epoch 96/500\n",
            "71/71 [==============================] - 3s 45ms/step - loss: 1.7878 - accuracy: 0.4194 - val_loss: 1.8152 - val_accuracy: 0.4136\n",
            "Epoch 97/500\n",
            "71/71 [==============================] - 3s 43ms/step - loss: 1.7979 - accuracy: 0.4161 - val_loss: 1.8129 - val_accuracy: 0.4183\n",
            "Epoch 98/500\n",
            "71/71 [==============================] - 3s 43ms/step - loss: 1.7745 - accuracy: 0.4208 - val_loss: 1.8237 - val_accuracy: 0.4093\n",
            "Epoch 99/500\n",
            "71/71 [==============================] - 3s 43ms/step - loss: 1.7806 - accuracy: 0.4130 - val_loss: 1.8157 - val_accuracy: 0.4113\n",
            "Epoch 100/500\n",
            "71/71 [==============================] - 3s 44ms/step - loss: 1.7911 - accuracy: 0.4184 - val_loss: 1.8150 - val_accuracy: 0.4146\n",
            "Epoch 101/500\n",
            "71/71 [==============================] - 3s 43ms/step - loss: 1.7792 - accuracy: 0.4176 - val_loss: 1.8133 - val_accuracy: 0.4156\n",
            "Epoch 102/500\n",
            "71/71 [==============================] - 3s 44ms/step - loss: 1.7886 - accuracy: 0.4113 - val_loss: 1.8139 - val_accuracy: 0.4176\n",
            "Epoch 103/500\n",
            "71/71 [==============================] - 3s 44ms/step - loss: 1.7750 - accuracy: 0.4223 - val_loss: 1.8126 - val_accuracy: 0.4126\n",
            "Epoch 104/500\n",
            "71/71 [==============================] - 3s 44ms/step - loss: 1.7910 - accuracy: 0.4099 - val_loss: 1.8144 - val_accuracy: 0.4173\n",
            "Epoch 105/500\n",
            "71/71 [==============================] - 3s 47ms/step - loss: 1.7711 - accuracy: 0.4189 - val_loss: 1.8147 - val_accuracy: 0.4130\n",
            "Epoch 106/500\n",
            "71/71 [==============================] - 3s 42ms/step - loss: 1.7717 - accuracy: 0.4215 - val_loss: 1.8212 - val_accuracy: 0.4060\n",
            "Epoch 107/500\n",
            "71/71 [==============================] - 3s 42ms/step - loss: 1.7675 - accuracy: 0.4242 - val_loss: 1.8178 - val_accuracy: 0.4143\n",
            "Epoch 108/500\n",
            "71/71 [==============================] - 3s 42ms/step - loss: 1.7658 - accuracy: 0.4202 - val_loss: 1.8166 - val_accuracy: 0.4146\n",
            "Epoch 109/500\n",
            "71/71 [==============================] - 3s 44ms/step - loss: 1.7647 - accuracy: 0.4250 - val_loss: 1.8137 - val_accuracy: 0.4153\n",
            "Epoch 110/500\n",
            "71/71 [==============================] - 3s 45ms/step - loss: 1.7899 - accuracy: 0.4126 - val_loss: 1.8121 - val_accuracy: 0.4179\n",
            "Epoch 111/500\n",
            "71/71 [==============================] - 3s 45ms/step - loss: 1.7477 - accuracy: 0.4270 - val_loss: 1.8222 - val_accuracy: 0.4080\n",
            "Epoch 112/500\n",
            "71/71 [==============================] - 3s 42ms/step - loss: 1.7749 - accuracy: 0.4218 - val_loss: 1.8129 - val_accuracy: 0.4159\n",
            "Epoch 113/500\n",
            "71/71 [==============================] - 3s 42ms/step - loss: 1.7731 - accuracy: 0.4162 - val_loss: 1.8152 - val_accuracy: 0.4110\n",
            "Epoch 114/500\n",
            "71/71 [==============================] - 3s 44ms/step - loss: 1.7704 - accuracy: 0.4234 - val_loss: 1.8211 - val_accuracy: 0.4146\n",
            "Epoch 115/500\n",
            "71/71 [==============================] - 3s 44ms/step - loss: 1.7710 - accuracy: 0.4179 - val_loss: 1.8183 - val_accuracy: 0.4103\n",
            "Epoch 116/500\n",
            "71/71 [==============================] - 3s 43ms/step - loss: 1.7639 - accuracy: 0.4214 - val_loss: 1.8175 - val_accuracy: 0.4169\n",
            "Epoch 117/500\n",
            "71/71 [==============================] - 3s 44ms/step - loss: 1.7695 - accuracy: 0.4236 - val_loss: 1.8209 - val_accuracy: 0.4146\n",
            "Epoch 118/500\n",
            "71/71 [==============================] - 3s 44ms/step - loss: 1.7780 - accuracy: 0.4228 - val_loss: 1.8168 - val_accuracy: 0.4143\n",
            "Epoch 119/500\n",
            "71/71 [==============================] - 3s 43ms/step - loss: 1.7509 - accuracy: 0.4293 - val_loss: 1.8227 - val_accuracy: 0.4126\n",
            "Epoch 120/500\n",
            "71/71 [==============================] - 3s 41ms/step - loss: 1.7913 - accuracy: 0.4224 - val_loss: 1.8177 - val_accuracy: 0.4116\n",
            "Epoch 121/500\n",
            "71/71 [==============================] - 3s 42ms/step - loss: 1.7677 - accuracy: 0.4239 - val_loss: 1.8176 - val_accuracy: 0.4163\n",
            "Epoch 122/500\n",
            "71/71 [==============================] - 3s 40ms/step - loss: 1.7838 - accuracy: 0.4102 - val_loss: 1.8171 - val_accuracy: 0.4120\n",
            "Epoch 123/500\n",
            "71/71 [==============================] - 3s 41ms/step - loss: 1.7909 - accuracy: 0.4141 - val_loss: 1.8200 - val_accuracy: 0.4159\n",
            "Epoch 124/500\n",
            "71/71 [==============================] - 3s 42ms/step - loss: 1.7957 - accuracy: 0.4038 - val_loss: 1.8191 - val_accuracy: 0.4176\n",
            "Epoch 125/500\n",
            "71/71 [==============================] - 3s 43ms/step - loss: 1.7681 - accuracy: 0.4149 - val_loss: 1.8250 - val_accuracy: 0.4040\n",
            "Epoch 126/500\n",
            "71/71 [==============================] - 3s 42ms/step - loss: 1.7663 - accuracy: 0.4179 - val_loss: 1.8157 - val_accuracy: 0.4150\n",
            "Epoch 127/500\n",
            "71/71 [==============================] - 3s 43ms/step - loss: 1.7497 - accuracy: 0.4282 - val_loss: 1.8184 - val_accuracy: 0.4159\n",
            "Epoch 128/500\n",
            "71/71 [==============================] - 3s 46ms/step - loss: 1.7673 - accuracy: 0.4235 - val_loss: 1.8157 - val_accuracy: 0.4136\n",
            "Epoch 129/500\n",
            "71/71 [==============================] - 3s 47ms/step - loss: 1.7472 - accuracy: 0.4317 - val_loss: 1.8228 - val_accuracy: 0.4054\n",
            "Epoch 130/500\n",
            "71/71 [==============================] - 3s 49ms/step - loss: 1.7608 - accuracy: 0.4299 - val_loss: 1.8169 - val_accuracy: 0.4156\n",
            "\u001b[1;37m2021-03-24 05:44:02 [INFO] Model Accuracy on test: 42.12%, Loss: 1.79\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:44:02 [INFO] 保存模型：model/lstm/phpbb.h5\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:44:03 [INFO] TensorBoard 日志：logs/lstm/phpbb210324053707\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:44:03 [INFO] ************************************************完成训练LSTM模型************************************************\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:44:03 [INFO] 开始加载编码后的密码数据：dataset/wordlist/myspace.txt\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:44:03 [INFO] 开始加载tokenizer模型：model/tokenizer/myspace.pkl\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:44:03 [INFO] 将编码后的密码转换为（整数）序列\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:44:03 [INFO] Total Sequences: 7586\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:44:03 [INFO] 创建LSTM模型的输入输出\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:44:03 [INFO] X Shape: (7586, 19), y Shape: (7586,)\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:44:03 [INFO] 划分训练集、验证集和测试集\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:44:03 [INFO] x_train Shape: (4551, 19), y_train Shape: (4551, 45)\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:44:03 [INFO] x_val Shape: (1517, 19), y_val Shape: (1517, 45)\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:44:03 [INFO] x_test Shape: (1518, 19), y_test Shape: (1518, 45)\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:44:03 [INFO] *************************************************创建LSTM模型*************************************************\u001b[0m\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 19, 10)            450       \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 19, 32)            5504      \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, 19, 32)            8320      \n",
            "_________________________________________________________________\n",
            "lstm_5 (LSTM)                (None, 32)                8320      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 45)                1485      \n",
            "=================================================================\n",
            "Total params: 25,135\n",
            "Trainable params: 25,135\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\u001b[1;37m2021-03-24 05:44:04 [INFO] 训练日志文件：logs/lstm/myspace210324054404\u001b[0m\n",
            "2021-03-24 05:44:04.053861: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.\n",
            "2021-03-24 05:44:04.053925: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.\n",
            "2021-03-24 05:44:04.053983: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.\n",
            "\u001b[1;37m2021-03-24 05:44:04 [INFO] ************************************************开始训练LSTM模型************************************************\u001b[0m\n",
            "Epoch 1/500\n",
            " 1/36 [..............................] - ETA: 3:13 - loss: 3.8078 - accuracy: 0.0000e+002021-03-24 05:44:09.837494: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.\n",
            "2021-03-24 05:44:09.837566: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.\n",
            " 2/36 [>.............................] - ETA: 8s - loss: 3.8071 - accuracy: 0.0098      2021-03-24 05:44:10.112832: I tensorflow/core/profiler/lib/profiler_session.cc:71] Profiler session collecting data.\n",
            "2021-03-24 05:44:10.152053: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.\n",
            "36/36 [==============================] - 9s 98ms/step - loss: 3.7129 - accuracy: 0.1584 - val_loss: 2.8959 - val_accuracy: 0.2327\n",
            "Epoch 2/500\n",
            "36/36 [==============================] - 2s 46ms/step - loss: 2.8372 - accuracy: 0.1810 - val_loss: 2.5959 - val_accuracy: 0.2327\n",
            "Epoch 3/500\n",
            "36/36 [==============================] - 2s 45ms/step - loss: 2.6439 - accuracy: 0.2060 - val_loss: 2.5568 - val_accuracy: 0.2327\n",
            "Epoch 4/500\n",
            "36/36 [==============================] - 2s 45ms/step - loss: 2.6073 - accuracy: 0.2110 - val_loss: 2.5511 - val_accuracy: 0.2327\n",
            "Epoch 5/500\n",
            "36/36 [==============================] - 2s 44ms/step - loss: 2.6217 - accuracy: 0.2070 - val_loss: 2.5577 - val_accuracy: 0.2327\n",
            "Epoch 6/500\n",
            "36/36 [==============================] - 2s 46ms/step - loss: 2.6165 - accuracy: 0.2010 - val_loss: 2.5550 - val_accuracy: 0.2327\n",
            "Epoch 7/500\n",
            "36/36 [==============================] - 2s 48ms/step - loss: 2.6259 - accuracy: 0.2074 - val_loss: 2.5530 - val_accuracy: 0.2327\n",
            "Epoch 8/500\n",
            "36/36 [==============================] - 2s 48ms/step - loss: 2.6049 - accuracy: 0.2033 - val_loss: 2.5504 - val_accuracy: 0.2327\n",
            "Epoch 9/500\n",
            "36/36 [==============================] - 2s 43ms/step - loss: 2.5978 - accuracy: 0.2044 - val_loss: 2.5477 - val_accuracy: 0.2327\n",
            "Epoch 10/500\n",
            "36/36 [==============================] - 2s 45ms/step - loss: 2.6054 - accuracy: 0.2063 - val_loss: 2.5525 - val_accuracy: 0.2327\n",
            "Epoch 11/500\n",
            "36/36 [==============================] - 2s 48ms/step - loss: 2.5925 - accuracy: 0.2033 - val_loss: 2.5498 - val_accuracy: 0.2327\n",
            "Epoch 12/500\n",
            "36/36 [==============================] - 2s 48ms/step - loss: 2.6279 - accuracy: 0.2053 - val_loss: 2.5484 - val_accuracy: 0.2327\n",
            "Epoch 13/500\n",
            "36/36 [==============================] - 2s 44ms/step - loss: 2.6257 - accuracy: 0.1969 - val_loss: 2.5524 - val_accuracy: 0.2327\n",
            "Epoch 14/500\n",
            "36/36 [==============================] - 2s 46ms/step - loss: 2.6057 - accuracy: 0.2019 - val_loss: 2.5553 - val_accuracy: 0.2327\n",
            "Epoch 15/500\n",
            "36/36 [==============================] - 2s 47ms/step - loss: 2.6158 - accuracy: 0.1983 - val_loss: 2.5562 - val_accuracy: 0.2327\n",
            "Epoch 16/500\n",
            "36/36 [==============================] - 2s 42ms/step - loss: 2.5779 - accuracy: 0.2073 - val_loss: 2.5535 - val_accuracy: 0.2327\n",
            "Epoch 17/500\n",
            "36/36 [==============================] - 2s 42ms/step - loss: 2.6127 - accuracy: 0.2024 - val_loss: 2.5521 - val_accuracy: 0.2327\n",
            "Epoch 18/500\n",
            "36/36 [==============================] - 2s 43ms/step - loss: 2.5993 - accuracy: 0.2017 - val_loss: 2.5547 - val_accuracy: 0.2327\n",
            "Epoch 19/500\n",
            "36/36 [==============================] - 2s 43ms/step - loss: 2.5992 - accuracy: 0.2108 - val_loss: 2.5472 - val_accuracy: 0.2327\n",
            "Epoch 20/500\n",
            "36/36 [==============================] - 1s 41ms/step - loss: 2.5813 - accuracy: 0.2078 - val_loss: 2.5338 - val_accuracy: 0.2327\n",
            "Epoch 21/500\n",
            "36/36 [==============================] - 2s 48ms/step - loss: 2.5396 - accuracy: 0.2106 - val_loss: 2.4070 - val_accuracy: 0.2927\n",
            "Epoch 22/500\n",
            "36/36 [==============================] - 2s 44ms/step - loss: 2.4527 - accuracy: 0.2588 - val_loss: 2.3623 - val_accuracy: 0.2940\n",
            "Epoch 23/500\n",
            "36/36 [==============================] - 2s 43ms/step - loss: 2.4093 - accuracy: 0.2700 - val_loss: 2.3285 - val_accuracy: 0.2960\n",
            "Epoch 24/500\n",
            "36/36 [==============================] - 2s 45ms/step - loss: 2.4081 - accuracy: 0.2755 - val_loss: 2.3068 - val_accuracy: 0.2993\n",
            "Epoch 25/500\n",
            "36/36 [==============================] - 2s 46ms/step - loss: 2.3961 - accuracy: 0.2804 - val_loss: 2.2991 - val_accuracy: 0.3263\n",
            "Epoch 26/500\n",
            "36/36 [==============================] - 2s 54ms/step - loss: 2.3453 - accuracy: 0.2949 - val_loss: 2.2807 - val_accuracy: 0.3065\n",
            "Epoch 27/500\n",
            "36/36 [==============================] - 2s 52ms/step - loss: 2.3289 - accuracy: 0.2872 - val_loss: 2.2640 - val_accuracy: 0.3210\n",
            "Epoch 28/500\n",
            "36/36 [==============================] - 2s 45ms/step - loss: 2.3545 - accuracy: 0.2885 - val_loss: 2.2552 - val_accuracy: 0.3191\n",
            "Epoch 29/500\n",
            "36/36 [==============================] - 2s 43ms/step - loss: 2.3375 - accuracy: 0.2969 - val_loss: 2.2555 - val_accuracy: 0.3092\n",
            "Epoch 30/500\n",
            "36/36 [==============================] - 2s 46ms/step - loss: 2.3120 - accuracy: 0.2989 - val_loss: 2.2700 - val_accuracy: 0.3415\n",
            "Epoch 31/500\n",
            "36/36 [==============================] - 2s 43ms/step - loss: 2.2847 - accuracy: 0.3113 - val_loss: 2.2251 - val_accuracy: 0.3553\n",
            "Epoch 32/500\n",
            "36/36 [==============================] - 2s 43ms/step - loss: 2.2209 - accuracy: 0.3324 - val_loss: 2.1799 - val_accuracy: 0.3428\n",
            "Epoch 33/500\n",
            "36/36 [==============================] - 2s 44ms/step - loss: 2.1502 - accuracy: 0.3407 - val_loss: 2.1055 - val_accuracy: 0.3698\n",
            "Epoch 34/500\n",
            "36/36 [==============================] - 2s 43ms/step - loss: 2.0965 - accuracy: 0.3419 - val_loss: 2.0862 - val_accuracy: 0.3731\n",
            "Epoch 35/500\n",
            "36/36 [==============================] - 1s 41ms/step - loss: 2.0998 - accuracy: 0.3263 - val_loss: 2.0610 - val_accuracy: 0.3724\n",
            "Epoch 36/500\n",
            "36/36 [==============================] - 2s 43ms/step - loss: 2.1172 - accuracy: 0.3306 - val_loss: 2.0524 - val_accuracy: 0.3665\n",
            "Epoch 37/500\n",
            "36/36 [==============================] - 2s 46ms/step - loss: 2.0633 - accuracy: 0.3383 - val_loss: 2.0363 - val_accuracy: 0.3751\n",
            "Epoch 38/500\n",
            "36/36 [==============================] - 2s 48ms/step - loss: 2.0761 - accuracy: 0.3422 - val_loss: 2.0336 - val_accuracy: 0.3698\n",
            "Epoch 39/500\n",
            "36/36 [==============================] - 2s 43ms/step - loss: 2.0638 - accuracy: 0.3478 - val_loss: 2.0210 - val_accuracy: 0.3790\n",
            "Epoch 40/500\n",
            "36/36 [==============================] - 2s 44ms/step - loss: 2.0494 - accuracy: 0.3466 - val_loss: 2.0182 - val_accuracy: 0.3698\n",
            "Epoch 41/500\n",
            "36/36 [==============================] - 2s 44ms/step - loss: 2.0289 - accuracy: 0.3547 - val_loss: 2.0029 - val_accuracy: 0.3764\n",
            "Epoch 42/500\n",
            "36/36 [==============================] - 2s 45ms/step - loss: 2.0100 - accuracy: 0.3487 - val_loss: 2.0038 - val_accuracy: 0.3764\n",
            "Epoch 43/500\n",
            "36/36 [==============================] - 2s 43ms/step - loss: 2.0142 - accuracy: 0.3530 - val_loss: 2.0061 - val_accuracy: 0.3764\n",
            "Epoch 44/500\n",
            "36/36 [==============================] - 2s 44ms/step - loss: 2.0141 - accuracy: 0.3505 - val_loss: 1.9962 - val_accuracy: 0.3685\n",
            "Epoch 45/500\n",
            "36/36 [==============================] - 2s 43ms/step - loss: 2.0325 - accuracy: 0.3414 - val_loss: 1.9984 - val_accuracy: 0.3744\n",
            "Epoch 46/500\n",
            "36/36 [==============================] - 1s 42ms/step - loss: 1.9883 - accuracy: 0.3547 - val_loss: 1.9913 - val_accuracy: 0.3731\n",
            "Epoch 47/500\n",
            "36/36 [==============================] - 2s 46ms/step - loss: 1.9890 - accuracy: 0.3638 - val_loss: 1.9914 - val_accuracy: 0.3790\n",
            "Epoch 48/500\n",
            "36/36 [==============================] - 2s 45ms/step - loss: 1.9905 - accuracy: 0.3572 - val_loss: 1.9968 - val_accuracy: 0.3764\n",
            "Epoch 49/500\n",
            "36/36 [==============================] - 2s 43ms/step - loss: 1.9671 - accuracy: 0.3595 - val_loss: 1.9932 - val_accuracy: 0.3757\n",
            "Epoch 50/500\n",
            "36/36 [==============================] - 2s 42ms/step - loss: 2.0200 - accuracy: 0.3514 - val_loss: 1.9878 - val_accuracy: 0.3738\n",
            "Epoch 51/500\n",
            "36/36 [==============================] - 1s 41ms/step - loss: 1.9887 - accuracy: 0.3707 - val_loss: 1.9915 - val_accuracy: 0.3804\n",
            "Epoch 52/500\n",
            "36/36 [==============================] - 2s 44ms/step - loss: 1.9737 - accuracy: 0.3725 - val_loss: 1.9979 - val_accuracy: 0.3797\n",
            "Epoch 53/500\n",
            "36/36 [==============================] - 2s 47ms/step - loss: 1.9405 - accuracy: 0.3736 - val_loss: 2.0031 - val_accuracy: 0.3685\n",
            "Epoch 54/500\n",
            "36/36 [==============================] - 2s 43ms/step - loss: 1.9845 - accuracy: 0.3716 - val_loss: 1.9919 - val_accuracy: 0.3665\n",
            "Epoch 55/500\n",
            "36/36 [==============================] - 2s 43ms/step - loss: 1.9942 - accuracy: 0.3535 - val_loss: 1.9928 - val_accuracy: 0.3764\n",
            "Epoch 56/500\n",
            "36/36 [==============================] - 2s 44ms/step - loss: 1.9722 - accuracy: 0.3598 - val_loss: 1.9885 - val_accuracy: 0.3751\n",
            "Epoch 57/500\n",
            "36/36 [==============================] - 2s 47ms/step - loss: 1.9954 - accuracy: 0.3508 - val_loss: 1.9989 - val_accuracy: 0.3672\n",
            "Epoch 58/500\n",
            "36/36 [==============================] - 2s 47ms/step - loss: 1.9709 - accuracy: 0.3544 - val_loss: 1.9812 - val_accuracy: 0.3764\n",
            "Epoch 59/500\n",
            "36/36 [==============================] - 2s 46ms/step - loss: 1.9677 - accuracy: 0.3636 - val_loss: 1.9987 - val_accuracy: 0.3665\n",
            "Epoch 60/500\n",
            "36/36 [==============================] - 2s 48ms/step - loss: 1.9747 - accuracy: 0.3609 - val_loss: 1.9800 - val_accuracy: 0.3744\n",
            "Epoch 61/500\n",
            "36/36 [==============================] - 2s 46ms/step - loss: 1.9681 - accuracy: 0.3603 - val_loss: 1.9802 - val_accuracy: 0.3731\n",
            "Epoch 62/500\n",
            "36/36 [==============================] - 2s 48ms/step - loss: 1.9707 - accuracy: 0.3601 - val_loss: 1.9930 - val_accuracy: 0.3691\n",
            "Epoch 63/500\n",
            "36/36 [==============================] - 2s 47ms/step - loss: 1.9881 - accuracy: 0.3515 - val_loss: 2.0312 - val_accuracy: 0.3685\n",
            "Epoch 64/500\n",
            "36/36 [==============================] - 2s 47ms/step - loss: 1.9860 - accuracy: 0.3673 - val_loss: 1.9858 - val_accuracy: 0.3804\n",
            "Epoch 65/500\n",
            "36/36 [==============================] - 2s 47ms/step - loss: 2.0086 - accuracy: 0.3624 - val_loss: 1.9820 - val_accuracy: 0.3777\n",
            "Epoch 66/500\n",
            "36/36 [==============================] - 2s 45ms/step - loss: 1.9803 - accuracy: 0.3563 - val_loss: 1.9944 - val_accuracy: 0.3724\n",
            "Epoch 67/500\n",
            "36/36 [==============================] - 2s 45ms/step - loss: 1.9625 - accuracy: 0.3681 - val_loss: 1.9877 - val_accuracy: 0.3823\n",
            "Epoch 68/500\n",
            "36/36 [==============================] - 2s 48ms/step - loss: 1.9877 - accuracy: 0.3586 - val_loss: 1.9845 - val_accuracy: 0.3757\n",
            "Epoch 69/500\n",
            "36/36 [==============================] - 2s 48ms/step - loss: 1.9328 - accuracy: 0.3901 - val_loss: 1.9943 - val_accuracy: 0.3738\n",
            "Epoch 70/500\n",
            "36/36 [==============================] - 2s 46ms/step - loss: 1.9683 - accuracy: 0.3684 - val_loss: 1.9802 - val_accuracy: 0.3817\n",
            "Epoch 71/500\n",
            "36/36 [==============================] - 2s 47ms/step - loss: 1.9704 - accuracy: 0.3626 - val_loss: 1.9815 - val_accuracy: 0.3771\n",
            "Epoch 72/500\n",
            "36/36 [==============================] - 2s 48ms/step - loss: 1.9690 - accuracy: 0.3631 - val_loss: 1.9817 - val_accuracy: 0.3738\n",
            "Epoch 73/500\n",
            "36/36 [==============================] - 2s 45ms/step - loss: 1.9769 - accuracy: 0.3612 - val_loss: 1.9872 - val_accuracy: 0.3705\n",
            "Epoch 74/500\n",
            "36/36 [==============================] - 2s 45ms/step - loss: 1.9906 - accuracy: 0.3587 - val_loss: 1.9992 - val_accuracy: 0.3777\n",
            "Epoch 75/500\n",
            "36/36 [==============================] - 2s 45ms/step - loss: 1.9646 - accuracy: 0.3716 - val_loss: 1.9981 - val_accuracy: 0.3738\n",
            "Epoch 76/500\n",
            "36/36 [==============================] - 2s 47ms/step - loss: 1.9606 - accuracy: 0.3722 - val_loss: 1.9907 - val_accuracy: 0.3691\n",
            "Epoch 77/500\n",
            "36/36 [==============================] - 2s 46ms/step - loss: 1.9696 - accuracy: 0.3666 - val_loss: 1.9852 - val_accuracy: 0.3784\n",
            "Epoch 78/500\n",
            "36/36 [==============================] - 2s 48ms/step - loss: 1.9656 - accuracy: 0.3673 - val_loss: 1.9938 - val_accuracy: 0.3757\n",
            "Epoch 79/500\n",
            "36/36 [==============================] - 2s 49ms/step - loss: 1.9249 - accuracy: 0.3715 - val_loss: 1.9813 - val_accuracy: 0.3757\n",
            "Epoch 80/500\n",
            "36/36 [==============================] - 2s 48ms/step - loss: 1.9315 - accuracy: 0.3805 - val_loss: 1.9882 - val_accuracy: 0.3823\n",
            "Epoch 81/500\n",
            "36/36 [==============================] - 2s 45ms/step - loss: 1.9467 - accuracy: 0.3704 - val_loss: 1.9835 - val_accuracy: 0.3777\n",
            "Epoch 82/500\n",
            "36/36 [==============================] - 2s 48ms/step - loss: 1.9340 - accuracy: 0.3722 - val_loss: 1.9898 - val_accuracy: 0.3784\n",
            "Epoch 83/500\n",
            "36/36 [==============================] - 2s 49ms/step - loss: 1.9516 - accuracy: 0.3727 - val_loss: 1.9890 - val_accuracy: 0.3764\n",
            "Epoch 84/500\n",
            "36/36 [==============================] - 2s 47ms/step - loss: 1.9730 - accuracy: 0.3590 - val_loss: 1.9862 - val_accuracy: 0.3797\n",
            "Epoch 85/500\n",
            "36/36 [==============================] - 2s 44ms/step - loss: 1.9779 - accuracy: 0.3643 - val_loss: 1.9967 - val_accuracy: 0.3757\n",
            "Epoch 86/500\n",
            "36/36 [==============================] - 2s 44ms/step - loss: 1.9690 - accuracy: 0.3630 - val_loss: 1.9880 - val_accuracy: 0.3724\n",
            "Epoch 87/500\n",
            "36/36 [==============================] - 2s 43ms/step - loss: 1.9886 - accuracy: 0.3579 - val_loss: 1.9793 - val_accuracy: 0.3856\n",
            "Epoch 88/500\n",
            "36/36 [==============================] - 2s 47ms/step - loss: 1.9576 - accuracy: 0.3781 - val_loss: 1.9852 - val_accuracy: 0.3889\n",
            "Epoch 89/500\n",
            "36/36 [==============================] - 2s 47ms/step - loss: 1.9499 - accuracy: 0.3771 - val_loss: 1.9829 - val_accuracy: 0.3843\n",
            "Epoch 90/500\n",
            "36/36 [==============================] - 2s 47ms/step - loss: 1.9459 - accuracy: 0.3817 - val_loss: 1.9915 - val_accuracy: 0.3843\n",
            "Epoch 91/500\n",
            "36/36 [==============================] - 2s 46ms/step - loss: 1.9516 - accuracy: 0.3750 - val_loss: 1.9869 - val_accuracy: 0.3837\n",
            "Epoch 92/500\n",
            "36/36 [==============================] - 2s 45ms/step - loss: 1.9692 - accuracy: 0.3653 - val_loss: 1.9847 - val_accuracy: 0.3843\n",
            "Epoch 93/500\n",
            "36/36 [==============================] - 2s 46ms/step - loss: 1.9460 - accuracy: 0.3757 - val_loss: 1.9825 - val_accuracy: 0.3883\n",
            "Epoch 94/500\n",
            "36/36 [==============================] - 2s 46ms/step - loss: 1.9524 - accuracy: 0.3695 - val_loss: 1.9850 - val_accuracy: 0.3909\n",
            "Epoch 95/500\n",
            "36/36 [==============================] - 2s 45ms/step - loss: 1.9009 - accuracy: 0.3875 - val_loss: 1.9756 - val_accuracy: 0.3843\n",
            "Epoch 96/500\n",
            "36/36 [==============================] - 2s 48ms/step - loss: 1.9607 - accuracy: 0.3700 - val_loss: 2.0042 - val_accuracy: 0.3744\n",
            "Epoch 97/500\n",
            "36/36 [==============================] - 2s 48ms/step - loss: 1.9452 - accuracy: 0.3818 - val_loss: 1.9714 - val_accuracy: 0.3869\n",
            "Epoch 98/500\n",
            "36/36 [==============================] - 2s 49ms/step - loss: 1.9053 - accuracy: 0.3886 - val_loss: 1.9673 - val_accuracy: 0.3935\n",
            "Epoch 99/500\n",
            "36/36 [==============================] - 2s 50ms/step - loss: 1.8885 - accuracy: 0.3966 - val_loss: 1.9633 - val_accuracy: 0.3922\n",
            "Epoch 100/500\n",
            "36/36 [==============================] - 2s 50ms/step - loss: 1.9191 - accuracy: 0.3855 - val_loss: 1.9810 - val_accuracy: 0.3837\n",
            "Epoch 101/500\n",
            "36/36 [==============================] - 2s 49ms/step - loss: 1.9273 - accuracy: 0.3820 - val_loss: 1.9630 - val_accuracy: 0.3916\n",
            "Epoch 102/500\n",
            "36/36 [==============================] - 2s 48ms/step - loss: 1.9306 - accuracy: 0.3918 - val_loss: 1.9622 - val_accuracy: 0.3955\n",
            "Epoch 103/500\n",
            "36/36 [==============================] - 2s 50ms/step - loss: 1.8958 - accuracy: 0.3949 - val_loss: 1.9685 - val_accuracy: 0.3896\n",
            "Epoch 104/500\n",
            "36/36 [==============================] - 2s 49ms/step - loss: 1.8784 - accuracy: 0.3955 - val_loss: 1.9616 - val_accuracy: 0.3856\n",
            "Epoch 105/500\n",
            "36/36 [==============================] - 2s 51ms/step - loss: 1.8989 - accuracy: 0.3944 - val_loss: 1.9584 - val_accuracy: 0.3955\n",
            "Epoch 106/500\n",
            "36/36 [==============================] - 2s 50ms/step - loss: 1.8711 - accuracy: 0.3925 - val_loss: 1.9518 - val_accuracy: 0.3929\n",
            "Epoch 107/500\n",
            "36/36 [==============================] - 2s 50ms/step - loss: 1.8957 - accuracy: 0.3887 - val_loss: 1.9586 - val_accuracy: 0.3955\n",
            "Epoch 108/500\n",
            "36/36 [==============================] - 2s 49ms/step - loss: 1.8800 - accuracy: 0.4035 - val_loss: 1.9524 - val_accuracy: 0.3949\n",
            "Epoch 109/500\n",
            "36/36 [==============================] - 2s 47ms/step - loss: 1.8728 - accuracy: 0.4017 - val_loss: 1.9555 - val_accuracy: 0.4001\n",
            "Epoch 110/500\n",
            "36/36 [==============================] - 2s 48ms/step - loss: 1.8914 - accuracy: 0.3985 - val_loss: 1.9677 - val_accuracy: 0.3863\n",
            "Epoch 111/500\n",
            "36/36 [==============================] - 2s 48ms/step - loss: 1.8547 - accuracy: 0.4035 - val_loss: 1.9527 - val_accuracy: 0.3922\n",
            "Epoch 112/500\n",
            "36/36 [==============================] - 2s 56ms/step - loss: 1.8783 - accuracy: 0.3984 - val_loss: 1.9487 - val_accuracy: 0.3975\n",
            "Epoch 113/500\n",
            "36/36 [==============================] - 2s 57ms/step - loss: 1.8844 - accuracy: 0.3923 - val_loss: 1.9573 - val_accuracy: 0.3922\n",
            "Epoch 114/500\n",
            "36/36 [==============================] - 2s 56ms/step - loss: 1.8932 - accuracy: 0.3861 - val_loss: 1.9528 - val_accuracy: 0.4008\n",
            "Epoch 115/500\n",
            "36/36 [==============================] - 2s 55ms/step - loss: 1.8422 - accuracy: 0.4108 - val_loss: 1.9540 - val_accuracy: 0.3962\n",
            "Epoch 116/500\n",
            "36/36 [==============================] - 2s 54ms/step - loss: 1.8756 - accuracy: 0.3967 - val_loss: 1.9672 - val_accuracy: 0.3869\n",
            "Epoch 117/500\n",
            "36/36 [==============================] - 2s 61ms/step - loss: 1.8805 - accuracy: 0.3989 - val_loss: 1.9669 - val_accuracy: 0.3784\n",
            "Epoch 118/500\n",
            "36/36 [==============================] - 2s 63ms/step - loss: 1.8947 - accuracy: 0.3986 - val_loss: 1.9534 - val_accuracy: 0.3889\n",
            "Epoch 119/500\n",
            "36/36 [==============================] - 2s 60ms/step - loss: 1.8566 - accuracy: 0.4051 - val_loss: 1.9498 - val_accuracy: 0.3922\n",
            "Epoch 120/500\n",
            "36/36 [==============================] - 2s 60ms/step - loss: 1.8684 - accuracy: 0.3952 - val_loss: 1.9470 - val_accuracy: 0.3995\n",
            "Epoch 121/500\n",
            "36/36 [==============================] - 2s 48ms/step - loss: 1.8904 - accuracy: 0.3951 - val_loss: 1.9617 - val_accuracy: 0.3856\n",
            "Epoch 122/500\n",
            "36/36 [==============================] - 2s 43ms/step - loss: 1.8844 - accuracy: 0.3985 - val_loss: 1.9476 - val_accuracy: 0.3949\n",
            "Epoch 123/500\n",
            "36/36 [==============================] - 2s 44ms/step - loss: 1.8598 - accuracy: 0.4033 - val_loss: 1.9489 - val_accuracy: 0.3942\n",
            "Epoch 124/500\n",
            "36/36 [==============================] - 2s 44ms/step - loss: 1.8651 - accuracy: 0.4018 - val_loss: 1.9514 - val_accuracy: 0.3942\n",
            "Epoch 125/500\n",
            "36/36 [==============================] - 2s 46ms/step - loss: 1.8573 - accuracy: 0.3997 - val_loss: 1.9466 - val_accuracy: 0.3968\n",
            "Epoch 126/500\n",
            "36/36 [==============================] - 2s 46ms/step - loss: 1.8902 - accuracy: 0.3917 - val_loss: 1.9467 - val_accuracy: 0.3982\n",
            "Epoch 127/500\n",
            "36/36 [==============================] - 2s 49ms/step - loss: 1.8735 - accuracy: 0.3988 - val_loss: 1.9532 - val_accuracy: 0.3896\n",
            "Epoch 128/500\n",
            "36/36 [==============================] - 2s 48ms/step - loss: 1.8783 - accuracy: 0.4036 - val_loss: 1.9506 - val_accuracy: 0.3988\n",
            "Epoch 129/500\n",
            "36/36 [==============================] - 2s 48ms/step - loss: 1.8727 - accuracy: 0.3982 - val_loss: 1.9505 - val_accuracy: 0.3962\n",
            "Epoch 130/500\n",
            "36/36 [==============================] - 2s 47ms/step - loss: 1.8448 - accuracy: 0.4081 - val_loss: 1.9652 - val_accuracy: 0.3850\n",
            "Epoch 131/500\n",
            "36/36 [==============================] - 2s 47ms/step - loss: 1.9053 - accuracy: 0.3842 - val_loss: 1.9510 - val_accuracy: 0.4001\n",
            "Epoch 132/500\n",
            "36/36 [==============================] - 2s 50ms/step - loss: 1.8396 - accuracy: 0.4072 - val_loss: 1.9496 - val_accuracy: 0.3982\n",
            "Epoch 133/500\n",
            "36/36 [==============================] - 2s 47ms/step - loss: 1.8788 - accuracy: 0.3996 - val_loss: 1.9498 - val_accuracy: 0.3982\n",
            "Epoch 134/500\n",
            "36/36 [==============================] - 2s 46ms/step - loss: 1.8783 - accuracy: 0.3993 - val_loss: 1.9532 - val_accuracy: 0.3955\n",
            "Epoch 135/500\n",
            "36/36 [==============================] - 2s 48ms/step - loss: 1.8589 - accuracy: 0.4090 - val_loss: 1.9571 - val_accuracy: 0.3942\n",
            "Epoch 136/500\n",
            "36/36 [==============================] - 2s 44ms/step - loss: 1.8533 - accuracy: 0.4069 - val_loss: 1.9565 - val_accuracy: 0.3876\n",
            "Epoch 137/500\n",
            "36/36 [==============================] - 1s 41ms/step - loss: 1.8761 - accuracy: 0.3988 - val_loss: 1.9473 - val_accuracy: 0.3982\n",
            "Epoch 138/500\n",
            "36/36 [==============================] - 2s 42ms/step - loss: 1.8456 - accuracy: 0.4129 - val_loss: 1.9561 - val_accuracy: 0.3909\n",
            "Epoch 139/500\n",
            "36/36 [==============================] - 2s 45ms/step - loss: 1.8626 - accuracy: 0.4062 - val_loss: 1.9605 - val_accuracy: 0.3909\n",
            "Epoch 140/500\n",
            "36/36 [==============================] - 2s 45ms/step - loss: 1.8505 - accuracy: 0.4091 - val_loss: 1.9561 - val_accuracy: 0.3902\n",
            "Epoch 141/500\n",
            "36/36 [==============================] - 2s 45ms/step - loss: 1.8247 - accuracy: 0.4164 - val_loss: 1.9599 - val_accuracy: 0.3876\n",
            "Epoch 142/500\n",
            "36/36 [==============================] - 2s 44ms/step - loss: 1.8555 - accuracy: 0.4001 - val_loss: 1.9558 - val_accuracy: 0.3975\n",
            "Epoch 143/500\n",
            "36/36 [==============================] - 2s 44ms/step - loss: 1.8505 - accuracy: 0.4093 - val_loss: 1.9540 - val_accuracy: 0.3968\n",
            "Epoch 144/500\n",
            "36/36 [==============================] - 2s 45ms/step - loss: 1.8634 - accuracy: 0.3950 - val_loss: 1.9540 - val_accuracy: 0.3988\n",
            "Epoch 145/500\n",
            "36/36 [==============================] - 2s 45ms/step - loss: 1.8427 - accuracy: 0.4121 - val_loss: 1.9524 - val_accuracy: 0.3962\n",
            "Epoch 146/500\n",
            "36/36 [==============================] - 2s 44ms/step - loss: 1.8396 - accuracy: 0.4101 - val_loss: 1.9605 - val_accuracy: 0.3902\n",
            "Epoch 147/500\n",
            "36/36 [==============================] - 2s 42ms/step - loss: 1.8781 - accuracy: 0.3950 - val_loss: 1.9530 - val_accuracy: 0.3982\n",
            "Epoch 148/500\n",
            "36/36 [==============================] - 2s 43ms/step - loss: 1.8331 - accuracy: 0.4066 - val_loss: 1.9555 - val_accuracy: 0.3975\n",
            "Epoch 149/500\n",
            "36/36 [==============================] - 2s 42ms/step - loss: 1.8575 - accuracy: 0.4047 - val_loss: 1.9755 - val_accuracy: 0.3817\n",
            "Epoch 150/500\n",
            "36/36 [==============================] - 2s 44ms/step - loss: 1.8360 - accuracy: 0.4141 - val_loss: 1.9691 - val_accuracy: 0.3883\n",
            "Epoch 151/500\n",
            "36/36 [==============================] - 2s 44ms/step - loss: 1.8371 - accuracy: 0.4055 - val_loss: 1.9534 - val_accuracy: 0.3949\n",
            "Epoch 152/500\n",
            "36/36 [==============================] - 2s 45ms/step - loss: 1.8464 - accuracy: 0.3993 - val_loss: 1.9567 - val_accuracy: 0.3909\n",
            "Epoch 153/500\n",
            "36/36 [==============================] - 2s 46ms/step - loss: 1.8686 - accuracy: 0.3949 - val_loss: 1.9653 - val_accuracy: 0.3889\n",
            "Epoch 154/500\n",
            "36/36 [==============================] - 2s 46ms/step - loss: 1.8418 - accuracy: 0.4096 - val_loss: 1.9528 - val_accuracy: 0.3975\n",
            "Epoch 155/500\n",
            "36/36 [==============================] - 2s 47ms/step - loss: 1.8843 - accuracy: 0.3959 - val_loss: 1.9594 - val_accuracy: 0.3982\n",
            "Epoch 156/500\n",
            "36/36 [==============================] - 2s 45ms/step - loss: 1.8633 - accuracy: 0.3962 - val_loss: 1.9580 - val_accuracy: 0.3909\n",
            "Epoch 157/500\n",
            "36/36 [==============================] - 2s 46ms/step - loss: 1.8690 - accuracy: 0.4058 - val_loss: 1.9593 - val_accuracy: 0.3955\n",
            "Epoch 158/500\n",
            "36/36 [==============================] - 2s 45ms/step - loss: 1.8324 - accuracy: 0.4135 - val_loss: 1.9641 - val_accuracy: 0.3955\n",
            "Epoch 159/500\n",
            "36/36 [==============================] - 2s 43ms/step - loss: 1.8303 - accuracy: 0.4093 - val_loss: 1.9662 - val_accuracy: 0.3922\n",
            "Epoch 160/500\n",
            "36/36 [==============================] - 2s 42ms/step - loss: 1.8533 - accuracy: 0.3923 - val_loss: 1.9648 - val_accuracy: 0.3962\n",
            "Epoch 161/500\n",
            "36/36 [==============================] - 2s 45ms/step - loss: 1.8568 - accuracy: 0.4036 - val_loss: 1.9725 - val_accuracy: 0.3922\n",
            "Epoch 162/500\n",
            "36/36 [==============================] - 2s 45ms/step - loss: 1.8585 - accuracy: 0.3999 - val_loss: 1.9656 - val_accuracy: 0.3935\n",
            "Epoch 163/500\n",
            "36/36 [==============================] - 2s 45ms/step - loss: 1.8455 - accuracy: 0.4072 - val_loss: 1.9594 - val_accuracy: 0.3942\n",
            "Epoch 164/500\n",
            "36/36 [==============================] - 2s 45ms/step - loss: 1.8075 - accuracy: 0.4195 - val_loss: 1.9695 - val_accuracy: 0.3889\n",
            "Epoch 165/500\n",
            "36/36 [==============================] - 2s 46ms/step - loss: 1.8630 - accuracy: 0.4034 - val_loss: 1.9583 - val_accuracy: 0.3988\n",
            "Epoch 166/500\n",
            "36/36 [==============================] - 2s 45ms/step - loss: 1.8291 - accuracy: 0.4103 - val_loss: 1.9637 - val_accuracy: 0.3922\n",
            "Epoch 167/500\n",
            "36/36 [==============================] - 2s 45ms/step - loss: 1.8521 - accuracy: 0.3997 - val_loss: 1.9590 - val_accuracy: 0.3962\n",
            "Epoch 168/500\n",
            "36/36 [==============================] - 2s 48ms/step - loss: 1.8732 - accuracy: 0.3904 - val_loss: 1.9620 - val_accuracy: 0.3962\n",
            "Epoch 169/500\n",
            "36/36 [==============================] - 2s 46ms/step - loss: 1.8261 - accuracy: 0.4040 - val_loss: 1.9654 - val_accuracy: 0.3995\n",
            "Epoch 170/500\n",
            "36/36 [==============================] - 2s 43ms/step - loss: 1.8326 - accuracy: 0.4040 - val_loss: 1.9650 - val_accuracy: 0.3916\n",
            "Epoch 171/500\n",
            "36/36 [==============================] - 2s 45ms/step - loss: 1.8151 - accuracy: 0.4107 - val_loss: 1.9774 - val_accuracy: 0.3856\n",
            "Epoch 172/500\n",
            "36/36 [==============================] - 2s 42ms/step - loss: 1.8205 - accuracy: 0.4086 - val_loss: 1.9707 - val_accuracy: 0.3869\n",
            "Epoch 173/500\n",
            "36/36 [==============================] - 2s 45ms/step - loss: 1.8465 - accuracy: 0.4041 - val_loss: 1.9813 - val_accuracy: 0.3817\n",
            "Epoch 174/500\n",
            "36/36 [==============================] - 1s 42ms/step - loss: 1.8013 - accuracy: 0.4150 - val_loss: 1.9914 - val_accuracy: 0.3823\n",
            "Epoch 175/500\n",
            "36/36 [==============================] - 2s 44ms/step - loss: 1.8514 - accuracy: 0.4049 - val_loss: 1.9707 - val_accuracy: 0.3942\n",
            "\u001b[1;37m2021-03-24 05:49:03 [INFO] Model Accuracy on test: 37.42%, Loss: 1.99\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:49:03 [INFO] 保存模型：model/lstm/myspace.h5\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:49:03 [INFO] TensorBoard 日志：logs/lstm/myspace210324054404\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:49:03 [INFO] ************************************************完成训练LSTM模型************************************************\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:49:03 [INFO] 开始加载编码后的密码数据：dataset/pl/wordlist/myspace_part.txt\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:49:03 [INFO] 开始加载tokenizer模型：model/tokenizer/myspace_part.pkl\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:49:03 [INFO] 将编码后的密码转换为（整数）序列\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:49:03 [INFO] Total Sequences: 5179\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:49:03 [INFO] 创建LSTM模型的输入输出\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:49:03 [INFO] X Shape: (5179, 19), y Shape: (5179,)\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:49:03 [INFO] 划分训练集、验证集和测试集\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:49:03 [INFO] x_train Shape: (3107, 19), y_train Shape: (3107, 41)\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:49:03 [INFO] x_val Shape: (1036, 19), y_val Shape: (1036, 41)\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:49:03 [INFO] x_test Shape: (1036, 19), y_test Shape: (1036, 41)\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:49:03 [INFO] *************************************************创建LSTM模型*************************************************\u001b[0m\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 19, 10)            410       \n",
            "_________________________________________________________________\n",
            "lstm_6 (LSTM)                (None, 19, 32)            5504      \n",
            "_________________________________________________________________\n",
            "lstm_7 (LSTM)                (None, 19, 32)            8320      \n",
            "_________________________________________________________________\n",
            "lstm_8 (LSTM)                (None, 32)                8320      \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 41)                1353      \n",
            "=================================================================\n",
            "Total params: 24,963\n",
            "Trainable params: 24,963\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\u001b[1;37m2021-03-24 05:49:04 [INFO] 训练日志文件：logs/lstm/myspace_part210324054904\u001b[0m\n",
            "2021-03-24 05:49:04.144709: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.\n",
            "2021-03-24 05:49:04.144760: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.\n",
            "2021-03-24 05:49:04.144830: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.\n",
            "\u001b[1;37m2021-03-24 05:49:04 [INFO] ************************************************开始训练LSTM模型************************************************\u001b[0m\n",
            "Epoch 1/500\n",
            " 1/25 [>.............................] - ETA: 2:02 - loss: 3.7133 - accuracy: 0.04692021-03-24 05:49:09.475476: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.\n",
            "2021-03-24 05:49:09.475540: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.\n",
            " 2/25 [=>............................] - ETA: 4s - loss: 3.7122 - accuracy: 0.0527  2021-03-24 05:49:09.716290: I tensorflow/core/profiler/lib/profiler_session.cc:71] Profiler session collecting data.\n",
            "2021-03-24 05:49:09.755978: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.\n",
            "25/25 [==============================] - 8s 112ms/step - loss: 3.6410 - accuracy: 0.0440 - val_loss: 3.0583 - val_accuracy: 0.1197\n",
            "Epoch 2/500\n",
            "25/25 [==============================] - 1s 45ms/step - loss: 2.8926 - accuracy: 0.1337 - val_loss: 2.6625 - val_accuracy: 0.1863\n",
            "Epoch 3/500\n",
            "25/25 [==============================] - 1s 44ms/step - loss: 2.5869 - accuracy: 0.2159 - val_loss: 2.6320 - val_accuracy: 0.1863\n",
            "Epoch 4/500\n",
            "25/25 [==============================] - 1s 43ms/step - loss: 2.5652 - accuracy: 0.2058 - val_loss: 2.6229 - val_accuracy: 0.1863\n",
            "Epoch 5/500\n",
            "25/25 [==============================] - 1s 43ms/step - loss: 2.5307 - accuracy: 0.2146 - val_loss: 2.6137 - val_accuracy: 0.1863\n",
            "Epoch 6/500\n",
            "25/25 [==============================] - 1s 45ms/step - loss: 2.5562 - accuracy: 0.2067 - val_loss: 2.6161 - val_accuracy: 0.1863\n",
            "Epoch 7/500\n",
            "25/25 [==============================] - 1s 51ms/step - loss: 2.5513 - accuracy: 0.2139 - val_loss: 2.6130 - val_accuracy: 0.1863\n",
            "Epoch 8/500\n",
            "25/25 [==============================] - 1s 49ms/step - loss: 2.5550 - accuracy: 0.2046 - val_loss: 2.6118 - val_accuracy: 0.1863\n",
            "Epoch 9/500\n",
            "25/25 [==============================] - 1s 51ms/step - loss: 2.5413 - accuracy: 0.2121 - val_loss: 2.6102 - val_accuracy: 0.1863\n",
            "Epoch 10/500\n",
            "25/25 [==============================] - 1s 49ms/step - loss: 2.5774 - accuracy: 0.2071 - val_loss: 2.6114 - val_accuracy: 0.1863\n",
            "Epoch 11/500\n",
            "25/25 [==============================] - 1s 51ms/step - loss: 2.5391 - accuracy: 0.2156 - val_loss: 2.6106 - val_accuracy: 0.1863\n",
            "Epoch 12/500\n",
            "25/25 [==============================] - 1s 47ms/step - loss: 2.5382 - accuracy: 0.2062 - val_loss: 2.6116 - val_accuracy: 0.1863\n",
            "Epoch 13/500\n",
            "25/25 [==============================] - 1s 47ms/step - loss: 2.5329 - accuracy: 0.2100 - val_loss: 2.6093 - val_accuracy: 0.1863\n",
            "Epoch 14/500\n",
            "25/25 [==============================] - 1s 49ms/step - loss: 2.5277 - accuracy: 0.2072 - val_loss: 2.6112 - val_accuracy: 0.1863\n",
            "Epoch 15/500\n",
            "25/25 [==============================] - 1s 50ms/step - loss: 2.5436 - accuracy: 0.2084 - val_loss: 2.6078 - val_accuracy: 0.1863\n",
            "Epoch 16/500\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 2.5373 - accuracy: 0.2125 - val_loss: 2.6150 - val_accuracy: 0.1863\n",
            "Epoch 17/500\n",
            "25/25 [==============================] - 1s 49ms/step - loss: 2.5462 - accuracy: 0.2009 - val_loss: 2.6128 - val_accuracy: 0.1863\n",
            "Epoch 18/500\n",
            "25/25 [==============================] - 1s 48ms/step - loss: 2.5583 - accuracy: 0.2092 - val_loss: 2.6051 - val_accuracy: 0.1863\n",
            "Epoch 19/500\n",
            "25/25 [==============================] - 1s 47ms/step - loss: 2.5470 - accuracy: 0.2123 - val_loss: 2.6067 - val_accuracy: 0.1863\n",
            "Epoch 20/500\n",
            "25/25 [==============================] - 1s 50ms/step - loss: 2.5531 - accuracy: 0.2085 - val_loss: 2.6079 - val_accuracy: 0.1863\n",
            "Epoch 21/500\n",
            "25/25 [==============================] - 1s 51ms/step - loss: 2.5474 - accuracy: 0.2117 - val_loss: 2.6063 - val_accuracy: 0.1863\n",
            "Epoch 22/500\n",
            "25/25 [==============================] - 1s 50ms/step - loss: 2.5677 - accuracy: 0.2079 - val_loss: 2.6026 - val_accuracy: 0.1863\n",
            "Epoch 23/500\n",
            "25/25 [==============================] - 1s 50ms/step - loss: 2.5436 - accuracy: 0.2094 - val_loss: 2.5848 - val_accuracy: 0.1863\n",
            "Epoch 24/500\n",
            "25/25 [==============================] - 1s 51ms/step - loss: 2.5174 - accuracy: 0.2063 - val_loss: 2.5439 - val_accuracy: 0.1863\n",
            "Epoch 25/500\n",
            "25/25 [==============================] - 1s 51ms/step - loss: 2.4693 - accuracy: 0.2192 - val_loss: 2.4337 - val_accuracy: 0.2346\n",
            "Epoch 26/500\n",
            "25/25 [==============================] - 1s 48ms/step - loss: 2.3495 - accuracy: 0.2686 - val_loss: 2.2756 - val_accuracy: 0.3021\n",
            "Epoch 27/500\n",
            "25/25 [==============================] - 1s 47ms/step - loss: 2.1866 - accuracy: 0.3181 - val_loss: 2.1835 - val_accuracy: 0.3234\n",
            "Epoch 28/500\n",
            "25/25 [==============================] - 1s 46ms/step - loss: 2.0882 - accuracy: 0.3395 - val_loss: 2.1456 - val_accuracy: 0.3263\n",
            "Epoch 29/500\n",
            "25/25 [==============================] - 1s 44ms/step - loss: 2.0777 - accuracy: 0.3120 - val_loss: 2.1281 - val_accuracy: 0.3243\n",
            "Epoch 30/500\n",
            "25/25 [==============================] - 1s 47ms/step - loss: 2.0214 - accuracy: 0.3402 - val_loss: 2.1022 - val_accuracy: 0.3118\n",
            "Epoch 31/500\n",
            "25/25 [==============================] - 1s 43ms/step - loss: 2.0273 - accuracy: 0.3279 - val_loss: 2.0777 - val_accuracy: 0.3195\n",
            "Epoch 32/500\n",
            "25/25 [==============================] - 1s 42ms/step - loss: 2.0162 - accuracy: 0.3256 - val_loss: 2.0647 - val_accuracy: 0.3263\n",
            "Epoch 33/500\n",
            "25/25 [==============================] - 1s 45ms/step - loss: 1.9600 - accuracy: 0.3408 - val_loss: 2.0549 - val_accuracy: 0.3224\n",
            "Epoch 34/500\n",
            "25/25 [==============================] - 1s 46ms/step - loss: 1.9736 - accuracy: 0.3391 - val_loss: 2.0465 - val_accuracy: 0.3224\n",
            "Epoch 35/500\n",
            "25/25 [==============================] - 1s 45ms/step - loss: 1.9608 - accuracy: 0.3525 - val_loss: 2.0514 - val_accuracy: 0.3282\n",
            "Epoch 36/500\n",
            "25/25 [==============================] - 1s 43ms/step - loss: 1.9357 - accuracy: 0.3514 - val_loss: 2.0234 - val_accuracy: 0.3359\n",
            "Epoch 37/500\n",
            "25/25 [==============================] - 1s 43ms/step - loss: 1.9430 - accuracy: 0.3594 - val_loss: 2.0130 - val_accuracy: 0.3427\n",
            "Epoch 38/500\n",
            "25/25 [==============================] - 1s 46ms/step - loss: 1.8909 - accuracy: 0.3782 - val_loss: 2.0104 - val_accuracy: 0.3485\n",
            "Epoch 39/500\n",
            "25/25 [==============================] - 1s 46ms/step - loss: 1.9268 - accuracy: 0.3782 - val_loss: 2.0022 - val_accuracy: 0.3407\n",
            "Epoch 40/500\n",
            "25/25 [==============================] - 1s 47ms/step - loss: 1.9275 - accuracy: 0.3741 - val_loss: 2.0002 - val_accuracy: 0.3407\n",
            "Epoch 41/500\n",
            "25/25 [==============================] - 1s 44ms/step - loss: 1.8993 - accuracy: 0.3699 - val_loss: 2.0082 - val_accuracy: 0.3427\n",
            "Epoch 42/500\n",
            "25/25 [==============================] - 1s 43ms/step - loss: 1.8931 - accuracy: 0.3818 - val_loss: 1.9951 - val_accuracy: 0.3349\n",
            "Epoch 43/500\n",
            "25/25 [==============================] - 1s 45ms/step - loss: 1.9115 - accuracy: 0.3639 - val_loss: 1.9964 - val_accuracy: 0.3475\n",
            "Epoch 44/500\n",
            "25/25 [==============================] - 1s 42ms/step - loss: 1.8579 - accuracy: 0.3866 - val_loss: 1.9920 - val_accuracy: 0.3523\n",
            "Epoch 45/500\n",
            "25/25 [==============================] - 1s 44ms/step - loss: 1.9211 - accuracy: 0.3694 - val_loss: 1.9871 - val_accuracy: 0.3398\n",
            "Epoch 46/500\n",
            "25/25 [==============================] - 1s 47ms/step - loss: 1.8865 - accuracy: 0.3830 - val_loss: 1.9968 - val_accuracy: 0.3456\n",
            "Epoch 47/500\n",
            "25/25 [==============================] - 1s 48ms/step - loss: 1.8618 - accuracy: 0.3691 - val_loss: 1.9811 - val_accuracy: 0.3485\n",
            "Epoch 48/500\n",
            "25/25 [==============================] - 1s 42ms/step - loss: 1.8844 - accuracy: 0.3810 - val_loss: 1.9928 - val_accuracy: 0.3292\n",
            "Epoch 49/500\n",
            "25/25 [==============================] - 1s 43ms/step - loss: 1.8729 - accuracy: 0.3670 - val_loss: 1.9850 - val_accuracy: 0.3417\n",
            "Epoch 50/500\n",
            "25/25 [==============================] - 1s 43ms/step - loss: 1.8947 - accuracy: 0.3675 - val_loss: 1.9808 - val_accuracy: 0.3552\n",
            "Epoch 51/500\n",
            "25/25 [==============================] - 1s 46ms/step - loss: 1.8714 - accuracy: 0.3785 - val_loss: 1.9899 - val_accuracy: 0.3494\n",
            "Epoch 52/500\n",
            "25/25 [==============================] - 1s 49ms/step - loss: 1.8637 - accuracy: 0.3825 - val_loss: 1.9851 - val_accuracy: 0.3378\n",
            "Epoch 53/500\n",
            "25/25 [==============================] - 1s 48ms/step - loss: 1.8882 - accuracy: 0.3640 - val_loss: 1.9778 - val_accuracy: 0.3562\n",
            "Epoch 54/500\n",
            "25/25 [==============================] - 1s 47ms/step - loss: 1.8858 - accuracy: 0.3835 - val_loss: 1.9795 - val_accuracy: 0.3571\n",
            "Epoch 55/500\n",
            "25/25 [==============================] - 1s 45ms/step - loss: 1.8694 - accuracy: 0.3913 - val_loss: 1.9900 - val_accuracy: 0.3301\n",
            "Epoch 56/500\n",
            "25/25 [==============================] - 1s 44ms/step - loss: 1.8730 - accuracy: 0.3732 - val_loss: 1.9802 - val_accuracy: 0.3407\n",
            "Epoch 57/500\n",
            "25/25 [==============================] - 1s 43ms/step - loss: 1.8690 - accuracy: 0.3774 - val_loss: 1.9782 - val_accuracy: 0.3581\n",
            "Epoch 58/500\n",
            "25/25 [==============================] - 1s 43ms/step - loss: 1.8630 - accuracy: 0.3819 - val_loss: 1.9764 - val_accuracy: 0.3562\n",
            "Epoch 59/500\n",
            "25/25 [==============================] - 1s 46ms/step - loss: 1.8570 - accuracy: 0.3931 - val_loss: 1.9735 - val_accuracy: 0.3562\n",
            "Epoch 60/500\n",
            "25/25 [==============================] - 1s 46ms/step - loss: 1.8350 - accuracy: 0.3821 - val_loss: 1.9713 - val_accuracy: 0.3610\n",
            "Epoch 61/500\n",
            "25/25 [==============================] - 1s 44ms/step - loss: 1.8606 - accuracy: 0.3854 - val_loss: 1.9682 - val_accuracy: 0.3562\n",
            "Epoch 62/500\n",
            "25/25 [==============================] - 1s 43ms/step - loss: 1.8716 - accuracy: 0.3897 - val_loss: 1.9697 - val_accuracy: 0.3562\n",
            "Epoch 63/500\n",
            "25/25 [==============================] - 1s 44ms/step - loss: 1.8501 - accuracy: 0.3970 - val_loss: 1.9724 - val_accuracy: 0.3571\n",
            "Epoch 64/500\n",
            "25/25 [==============================] - 1s 46ms/step - loss: 1.8542 - accuracy: 0.3864 - val_loss: 1.9739 - val_accuracy: 0.3514\n",
            "Epoch 65/500\n",
            "25/25 [==============================] - 1s 50ms/step - loss: 1.8783 - accuracy: 0.3787 - val_loss: 1.9793 - val_accuracy: 0.3494\n",
            "Epoch 66/500\n",
            "25/25 [==============================] - 1s 51ms/step - loss: 1.8292 - accuracy: 0.3762 - val_loss: 1.9675 - val_accuracy: 0.3533\n",
            "Epoch 67/500\n",
            "25/25 [==============================] - 1s 51ms/step - loss: 1.8321 - accuracy: 0.3908 - val_loss: 1.9721 - val_accuracy: 0.3523\n",
            "Epoch 68/500\n",
            "25/25 [==============================] - 1s 50ms/step - loss: 1.8031 - accuracy: 0.4088 - val_loss: 1.9712 - val_accuracy: 0.3581\n",
            "Epoch 69/500\n",
            "25/25 [==============================] - 1s 44ms/step - loss: 1.8500 - accuracy: 0.3878 - val_loss: 1.9837 - val_accuracy: 0.3504\n",
            "Epoch 70/500\n",
            "25/25 [==============================] - 1s 46ms/step - loss: 1.8656 - accuracy: 0.3824 - val_loss: 1.9742 - val_accuracy: 0.3629\n",
            "Epoch 71/500\n",
            "25/25 [==============================] - 1s 47ms/step - loss: 1.8334 - accuracy: 0.3890 - val_loss: 1.9723 - val_accuracy: 0.3552\n",
            "Epoch 72/500\n",
            "25/25 [==============================] - 1s 50ms/step - loss: 1.8240 - accuracy: 0.3885 - val_loss: 1.9707 - val_accuracy: 0.3552\n",
            "Epoch 73/500\n",
            "25/25 [==============================] - 1s 50ms/step - loss: 1.8678 - accuracy: 0.3627 - val_loss: 1.9663 - val_accuracy: 0.3600\n",
            "Epoch 74/500\n",
            "25/25 [==============================] - 1s 50ms/step - loss: 1.8327 - accuracy: 0.3840 - val_loss: 1.9688 - val_accuracy: 0.3552\n",
            "Epoch 75/500\n",
            "25/25 [==============================] - 1s 49ms/step - loss: 1.8551 - accuracy: 0.3796 - val_loss: 1.9699 - val_accuracy: 0.3417\n",
            "Epoch 76/500\n",
            "25/25 [==============================] - 1s 49ms/step - loss: 1.8582 - accuracy: 0.3872 - val_loss: 1.9716 - val_accuracy: 0.3620\n",
            "Epoch 77/500\n",
            "25/25 [==============================] - 1s 50ms/step - loss: 1.8311 - accuracy: 0.3934 - val_loss: 1.9590 - val_accuracy: 0.3668\n",
            "Epoch 78/500\n",
            "25/25 [==============================] - 1s 50ms/step - loss: 1.8126 - accuracy: 0.4016 - val_loss: 1.9636 - val_accuracy: 0.3571\n",
            "Epoch 79/500\n",
            "25/25 [==============================] - 1s 50ms/step - loss: 1.8610 - accuracy: 0.3905 - val_loss: 1.9664 - val_accuracy: 0.3639\n",
            "Epoch 80/500\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 1.8401 - accuracy: 0.3926 - val_loss: 1.9632 - val_accuracy: 0.3571\n",
            "Epoch 81/500\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 1.7805 - accuracy: 0.4097 - val_loss: 1.9595 - val_accuracy: 0.3658\n",
            "Epoch 82/500\n",
            "25/25 [==============================] - 1s 50ms/step - loss: 1.8265 - accuracy: 0.4144 - val_loss: 1.9652 - val_accuracy: 0.3629\n",
            "Epoch 83/500\n",
            "25/25 [==============================] - 1s 48ms/step - loss: 1.8100 - accuracy: 0.3964 - val_loss: 1.9647 - val_accuracy: 0.3668\n",
            "Epoch 84/500\n",
            "25/25 [==============================] - 1s 50ms/step - loss: 1.8225 - accuracy: 0.4104 - val_loss: 1.9625 - val_accuracy: 0.3687\n",
            "Epoch 85/500\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 1.8332 - accuracy: 0.3966 - val_loss: 1.9804 - val_accuracy: 0.3600\n",
            "Epoch 86/500\n",
            "25/25 [==============================] - 1s 50ms/step - loss: 1.7831 - accuracy: 0.4109 - val_loss: 1.9728 - val_accuracy: 0.3562\n",
            "Epoch 87/500\n",
            "25/25 [==============================] - 1s 51ms/step - loss: 1.8231 - accuracy: 0.3962 - val_loss: 1.9600 - val_accuracy: 0.3649\n",
            "Epoch 88/500\n",
            "25/25 [==============================] - 1s 50ms/step - loss: 1.8165 - accuracy: 0.4103 - val_loss: 1.9633 - val_accuracy: 0.3726\n",
            "Epoch 89/500\n",
            "25/25 [==============================] - 1s 49ms/step - loss: 1.7942 - accuracy: 0.4072 - val_loss: 1.9630 - val_accuracy: 0.3736\n",
            "Epoch 90/500\n",
            "25/25 [==============================] - 1s 47ms/step - loss: 1.8146 - accuracy: 0.4050 - val_loss: 1.9623 - val_accuracy: 0.3668\n",
            "Epoch 91/500\n",
            "25/25 [==============================] - 1s 49ms/step - loss: 1.7992 - accuracy: 0.4045 - val_loss: 1.9742 - val_accuracy: 0.3678\n",
            "Epoch 92/500\n",
            "25/25 [==============================] - 1s 49ms/step - loss: 1.8101 - accuracy: 0.4089 - val_loss: 1.9499 - val_accuracy: 0.3890\n",
            "Epoch 93/500\n",
            "25/25 [==============================] - 1s 44ms/step - loss: 1.7834 - accuracy: 0.4108 - val_loss: 1.9576 - val_accuracy: 0.3764\n",
            "Epoch 94/500\n",
            "25/25 [==============================] - 1s 50ms/step - loss: 1.7935 - accuracy: 0.4152 - val_loss: 1.9572 - val_accuracy: 0.3755\n",
            "Epoch 95/500\n",
            "25/25 [==============================] - 1s 44ms/step - loss: 1.7865 - accuracy: 0.4191 - val_loss: 1.9535 - val_accuracy: 0.3861\n",
            "Epoch 96/500\n",
            "25/25 [==============================] - 1s 45ms/step - loss: 1.8004 - accuracy: 0.4023 - val_loss: 1.9522 - val_accuracy: 0.3900\n",
            "Epoch 97/500\n",
            "25/25 [==============================] - 1s 45ms/step - loss: 1.7586 - accuracy: 0.4130 - val_loss: 1.9533 - val_accuracy: 0.3813\n",
            "Epoch 98/500\n",
            "25/25 [==============================] - 1s 43ms/step - loss: 1.7820 - accuracy: 0.4162 - val_loss: 1.9587 - val_accuracy: 0.3842\n",
            "Epoch 99/500\n",
            "25/25 [==============================] - 1s 47ms/step - loss: 1.8063 - accuracy: 0.4064 - val_loss: 1.9493 - val_accuracy: 0.3861\n",
            "Epoch 100/500\n",
            "25/25 [==============================] - 1s 44ms/step - loss: 1.7841 - accuracy: 0.4054 - val_loss: 1.9494 - val_accuracy: 0.3871\n",
            "Epoch 101/500\n",
            "25/25 [==============================] - 1s 45ms/step - loss: 1.8046 - accuracy: 0.4043 - val_loss: 1.9494 - val_accuracy: 0.3842\n",
            "Epoch 102/500\n",
            "25/25 [==============================] - 1s 45ms/step - loss: 1.7660 - accuracy: 0.4231 - val_loss: 1.9523 - val_accuracy: 0.3851\n",
            "Epoch 103/500\n",
            "25/25 [==============================] - 1s 46ms/step - loss: 1.7793 - accuracy: 0.4059 - val_loss: 1.9458 - val_accuracy: 0.3890\n",
            "Epoch 104/500\n",
            "25/25 [==============================] - 1s 46ms/step - loss: 1.7763 - accuracy: 0.4170 - val_loss: 1.9471 - val_accuracy: 0.3938\n",
            "Epoch 105/500\n",
            "25/25 [==============================] - 1s 46ms/step - loss: 1.7722 - accuracy: 0.4161 - val_loss: 1.9458 - val_accuracy: 0.3813\n",
            "Epoch 106/500\n",
            "25/25 [==============================] - 1s 46ms/step - loss: 1.7643 - accuracy: 0.4202 - val_loss: 1.9419 - val_accuracy: 0.3958\n",
            "Epoch 107/500\n",
            "25/25 [==============================] - 1s 49ms/step - loss: 1.7626 - accuracy: 0.4183 - val_loss: 1.9463 - val_accuracy: 0.3919\n",
            "Epoch 108/500\n",
            "25/25 [==============================] - 1s 51ms/step - loss: 1.7860 - accuracy: 0.4035 - val_loss: 1.9357 - val_accuracy: 0.4035\n",
            "Epoch 109/500\n",
            "25/25 [==============================] - 1s 46ms/step - loss: 1.7824 - accuracy: 0.4182 - val_loss: 1.9511 - val_accuracy: 0.3909\n",
            "Epoch 110/500\n",
            "25/25 [==============================] - 1s 49ms/step - loss: 1.7527 - accuracy: 0.4216 - val_loss: 1.9410 - val_accuracy: 0.3813\n",
            "Epoch 111/500\n",
            "25/25 [==============================] - 1s 48ms/step - loss: 1.7918 - accuracy: 0.4143 - val_loss: 1.9469 - val_accuracy: 0.3948\n",
            "Epoch 112/500\n",
            "25/25 [==============================] - 1s 46ms/step - loss: 1.8152 - accuracy: 0.4025 - val_loss: 1.9326 - val_accuracy: 0.3919\n",
            "Epoch 113/500\n",
            "25/25 [==============================] - 1s 46ms/step - loss: 1.7585 - accuracy: 0.4248 - val_loss: 1.9423 - val_accuracy: 0.3948\n",
            "Epoch 114/500\n",
            "25/25 [==============================] - 1s 45ms/step - loss: 1.7838 - accuracy: 0.4054 - val_loss: 1.9401 - val_accuracy: 0.3880\n",
            "Epoch 115/500\n",
            "25/25 [==============================] - 1s 45ms/step - loss: 1.7405 - accuracy: 0.4233 - val_loss: 1.9374 - val_accuracy: 0.3948\n",
            "Epoch 116/500\n",
            "25/25 [==============================] - 1s 45ms/step - loss: 1.7580 - accuracy: 0.4231 - val_loss: 1.9332 - val_accuracy: 0.3919\n",
            "Epoch 117/500\n",
            "25/25 [==============================] - 1s 48ms/step - loss: 1.7548 - accuracy: 0.4230 - val_loss: 1.9330 - val_accuracy: 0.3938\n",
            "Epoch 118/500\n",
            "25/25 [==============================] - 1s 47ms/step - loss: 1.7263 - accuracy: 0.4291 - val_loss: 1.9386 - val_accuracy: 0.3871\n",
            "Epoch 119/500\n",
            "25/25 [==============================] - 1s 50ms/step - loss: 1.7726 - accuracy: 0.4122 - val_loss: 1.9369 - val_accuracy: 0.3938\n",
            "Epoch 120/500\n",
            "25/25 [==============================] - 1s 51ms/step - loss: 1.7900 - accuracy: 0.4066 - val_loss: 1.9350 - val_accuracy: 0.3909\n",
            "Epoch 121/500\n",
            "25/25 [==============================] - 1s 49ms/step - loss: 1.7947 - accuracy: 0.4158 - val_loss: 1.9352 - val_accuracy: 0.3967\n",
            "Epoch 122/500\n",
            "25/25 [==============================] - 1s 49ms/step - loss: 1.7566 - accuracy: 0.4114 - val_loss: 1.9344 - val_accuracy: 0.3909\n",
            "Epoch 123/500\n",
            "25/25 [==============================] - 1s 48ms/step - loss: 1.7735 - accuracy: 0.4224 - val_loss: 1.9340 - val_accuracy: 0.3938\n",
            "Epoch 124/500\n",
            "25/25 [==============================] - 1s 49ms/step - loss: 1.7557 - accuracy: 0.4248 - val_loss: 1.9300 - val_accuracy: 0.3890\n",
            "Epoch 125/500\n",
            "25/25 [==============================] - 1s 49ms/step - loss: 1.7701 - accuracy: 0.4188 - val_loss: 1.9349 - val_accuracy: 0.3900\n",
            "Epoch 126/500\n",
            "25/25 [==============================] - 1s 49ms/step - loss: 1.7330 - accuracy: 0.4209 - val_loss: 1.9307 - val_accuracy: 0.3958\n",
            "Epoch 127/500\n",
            "25/25 [==============================] - 1s 46ms/step - loss: 1.7300 - accuracy: 0.4318 - val_loss: 1.9330 - val_accuracy: 0.3948\n",
            "Epoch 128/500\n",
            "25/25 [==============================] - 1s 46ms/step - loss: 1.8128 - accuracy: 0.3950 - val_loss: 1.9241 - val_accuracy: 0.3909\n",
            "Epoch 129/500\n",
            "25/25 [==============================] - 1s 48ms/step - loss: 1.7369 - accuracy: 0.4253 - val_loss: 1.9253 - val_accuracy: 0.3880\n",
            "Epoch 130/500\n",
            "25/25 [==============================] - 1s 50ms/step - loss: 1.7754 - accuracy: 0.4178 - val_loss: 1.9286 - val_accuracy: 0.3986\n",
            "Epoch 131/500\n",
            "25/25 [==============================] - 1s 50ms/step - loss: 1.7532 - accuracy: 0.4165 - val_loss: 1.9237 - val_accuracy: 0.4025\n",
            "Epoch 132/500\n",
            "25/25 [==============================] - 1s 44ms/step - loss: 1.7679 - accuracy: 0.4042 - val_loss: 1.9287 - val_accuracy: 0.4044\n",
            "Epoch 133/500\n",
            "25/25 [==============================] - 1s 43ms/step - loss: 1.7539 - accuracy: 0.4225 - val_loss: 1.9332 - val_accuracy: 0.3909\n",
            "Epoch 134/500\n",
            "25/25 [==============================] - 1s 45ms/step - loss: 1.7383 - accuracy: 0.4253 - val_loss: 1.9314 - val_accuracy: 0.3919\n",
            "Epoch 135/500\n",
            "25/25 [==============================] - 1s 44ms/step - loss: 1.7679 - accuracy: 0.4186 - val_loss: 1.9364 - val_accuracy: 0.3880\n",
            "Epoch 136/500\n",
            "25/25 [==============================] - 1s 44ms/step - loss: 1.7277 - accuracy: 0.4291 - val_loss: 1.9343 - val_accuracy: 0.3900\n",
            "Epoch 137/500\n",
            "25/25 [==============================] - 1s 43ms/step - loss: 1.7475 - accuracy: 0.4237 - val_loss: 1.9363 - val_accuracy: 0.3909\n",
            "Epoch 138/500\n",
            "25/25 [==============================] - 1s 43ms/step - loss: 1.7477 - accuracy: 0.4259 - val_loss: 1.9384 - val_accuracy: 0.3900\n",
            "Epoch 139/500\n",
            "25/25 [==============================] - 1s 51ms/step - loss: 1.7454 - accuracy: 0.4210 - val_loss: 1.9246 - val_accuracy: 0.3948\n",
            "Epoch 140/500\n",
            "25/25 [==============================] - 1s 46ms/step - loss: 1.7433 - accuracy: 0.4216 - val_loss: 1.9235 - val_accuracy: 0.3958\n",
            "Epoch 141/500\n",
            "25/25 [==============================] - 1s 44ms/step - loss: 1.7734 - accuracy: 0.4116 - val_loss: 1.9237 - val_accuracy: 0.3948\n",
            "Epoch 142/500\n",
            "25/25 [==============================] - 1s 45ms/step - loss: 1.7684 - accuracy: 0.4000 - val_loss: 1.9291 - val_accuracy: 0.3890\n",
            "Epoch 143/500\n",
            "25/25 [==============================] - 1s 43ms/step - loss: 1.7286 - accuracy: 0.4190 - val_loss: 1.9202 - val_accuracy: 0.4006\n",
            "Epoch 144/500\n",
            "25/25 [==============================] - 1s 46ms/step - loss: 1.7336 - accuracy: 0.4207 - val_loss: 1.9227 - val_accuracy: 0.4044\n",
            "Epoch 145/500\n",
            "25/25 [==============================] - 1s 46ms/step - loss: 1.7264 - accuracy: 0.4249 - val_loss: 1.9298 - val_accuracy: 0.3842\n",
            "Epoch 146/500\n",
            "25/25 [==============================] - 1s 46ms/step - loss: 1.7539 - accuracy: 0.4099 - val_loss: 1.9349 - val_accuracy: 0.3851\n",
            "Epoch 147/500\n",
            "25/25 [==============================] - 1s 44ms/step - loss: 1.7635 - accuracy: 0.4085 - val_loss: 1.9162 - val_accuracy: 0.3938\n",
            "Epoch 148/500\n",
            "25/25 [==============================] - 1s 44ms/step - loss: 1.7278 - accuracy: 0.4199 - val_loss: 1.9267 - val_accuracy: 0.3842\n",
            "Epoch 149/500\n",
            "25/25 [==============================] - 1s 44ms/step - loss: 1.7596 - accuracy: 0.4148 - val_loss: 1.9241 - val_accuracy: 0.3929\n",
            "Epoch 150/500\n",
            "25/25 [==============================] - 1s 44ms/step - loss: 1.7251 - accuracy: 0.4270 - val_loss: 1.9268 - val_accuracy: 0.3919\n",
            "Epoch 151/500\n",
            "25/25 [==============================] - 1s 45ms/step - loss: 1.7029 - accuracy: 0.4357 - val_loss: 1.9278 - val_accuracy: 0.3861\n",
            "Epoch 152/500\n",
            "25/25 [==============================] - 1s 46ms/step - loss: 1.7380 - accuracy: 0.4258 - val_loss: 1.9212 - val_accuracy: 0.3871\n",
            "Epoch 153/500\n",
            "25/25 [==============================] - 1s 47ms/step - loss: 1.7079 - accuracy: 0.4331 - val_loss: 1.9253 - val_accuracy: 0.3900\n",
            "Epoch 154/500\n",
            "25/25 [==============================] - 1s 45ms/step - loss: 1.7481 - accuracy: 0.4275 - val_loss: 1.9162 - val_accuracy: 0.3871\n",
            "Epoch 155/500\n",
            "25/25 [==============================] - 1s 46ms/step - loss: 1.7044 - accuracy: 0.4295 - val_loss: 1.9237 - val_accuracy: 0.3871\n",
            "Epoch 156/500\n",
            "25/25 [==============================] - 1s 44ms/step - loss: 1.7355 - accuracy: 0.4176 - val_loss: 1.9166 - val_accuracy: 0.3919\n",
            "Epoch 157/500\n",
            "25/25 [==============================] - 1s 45ms/step - loss: 1.7349 - accuracy: 0.4069 - val_loss: 1.9146 - val_accuracy: 0.4015\n",
            "Epoch 158/500\n",
            "25/25 [==============================] - 1s 45ms/step - loss: 1.7145 - accuracy: 0.4409 - val_loss: 1.9273 - val_accuracy: 0.3890\n",
            "Epoch 159/500\n",
            "25/25 [==============================] - 1s 45ms/step - loss: 1.7136 - accuracy: 0.4214 - val_loss: 1.9209 - val_accuracy: 0.3919\n",
            "Epoch 160/500\n",
            "25/25 [==============================] - 1s 45ms/step - loss: 1.7094 - accuracy: 0.4366 - val_loss: 1.9172 - val_accuracy: 0.3900\n",
            "Epoch 161/500\n",
            "25/25 [==============================] - 1s 44ms/step - loss: 1.7768 - accuracy: 0.4128 - val_loss: 1.9286 - val_accuracy: 0.3909\n",
            "Epoch 162/500\n",
            "25/25 [==============================] - 1s 44ms/step - loss: 1.6959 - accuracy: 0.4325 - val_loss: 1.9213 - val_accuracy: 0.3861\n",
            "Epoch 163/500\n",
            "25/25 [==============================] - 1s 43ms/step - loss: 1.7068 - accuracy: 0.4174 - val_loss: 1.9172 - val_accuracy: 0.3919\n",
            "Epoch 164/500\n",
            "25/25 [==============================] - 1s 43ms/step - loss: 1.7506 - accuracy: 0.4120 - val_loss: 1.9177 - val_accuracy: 0.3890\n",
            "Epoch 165/500\n",
            "25/25 [==============================] - 1s 43ms/step - loss: 1.7173 - accuracy: 0.4228 - val_loss: 1.9291 - val_accuracy: 0.3871\n",
            "Epoch 166/500\n",
            "25/25 [==============================] - 1s 42ms/step - loss: 1.7409 - accuracy: 0.4183 - val_loss: 1.9275 - val_accuracy: 0.3880\n",
            "Epoch 167/500\n",
            "25/25 [==============================] - 1s 44ms/step - loss: 1.7206 - accuracy: 0.4295 - val_loss: 1.9192 - val_accuracy: 0.3900\n",
            "Epoch 168/500\n",
            "25/25 [==============================] - 1s 46ms/step - loss: 1.7395 - accuracy: 0.4171 - val_loss: 1.9343 - val_accuracy: 0.3842\n",
            "Epoch 169/500\n",
            "25/25 [==============================] - 1s 45ms/step - loss: 1.7236 - accuracy: 0.4189 - val_loss: 1.9259 - val_accuracy: 0.3861\n",
            "Epoch 170/500\n",
            "25/25 [==============================] - 1s 46ms/step - loss: 1.7345 - accuracy: 0.4259 - val_loss: 1.9196 - val_accuracy: 0.3929\n",
            "Epoch 171/500\n",
            "25/25 [==============================] - 1s 46ms/step - loss: 1.7032 - accuracy: 0.4336 - val_loss: 1.9203 - val_accuracy: 0.3890\n",
            "Epoch 172/500\n",
            "25/25 [==============================] - 1s 47ms/step - loss: 1.7328 - accuracy: 0.4281 - val_loss: 1.9213 - val_accuracy: 0.3880\n",
            "Epoch 173/500\n",
            "25/25 [==============================] - 1s 47ms/step - loss: 1.7226 - accuracy: 0.4130 - val_loss: 1.9221 - val_accuracy: 0.4044\n",
            "Epoch 174/500\n",
            "25/25 [==============================] - 1s 45ms/step - loss: 1.7335 - accuracy: 0.4162 - val_loss: 1.9240 - val_accuracy: 0.3919\n",
            "Epoch 175/500\n",
            "25/25 [==============================] - 1s 47ms/step - loss: 1.7042 - accuracy: 0.4327 - val_loss: 1.9141 - val_accuracy: 0.3938\n",
            "Epoch 176/500\n",
            "25/25 [==============================] - 1s 48ms/step - loss: 1.7610 - accuracy: 0.4171 - val_loss: 1.9290 - val_accuracy: 0.3832\n",
            "Epoch 177/500\n",
            "25/25 [==============================] - 1s 47ms/step - loss: 1.7250 - accuracy: 0.4123 - val_loss: 1.9236 - val_accuracy: 0.3919\n",
            "Epoch 178/500\n",
            "25/25 [==============================] - 1s 46ms/step - loss: 1.6868 - accuracy: 0.4280 - val_loss: 1.9259 - val_accuracy: 0.3861\n",
            "Epoch 179/500\n",
            "25/25 [==============================] - 1s 48ms/step - loss: 1.7315 - accuracy: 0.4243 - val_loss: 1.9166 - val_accuracy: 0.3986\n",
            "Epoch 180/500\n",
            "25/25 [==============================] - 1s 47ms/step - loss: 1.7115 - accuracy: 0.4235 - val_loss: 1.9217 - val_accuracy: 0.3967\n",
            "Epoch 181/500\n",
            "25/25 [==============================] - 1s 47ms/step - loss: 1.7075 - accuracy: 0.4279 - val_loss: 1.9272 - val_accuracy: 0.3871\n",
            "Epoch 182/500\n",
            "25/25 [==============================] - 1s 47ms/step - loss: 1.6989 - accuracy: 0.4365 - val_loss: 1.9269 - val_accuracy: 0.3851\n",
            "Epoch 183/500\n",
            "25/25 [==============================] - 1s 47ms/step - loss: 1.7395 - accuracy: 0.4257 - val_loss: 1.9311 - val_accuracy: 0.3880\n",
            "Epoch 184/500\n",
            "25/25 [==============================] - 1s 49ms/step - loss: 1.7139 - accuracy: 0.4185 - val_loss: 1.9240 - val_accuracy: 0.3986\n",
            "Epoch 185/500\n",
            "25/25 [==============================] - 1s 49ms/step - loss: 1.7048 - accuracy: 0.4355 - val_loss: 1.9179 - val_accuracy: 0.3948\n",
            "Epoch 186/500\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 1.7026 - accuracy: 0.4296 - val_loss: 1.9296 - val_accuracy: 0.3977\n",
            "Epoch 187/500\n",
            "25/25 [==============================] - 1s 49ms/step - loss: 1.7545 - accuracy: 0.4056 - val_loss: 1.9248 - val_accuracy: 0.3909\n",
            "Epoch 188/500\n",
            "25/25 [==============================] - 1s 48ms/step - loss: 1.7061 - accuracy: 0.4153 - val_loss: 1.9255 - val_accuracy: 0.3929\n",
            "Epoch 189/500\n",
            "25/25 [==============================] - 1s 46ms/step - loss: 1.7050 - accuracy: 0.4302 - val_loss: 1.9237 - val_accuracy: 0.3958\n",
            "Epoch 190/500\n",
            "25/25 [==============================] - 1s 46ms/step - loss: 1.7215 - accuracy: 0.4228 - val_loss: 1.9224 - val_accuracy: 0.3929\n",
            "Epoch 191/500\n",
            "25/25 [==============================] - 1s 47ms/step - loss: 1.7056 - accuracy: 0.4256 - val_loss: 1.9176 - val_accuracy: 0.3986\n",
            "Epoch 192/500\n",
            "25/25 [==============================] - 1s 49ms/step - loss: 1.6986 - accuracy: 0.4262 - val_loss: 1.9315 - val_accuracy: 0.3919\n",
            "Epoch 193/500\n",
            "25/25 [==============================] - 1s 51ms/step - loss: 1.6892 - accuracy: 0.4357 - val_loss: 1.9290 - val_accuracy: 0.3909\n",
            "Epoch 194/500\n",
            "25/25 [==============================] - 1s 47ms/step - loss: 1.7515 - accuracy: 0.4218 - val_loss: 1.9248 - val_accuracy: 0.3948\n",
            "Epoch 195/500\n",
            "25/25 [==============================] - 1s 48ms/step - loss: 1.7058 - accuracy: 0.4353 - val_loss: 1.9233 - val_accuracy: 0.3958\n",
            "Epoch 196/500\n",
            "25/25 [==============================] - 1s 46ms/step - loss: 1.6959 - accuracy: 0.4298 - val_loss: 1.9256 - val_accuracy: 0.3900\n",
            "Epoch 197/500\n",
            "25/25 [==============================] - 1s 47ms/step - loss: 1.7099 - accuracy: 0.4284 - val_loss: 1.9282 - val_accuracy: 0.3900\n",
            "Epoch 198/500\n",
            "25/25 [==============================] - 1s 48ms/step - loss: 1.6786 - accuracy: 0.4392 - val_loss: 1.9244 - val_accuracy: 0.4015\n",
            "Epoch 199/500\n",
            "25/25 [==============================] - 1s 50ms/step - loss: 1.6836 - accuracy: 0.4356 - val_loss: 1.9336 - val_accuracy: 0.3861\n",
            "Epoch 200/500\n",
            "25/25 [==============================] - 1s 49ms/step - loss: 1.7044 - accuracy: 0.4315 - val_loss: 1.9338 - val_accuracy: 0.3919\n",
            "Epoch 201/500\n",
            "25/25 [==============================] - 1s 46ms/step - loss: 1.7051 - accuracy: 0.4224 - val_loss: 1.9281 - val_accuracy: 0.3996\n",
            "Epoch 202/500\n",
            "25/25 [==============================] - 1s 47ms/step - loss: 1.6949 - accuracy: 0.4244 - val_loss: 1.9298 - val_accuracy: 0.3938\n",
            "Epoch 203/500\n",
            "25/25 [==============================] - 1s 45ms/step - loss: 1.7349 - accuracy: 0.4263 - val_loss: 1.9289 - val_accuracy: 0.3929\n",
            "Epoch 204/500\n",
            "25/25 [==============================] - 1s 44ms/step - loss: 1.6982 - accuracy: 0.4275 - val_loss: 1.9308 - val_accuracy: 0.3900\n",
            "Epoch 205/500\n",
            "25/25 [==============================] - 1s 45ms/step - loss: 1.6773 - accuracy: 0.4352 - val_loss: 1.9237 - val_accuracy: 0.3986\n",
            "Epoch 206/500\n",
            "25/25 [==============================] - 1s 44ms/step - loss: 1.6721 - accuracy: 0.4343 - val_loss: 1.9379 - val_accuracy: 0.3832\n",
            "Epoch 207/500\n",
            "25/25 [==============================] - 1s 45ms/step - loss: 1.6971 - accuracy: 0.4354 - val_loss: 1.9358 - val_accuracy: 0.3861\n",
            "Epoch 208/500\n",
            "25/25 [==============================] - 1s 45ms/step - loss: 1.7337 - accuracy: 0.4186 - val_loss: 1.9245 - val_accuracy: 0.3909\n",
            "Epoch 209/500\n",
            "25/25 [==============================] - 1s 44ms/step - loss: 1.7011 - accuracy: 0.4303 - val_loss: 1.9339 - val_accuracy: 0.3890\n",
            "Epoch 210/500\n",
            "25/25 [==============================] - 1s 45ms/step - loss: 1.6722 - accuracy: 0.4400 - val_loss: 1.9234 - val_accuracy: 0.3929\n",
            "Epoch 211/500\n",
            "25/25 [==============================] - 1s 47ms/step - loss: 1.7033 - accuracy: 0.4243 - val_loss: 1.9367 - val_accuracy: 0.3909\n",
            "Epoch 212/500\n",
            "25/25 [==============================] - 1s 46ms/step - loss: 1.7169 - accuracy: 0.4272 - val_loss: 1.9261 - val_accuracy: 0.3967\n",
            "Epoch 213/500\n",
            "25/25 [==============================] - 1s 43ms/step - loss: 1.6705 - accuracy: 0.4291 - val_loss: 1.9292 - val_accuracy: 0.3900\n",
            "Epoch 214/500\n",
            "25/25 [==============================] - 1s 44ms/step - loss: 1.7061 - accuracy: 0.4287 - val_loss: 1.9275 - val_accuracy: 0.3909\n",
            "Epoch 215/500\n",
            "25/25 [==============================] - 1s 45ms/step - loss: 1.6811 - accuracy: 0.4323 - val_loss: 1.9305 - val_accuracy: 0.3919\n",
            "Epoch 216/500\n",
            "25/25 [==============================] - 1s 47ms/step - loss: 1.6881 - accuracy: 0.4447 - val_loss: 1.9313 - val_accuracy: 0.3919\n",
            "Epoch 217/500\n",
            "25/25 [==============================] - 1s 47ms/step - loss: 1.7047 - accuracy: 0.4336 - val_loss: 1.9420 - val_accuracy: 0.3958\n",
            "Epoch 218/500\n",
            "25/25 [==============================] - 1s 46ms/step - loss: 1.6940 - accuracy: 0.4293 - val_loss: 1.9373 - val_accuracy: 0.3909\n",
            "Epoch 219/500\n",
            "25/25 [==============================] - 1s 45ms/step - loss: 1.7014 - accuracy: 0.4272 - val_loss: 1.9562 - val_accuracy: 0.3813\n",
            "Epoch 220/500\n",
            "25/25 [==============================] - 1s 45ms/step - loss: 1.7087 - accuracy: 0.4137 - val_loss: 1.9322 - val_accuracy: 0.3890\n",
            "Epoch 221/500\n",
            "25/25 [==============================] - 1s 46ms/step - loss: 1.7089 - accuracy: 0.4196 - val_loss: 1.9471 - val_accuracy: 0.3803\n",
            "Epoch 222/500\n",
            "25/25 [==============================] - 1s 44ms/step - loss: 1.6700 - accuracy: 0.4316 - val_loss: 1.9335 - val_accuracy: 0.3958\n",
            "Epoch 223/500\n",
            "25/25 [==============================] - 1s 45ms/step - loss: 1.7082 - accuracy: 0.4277 - val_loss: 1.9326 - val_accuracy: 0.3977\n",
            "Epoch 224/500\n",
            "25/25 [==============================] - 1s 44ms/step - loss: 1.7125 - accuracy: 0.4329 - val_loss: 1.9499 - val_accuracy: 0.3842\n",
            "Epoch 225/500\n",
            "25/25 [==============================] - 1s 46ms/step - loss: 1.6936 - accuracy: 0.4382 - val_loss: 1.9346 - val_accuracy: 0.3842\n",
            "\u001b[1;37m2021-03-24 05:53:33 [INFO] Model Accuracy on test: 41.02%, Loss: 1.90\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:53:33 [INFO] 保存模型：model/lstm/myspace_part.h5\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:53:33 [INFO] TensorBoard 日志：logs/lstm/myspace_part210324054904\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:53:33 [INFO] ************************************************完成训练LSTM模型************************************************\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:53:33 [INFO] 开始加载编码后的密码数据：dataset/pl/wordlist/phpbb_part.txt\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:53:33 [INFO] 开始加载tokenizer模型：model/tokenizer/phpbb_part.pkl\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:53:33 [INFO] 将编码后的密码转换为（整数）序列\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:53:33 [INFO] Total Sequences: 10311\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:53:33 [INFO] 创建LSTM模型的输入输出\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:53:33 [INFO] X Shape: (10311, 19), y Shape: (10311,)\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:53:33 [INFO] 划分训练集、验证集和测试集\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:53:33 [INFO] x_train Shape: (6186, 19), y_train Shape: (6186, 49)\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:53:33 [INFO] x_val Shape: (2062, 19), y_val Shape: (2062, 49)\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:53:33 [INFO] x_test Shape: (2063, 19), y_test Shape: (2063, 49)\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:53:33 [INFO] *************************************************创建LSTM模型*************************************************\u001b[0m\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 19, 10)            490       \n",
            "_________________________________________________________________\n",
            "lstm_9 (LSTM)                (None, 19, 32)            5504      \n",
            "_________________________________________________________________\n",
            "lstm_10 (LSTM)               (None, 19, 32)            8320      \n",
            "_________________________________________________________________\n",
            "lstm_11 (LSTM)               (None, 32)                8320      \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 49)                1617      \n",
            "=================================================================\n",
            "Total params: 25,307\n",
            "Trainable params: 25,307\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\u001b[1;37m2021-03-24 05:53:34 [INFO] 训练日志文件：logs/lstm/phpbb_part210324055334\u001b[0m\n",
            "2021-03-24 05:53:34.070375: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.\n",
            "2021-03-24 05:53:34.070430: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.\n",
            "2021-03-24 05:53:34.070485: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.\n",
            "\u001b[1;37m2021-03-24 05:53:34 [INFO] ************************************************开始训练LSTM模型************************************************\u001b[0m\n",
            "Epoch 1/500\n",
            " 1/49 [..............................] - ETA: 3:44 - loss: 3.8917 - accuracy: 0.09382021-03-24 05:53:38.977604: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.\n",
            "2021-03-24 05:53:38.977671: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.\n",
            " 2/49 [>.............................] - ETA: 9s - loss: 3.8908 - accuracy: 0.1133  2021-03-24 05:53:39.207766: I tensorflow/core/profiler/lib/profiler_session.cc:71] Profiler session collecting data.\n",
            "2021-03-24 05:53:39.252280: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.\n",
            "49/49 [==============================] - 9s 86ms/step - loss: 3.6327 - accuracy: 0.1592 - val_loss: 2.6057 - val_accuracy: 0.1823\n",
            "Epoch 2/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 2.5473 - accuracy: 0.1938 - val_loss: 2.4526 - val_accuracy: 0.1823\n",
            "Epoch 3/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 2.4471 - accuracy: 0.1960 - val_loss: 2.4386 - val_accuracy: 0.1823\n",
            "Epoch 4/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 2.4382 - accuracy: 0.1933 - val_loss: 2.4347 - val_accuracy: 0.1823\n",
            "Epoch 5/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 2.4401 - accuracy: 0.1947 - val_loss: 2.4368 - val_accuracy: 0.1823\n",
            "Epoch 6/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 2.4333 - accuracy: 0.1928 - val_loss: 2.4327 - val_accuracy: 0.1823\n",
            "Epoch 7/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 2.4399 - accuracy: 0.1948 - val_loss: 2.4303 - val_accuracy: 0.1736\n",
            "Epoch 8/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 2.4582 - accuracy: 0.1894 - val_loss: 2.4338 - val_accuracy: 0.1823\n",
            "Epoch 9/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 2.4480 - accuracy: 0.1948 - val_loss: 2.4294 - val_accuracy: 0.1823\n",
            "Epoch 10/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 2.4507 - accuracy: 0.1897 - val_loss: 2.4317 - val_accuracy: 0.1717\n",
            "Epoch 11/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 2.4505 - accuracy: 0.1783 - val_loss: 2.4326 - val_accuracy: 0.1823\n",
            "Epoch 12/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 2.4521 - accuracy: 0.1815 - val_loss: 2.4316 - val_accuracy: 0.1736\n",
            "Epoch 13/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 2.4699 - accuracy: 0.1829 - val_loss: 2.4328 - val_accuracy: 0.1717\n",
            "Epoch 14/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 2.4587 - accuracy: 0.1802 - val_loss: 2.4355 - val_accuracy: 0.1823\n",
            "Epoch 15/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 2.4732 - accuracy: 0.1850 - val_loss: 2.4314 - val_accuracy: 0.1823\n",
            "Epoch 16/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 2.4565 - accuracy: 0.1772 - val_loss: 2.4325 - val_accuracy: 0.1823\n",
            "Epoch 17/500\n",
            "49/49 [==============================] - 2s 40ms/step - loss: 2.4499 - accuracy: 0.1933 - val_loss: 2.4316 - val_accuracy: 0.1823\n",
            "Epoch 18/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 2.4380 - accuracy: 0.1986 - val_loss: 2.4297 - val_accuracy: 0.1823\n",
            "Epoch 19/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 2.4664 - accuracy: 0.1779 - val_loss: 2.4305 - val_accuracy: 0.1823\n",
            "Epoch 20/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 2.4528 - accuracy: 0.1940 - val_loss: 2.4305 - val_accuracy: 0.1823\n",
            "Epoch 21/500\n",
            "49/49 [==============================] - 2s 40ms/step - loss: 2.4436 - accuracy: 0.1923 - val_loss: 2.4302 - val_accuracy: 0.1823\n",
            "Epoch 22/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 2.4383 - accuracy: 0.1929 - val_loss: 2.4301 - val_accuracy: 0.1823\n",
            "Epoch 23/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 2.4224 - accuracy: 0.1943 - val_loss: 2.4210 - val_accuracy: 0.1823\n",
            "Epoch 24/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 2.4326 - accuracy: 0.1940 - val_loss: 2.3900 - val_accuracy: 0.1823\n",
            "Epoch 25/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 2.4126 - accuracy: 0.2328 - val_loss: 2.2422 - val_accuracy: 0.3060\n",
            "Epoch 26/500\n",
            "49/49 [==============================] - 2s 43ms/step - loss: 2.1884 - accuracy: 0.3555 - val_loss: 1.9859 - val_accuracy: 0.3870\n",
            "Epoch 27/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.9544 - accuracy: 0.3918 - val_loss: 1.8891 - val_accuracy: 0.4166\n",
            "Epoch 28/500\n",
            "49/49 [==============================] - 2s 43ms/step - loss: 1.8772 - accuracy: 0.4134 - val_loss: 1.8570 - val_accuracy: 0.4214\n",
            "Epoch 29/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 1.8344 - accuracy: 0.4234 - val_loss: 1.8473 - val_accuracy: 0.4243\n",
            "Epoch 30/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.8480 - accuracy: 0.4189 - val_loss: 1.8478 - val_accuracy: 0.4176\n",
            "Epoch 31/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 1.8587 - accuracy: 0.4078 - val_loss: 1.8192 - val_accuracy: 0.4340\n",
            "Epoch 32/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.8177 - accuracy: 0.4151 - val_loss: 1.8155 - val_accuracy: 0.4316\n",
            "Epoch 33/500\n",
            "49/49 [==============================] - 2s 44ms/step - loss: 1.8249 - accuracy: 0.4216 - val_loss: 1.8086 - val_accuracy: 0.4316\n",
            "Epoch 34/500\n",
            "49/49 [==============================] - 2s 47ms/step - loss: 1.8188 - accuracy: 0.4161 - val_loss: 1.8388 - val_accuracy: 0.4277\n",
            "Epoch 35/500\n",
            "49/49 [==============================] - 2s 43ms/step - loss: 1.8078 - accuracy: 0.4161 - val_loss: 1.8001 - val_accuracy: 0.4345\n",
            "Epoch 36/500\n",
            "49/49 [==============================] - 2s 43ms/step - loss: 1.7873 - accuracy: 0.4331 - val_loss: 1.7938 - val_accuracy: 0.4379\n",
            "Epoch 37/500\n",
            "49/49 [==============================] - 2s 45ms/step - loss: 1.8045 - accuracy: 0.4249 - val_loss: 1.8063 - val_accuracy: 0.4277\n",
            "Epoch 38/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.7843 - accuracy: 0.4245 - val_loss: 1.7863 - val_accuracy: 0.4355\n",
            "Epoch 39/500\n",
            "49/49 [==============================] - 2s 43ms/step - loss: 1.7779 - accuracy: 0.4342 - val_loss: 1.7898 - val_accuracy: 0.4374\n",
            "Epoch 40/500\n",
            "49/49 [==============================] - 2s 43ms/step - loss: 1.7916 - accuracy: 0.4145 - val_loss: 1.7893 - val_accuracy: 0.4273\n",
            "Epoch 41/500\n",
            "49/49 [==============================] - 2s 45ms/step - loss: 1.7812 - accuracy: 0.4283 - val_loss: 1.7800 - val_accuracy: 0.4336\n",
            "Epoch 42/500\n",
            "49/49 [==============================] - 2s 44ms/step - loss: 1.7793 - accuracy: 0.4267 - val_loss: 1.7762 - val_accuracy: 0.4336\n",
            "Epoch 43/500\n",
            "49/49 [==============================] - 2s 43ms/step - loss: 1.7569 - accuracy: 0.4377 - val_loss: 1.7884 - val_accuracy: 0.4287\n",
            "Epoch 44/500\n",
            "49/49 [==============================] - 2s 44ms/step - loss: 1.7396 - accuracy: 0.4297 - val_loss: 1.7690 - val_accuracy: 0.4355\n",
            "Epoch 45/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.7597 - accuracy: 0.4305 - val_loss: 1.7680 - val_accuracy: 0.4345\n",
            "Epoch 46/500\n",
            "49/49 [==============================] - 2s 43ms/step - loss: 1.7668 - accuracy: 0.4228 - val_loss: 1.7721 - val_accuracy: 0.4350\n",
            "Epoch 47/500\n",
            "49/49 [==============================] - 2s 44ms/step - loss: 1.7654 - accuracy: 0.4188 - val_loss: 1.7622 - val_accuracy: 0.4379\n",
            "Epoch 48/500\n",
            "49/49 [==============================] - 2s 43ms/step - loss: 1.7025 - accuracy: 0.4418 - val_loss: 1.7581 - val_accuracy: 0.4394\n",
            "Epoch 49/500\n",
            "49/49 [==============================] - 2s 47ms/step - loss: 1.7321 - accuracy: 0.4354 - val_loss: 1.7591 - val_accuracy: 0.4340\n",
            "Epoch 50/500\n",
            "49/49 [==============================] - 2s 44ms/step - loss: 1.7630 - accuracy: 0.4328 - val_loss: 1.7631 - val_accuracy: 0.4345\n",
            "Epoch 51/500\n",
            "49/49 [==============================] - 2s 47ms/step - loss: 1.7488 - accuracy: 0.4248 - val_loss: 1.7587 - val_accuracy: 0.4399\n",
            "Epoch 52/500\n",
            "49/49 [==============================] - 2s 47ms/step - loss: 1.7276 - accuracy: 0.4376 - val_loss: 1.7580 - val_accuracy: 0.4399\n",
            "Epoch 53/500\n",
            "49/49 [==============================] - 2s 49ms/step - loss: 1.7163 - accuracy: 0.4409 - val_loss: 1.7508 - val_accuracy: 0.4413\n",
            "Epoch 54/500\n",
            "49/49 [==============================] - 2s 51ms/step - loss: 1.7293 - accuracy: 0.4330 - val_loss: 1.7559 - val_accuracy: 0.4384\n",
            "Epoch 55/500\n",
            "49/49 [==============================] - 2s 51ms/step - loss: 1.7341 - accuracy: 0.4323 - val_loss: 1.7494 - val_accuracy: 0.4379\n",
            "Epoch 56/500\n",
            "49/49 [==============================] - 2s 50ms/step - loss: 1.7051 - accuracy: 0.4395 - val_loss: 1.7656 - val_accuracy: 0.4263\n",
            "Epoch 57/500\n",
            "49/49 [==============================] - 2s 50ms/step - loss: 1.7596 - accuracy: 0.4262 - val_loss: 1.7517 - val_accuracy: 0.4428\n",
            "Epoch 58/500\n",
            "49/49 [==============================] - 2s 50ms/step - loss: 1.7353 - accuracy: 0.4360 - val_loss: 1.7486 - val_accuracy: 0.4379\n",
            "Epoch 59/500\n",
            "49/49 [==============================] - 2s 47ms/step - loss: 1.7050 - accuracy: 0.4436 - val_loss: 1.7548 - val_accuracy: 0.4423\n",
            "Epoch 60/500\n",
            "49/49 [==============================] - 2s 44ms/step - loss: 1.7045 - accuracy: 0.4307 - val_loss: 1.7479 - val_accuracy: 0.4389\n",
            "Epoch 61/500\n",
            "49/49 [==============================] - 2s 46ms/step - loss: 1.7064 - accuracy: 0.4358 - val_loss: 1.7497 - val_accuracy: 0.4370\n",
            "Epoch 62/500\n",
            "49/49 [==============================] - 2s 46ms/step - loss: 1.7357 - accuracy: 0.4279 - val_loss: 1.7613 - val_accuracy: 0.4336\n",
            "Epoch 63/500\n",
            "49/49 [==============================] - 2s 44ms/step - loss: 1.7277 - accuracy: 0.4310 - val_loss: 1.7501 - val_accuracy: 0.4389\n",
            "Epoch 64/500\n",
            "49/49 [==============================] - 2s 46ms/step - loss: 1.7368 - accuracy: 0.4263 - val_loss: 1.7481 - val_accuracy: 0.4403\n",
            "Epoch 65/500\n",
            "49/49 [==============================] - 2s 44ms/step - loss: 1.7239 - accuracy: 0.4317 - val_loss: 1.7536 - val_accuracy: 0.4340\n",
            "Epoch 66/500\n",
            "49/49 [==============================] - 2s 44ms/step - loss: 1.7349 - accuracy: 0.4274 - val_loss: 1.7510 - val_accuracy: 0.4345\n",
            "Epoch 67/500\n",
            "49/49 [==============================] - 2s 45ms/step - loss: 1.6919 - accuracy: 0.4318 - val_loss: 1.7564 - val_accuracy: 0.4340\n",
            "Epoch 68/500\n",
            "49/49 [==============================] - 2s 45ms/step - loss: 1.7101 - accuracy: 0.4398 - val_loss: 1.7468 - val_accuracy: 0.4370\n",
            "Epoch 69/500\n",
            "49/49 [==============================] - 2s 45ms/step - loss: 1.6789 - accuracy: 0.4504 - val_loss: 1.7452 - val_accuracy: 0.4403\n",
            "Epoch 70/500\n",
            "49/49 [==============================] - 2s 45ms/step - loss: 1.7151 - accuracy: 0.4412 - val_loss: 1.7464 - val_accuracy: 0.4355\n",
            "Epoch 71/500\n",
            "49/49 [==============================] - 2s 44ms/step - loss: 1.7225 - accuracy: 0.4370 - val_loss: 1.7520 - val_accuracy: 0.4292\n",
            "Epoch 72/500\n",
            "49/49 [==============================] - 2s 44ms/step - loss: 1.7145 - accuracy: 0.4333 - val_loss: 1.7572 - val_accuracy: 0.4273\n",
            "Epoch 73/500\n",
            "49/49 [==============================] - 2s 43ms/step - loss: 1.7351 - accuracy: 0.4254 - val_loss: 1.7434 - val_accuracy: 0.4379\n",
            "Epoch 74/500\n",
            "49/49 [==============================] - 2s 43ms/step - loss: 1.7037 - accuracy: 0.4371 - val_loss: 1.7427 - val_accuracy: 0.4403\n",
            "Epoch 75/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.7048 - accuracy: 0.4406 - val_loss: 1.7404 - val_accuracy: 0.4389\n",
            "Epoch 76/500\n",
            "49/49 [==============================] - 2s 44ms/step - loss: 1.7134 - accuracy: 0.4381 - val_loss: 1.7432 - val_accuracy: 0.4370\n",
            "Epoch 77/500\n",
            "49/49 [==============================] - 2s 44ms/step - loss: 1.7177 - accuracy: 0.4305 - val_loss: 1.7437 - val_accuracy: 0.4355\n",
            "Epoch 78/500\n",
            "49/49 [==============================] - 2s 43ms/step - loss: 1.7237 - accuracy: 0.4302 - val_loss: 1.7432 - val_accuracy: 0.4370\n",
            "Epoch 79/500\n",
            "49/49 [==============================] - 2s 45ms/step - loss: 1.7179 - accuracy: 0.4285 - val_loss: 1.7416 - val_accuracy: 0.4350\n",
            "Epoch 80/500\n",
            "49/49 [==============================] - 2s 45ms/step - loss: 1.7265 - accuracy: 0.4315 - val_loss: 1.7406 - val_accuracy: 0.4399\n",
            "Epoch 81/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.6844 - accuracy: 0.4356 - val_loss: 1.7576 - val_accuracy: 0.4253\n",
            "Epoch 82/500\n",
            "49/49 [==============================] - 2s 43ms/step - loss: 1.7073 - accuracy: 0.4376 - val_loss: 1.7430 - val_accuracy: 0.4331\n",
            "Epoch 83/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.6975 - accuracy: 0.4331 - val_loss: 1.7401 - val_accuracy: 0.4374\n",
            "Epoch 84/500\n",
            "49/49 [==============================] - 2s 43ms/step - loss: 1.6774 - accuracy: 0.4482 - val_loss: 1.7450 - val_accuracy: 0.4326\n",
            "Epoch 85/500\n",
            "49/49 [==============================] - 2s 43ms/step - loss: 1.6927 - accuracy: 0.4350 - val_loss: 1.7468 - val_accuracy: 0.4360\n",
            "Epoch 86/500\n",
            "49/49 [==============================] - 2s 43ms/step - loss: 1.7113 - accuracy: 0.4327 - val_loss: 1.7487 - val_accuracy: 0.4340\n",
            "Epoch 87/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.7087 - accuracy: 0.4351 - val_loss: 1.7413 - val_accuracy: 0.4360\n",
            "Epoch 88/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.7052 - accuracy: 0.4365 - val_loss: 1.7414 - val_accuracy: 0.4384\n",
            "Epoch 89/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.6722 - accuracy: 0.4379 - val_loss: 1.7400 - val_accuracy: 0.4399\n",
            "Epoch 90/500\n",
            "49/49 [==============================] - 2s 43ms/step - loss: 1.7136 - accuracy: 0.4310 - val_loss: 1.7409 - val_accuracy: 0.4336\n",
            "Epoch 91/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.7160 - accuracy: 0.4297 - val_loss: 1.7417 - val_accuracy: 0.4345\n",
            "Epoch 92/500\n",
            "49/49 [==============================] - 2s 45ms/step - loss: 1.7090 - accuracy: 0.4261 - val_loss: 1.7467 - val_accuracy: 0.4282\n",
            "Epoch 93/500\n",
            "49/49 [==============================] - 2s 45ms/step - loss: 1.6750 - accuracy: 0.4506 - val_loss: 1.7433 - val_accuracy: 0.4340\n",
            "Epoch 94/500\n",
            "49/49 [==============================] - 2s 46ms/step - loss: 1.6973 - accuracy: 0.4389 - val_loss: 1.7421 - val_accuracy: 0.4350\n",
            "Epoch 95/500\n",
            "49/49 [==============================] - 2s 44ms/step - loss: 1.7034 - accuracy: 0.4401 - val_loss: 1.7622 - val_accuracy: 0.4282\n",
            "Epoch 96/500\n",
            "49/49 [==============================] - 2s 46ms/step - loss: 1.7076 - accuracy: 0.4307 - val_loss: 1.7432 - val_accuracy: 0.4403\n",
            "Epoch 97/500\n",
            "49/49 [==============================] - 2s 45ms/step - loss: 1.6940 - accuracy: 0.4441 - val_loss: 1.7366 - val_accuracy: 0.4355\n",
            "Epoch 98/500\n",
            "49/49 [==============================] - 2s 44ms/step - loss: 1.6795 - accuracy: 0.4452 - val_loss: 1.7449 - val_accuracy: 0.4311\n",
            "Epoch 99/500\n",
            "49/49 [==============================] - 2s 45ms/step - loss: 1.6978 - accuracy: 0.4438 - val_loss: 1.7420 - val_accuracy: 0.4340\n",
            "Epoch 100/500\n",
            "49/49 [==============================] - 2s 43ms/step - loss: 1.6932 - accuracy: 0.4452 - val_loss: 1.7412 - val_accuracy: 0.4379\n",
            "Epoch 101/500\n",
            "49/49 [==============================] - 2s 43ms/step - loss: 1.7206 - accuracy: 0.4364 - val_loss: 1.7477 - val_accuracy: 0.4321\n",
            "Epoch 102/500\n",
            "49/49 [==============================] - 2s 46ms/step - loss: 1.6702 - accuracy: 0.4445 - val_loss: 1.7493 - val_accuracy: 0.4336\n",
            "Epoch 103/500\n",
            "49/49 [==============================] - 2s 43ms/step - loss: 1.6832 - accuracy: 0.4409 - val_loss: 1.7399 - val_accuracy: 0.4355\n",
            "Epoch 104/500\n",
            "49/49 [==============================] - 2s 43ms/step - loss: 1.6794 - accuracy: 0.4403 - val_loss: 1.7420 - val_accuracy: 0.4374\n",
            "Epoch 105/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.6948 - accuracy: 0.4395 - val_loss: 1.7527 - val_accuracy: 0.4350\n",
            "Epoch 106/500\n",
            "49/49 [==============================] - 2s 44ms/step - loss: 1.7035 - accuracy: 0.4294 - val_loss: 1.7415 - val_accuracy: 0.4350\n",
            "Epoch 107/500\n",
            "49/49 [==============================] - 2s 44ms/step - loss: 1.6761 - accuracy: 0.4441 - val_loss: 1.7466 - val_accuracy: 0.4326\n",
            "Epoch 108/500\n",
            "49/49 [==============================] - 2s 45ms/step - loss: 1.6846 - accuracy: 0.4453 - val_loss: 1.7534 - val_accuracy: 0.4248\n",
            "Epoch 109/500\n",
            "49/49 [==============================] - 2s 51ms/step - loss: 1.6983 - accuracy: 0.4358 - val_loss: 1.7460 - val_accuracy: 0.4311\n",
            "Epoch 110/500\n",
            "49/49 [==============================] - 3s 56ms/step - loss: 1.6952 - accuracy: 0.4328 - val_loss: 1.7418 - val_accuracy: 0.4306\n",
            "Epoch 111/500\n",
            "49/49 [==============================] - 3s 52ms/step - loss: 1.6861 - accuracy: 0.4460 - val_loss: 1.7424 - val_accuracy: 0.4340\n",
            "Epoch 112/500\n",
            "49/49 [==============================] - 3s 60ms/step - loss: 1.6856 - accuracy: 0.4399 - val_loss: 1.7430 - val_accuracy: 0.4336\n",
            "Epoch 113/500\n",
            "49/49 [==============================] - 3s 55ms/step - loss: 1.6554 - accuracy: 0.4463 - val_loss: 1.7414 - val_accuracy: 0.4326\n",
            "Epoch 114/500\n",
            "49/49 [==============================] - 2s 44ms/step - loss: 1.6654 - accuracy: 0.4355 - val_loss: 1.7469 - val_accuracy: 0.4403\n",
            "Epoch 115/500\n",
            "49/49 [==============================] - 2s 44ms/step - loss: 1.6992 - accuracy: 0.4337 - val_loss: 1.7508 - val_accuracy: 0.4331\n",
            "Epoch 116/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.6603 - accuracy: 0.4424 - val_loss: 1.7447 - val_accuracy: 0.4292\n",
            "Epoch 117/500\n",
            "49/49 [==============================] - 2s 43ms/step - loss: 1.7016 - accuracy: 0.4355 - val_loss: 1.7401 - val_accuracy: 0.4336\n",
            "Epoch 118/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.6773 - accuracy: 0.4413 - val_loss: 1.7474 - val_accuracy: 0.4321\n",
            "Epoch 119/500\n",
            "49/49 [==============================] - 2s 43ms/step - loss: 1.6644 - accuracy: 0.4446 - val_loss: 1.7426 - val_accuracy: 0.4350\n",
            "Epoch 120/500\n",
            "49/49 [==============================] - 2s 44ms/step - loss: 1.6899 - accuracy: 0.4421 - val_loss: 1.7437 - val_accuracy: 0.4282\n",
            "Epoch 121/500\n",
            "49/49 [==============================] - 2s 43ms/step - loss: 1.7004 - accuracy: 0.4366 - val_loss: 1.7467 - val_accuracy: 0.4277\n",
            "Epoch 122/500\n",
            "49/49 [==============================] - 2s 43ms/step - loss: 1.6804 - accuracy: 0.4468 - val_loss: 1.7476 - val_accuracy: 0.4336\n",
            "Epoch 123/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.6884 - accuracy: 0.4387 - val_loss: 1.7384 - val_accuracy: 0.4306\n",
            "Epoch 124/500\n",
            "49/49 [==============================] - 2s 44ms/step - loss: 1.6797 - accuracy: 0.4453 - val_loss: 1.7458 - val_accuracy: 0.4302\n",
            "Epoch 125/500\n",
            "49/49 [==============================] - 2s 43ms/step - loss: 1.6937 - accuracy: 0.4356 - val_loss: 1.7450 - val_accuracy: 0.4316\n",
            "Epoch 126/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.7170 - accuracy: 0.4264 - val_loss: 1.7501 - val_accuracy: 0.4321\n",
            "Epoch 127/500\n",
            "49/49 [==============================] - 2s 41ms/step - loss: 1.6698 - accuracy: 0.4427 - val_loss: 1.7412 - val_accuracy: 0.4306\n",
            "Epoch 128/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.6855 - accuracy: 0.4407 - val_loss: 1.7436 - val_accuracy: 0.4321\n",
            "Epoch 129/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.6712 - accuracy: 0.4458 - val_loss: 1.7388 - val_accuracy: 0.4374\n",
            "Epoch 130/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.6796 - accuracy: 0.4399 - val_loss: 1.7491 - val_accuracy: 0.4350\n",
            "Epoch 131/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.6660 - accuracy: 0.4524 - val_loss: 1.7411 - val_accuracy: 0.4326\n",
            "Epoch 132/500\n",
            "49/49 [==============================] - 2s 44ms/step - loss: 1.6964 - accuracy: 0.4404 - val_loss: 1.7410 - val_accuracy: 0.4302\n",
            "Epoch 133/500\n",
            "49/49 [==============================] - 2s 43ms/step - loss: 1.6661 - accuracy: 0.4509 - val_loss: 1.7439 - val_accuracy: 0.4302\n",
            "Epoch 134/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.6801 - accuracy: 0.4395 - val_loss: 1.7481 - val_accuracy: 0.4292\n",
            "Epoch 135/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.6502 - accuracy: 0.4467 - val_loss: 1.7549 - val_accuracy: 0.4331\n",
            "Epoch 136/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.6999 - accuracy: 0.4369 - val_loss: 1.7511 - val_accuracy: 0.4311\n",
            "Epoch 137/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.6609 - accuracy: 0.4425 - val_loss: 1.7445 - val_accuracy: 0.4292\n",
            "Epoch 138/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.6712 - accuracy: 0.4433 - val_loss: 1.7449 - val_accuracy: 0.4302\n",
            "Epoch 139/500\n",
            "49/49 [==============================] - 2s 44ms/step - loss: 1.6844 - accuracy: 0.4429 - val_loss: 1.7395 - val_accuracy: 0.4336\n",
            "Epoch 140/500\n",
            "49/49 [==============================] - 2s 44ms/step - loss: 1.6784 - accuracy: 0.4425 - val_loss: 1.7459 - val_accuracy: 0.4302\n",
            "Epoch 141/500\n",
            "49/49 [==============================] - 2s 44ms/step - loss: 1.6699 - accuracy: 0.4427 - val_loss: 1.7542 - val_accuracy: 0.4302\n",
            "Epoch 142/500\n",
            "49/49 [==============================] - 2s 44ms/step - loss: 1.6836 - accuracy: 0.4449 - val_loss: 1.7430 - val_accuracy: 0.4355\n",
            "Epoch 143/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.6568 - accuracy: 0.4510 - val_loss: 1.7456 - val_accuracy: 0.4345\n",
            "Epoch 144/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.6522 - accuracy: 0.4528 - val_loss: 1.7595 - val_accuracy: 0.4282\n",
            "Epoch 145/500\n",
            "49/49 [==============================] - 2s 42ms/step - loss: 1.6876 - accuracy: 0.4364 - val_loss: 1.7540 - val_accuracy: 0.4287\n",
            "Epoch 146/500\n",
            "49/49 [==============================] - 2s 44ms/step - loss: 1.6682 - accuracy: 0.4438 - val_loss: 1.7427 - val_accuracy: 0.4326\n",
            "Epoch 147/500\n",
            "49/49 [==============================] - 2s 43ms/step - loss: 1.6764 - accuracy: 0.4484 - val_loss: 1.7514 - val_accuracy: 0.4316\n",
            "\u001b[1;37m2021-03-24 05:58:56 [INFO] Model Accuracy on test: 42.17%, Loss: 1.78\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:58:56 [INFO] 保存模型：model/lstm/phpbb_part.h5\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:58:56 [INFO] TensorBoard 日志：logs/lstm/phpbb_part210324055334\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:58:56 [INFO] ************************************************完成训练LSTM模型************************************************\u001b[0m\n",
            "\u001b[1;37m2021-03-24 05:58:56 [INFO] End...\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYdgdH0kwUHz"
      },
      "source": [
        "## 训练char-level CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7yH2xi2uA5V",
        "outputId": "0550efb9-9256-4640-e8ee-a99072f90e5e"
      },
      "source": [
        "!python main.py \\\n",
        "  -e pro \\\n",
        "  --train \\\n",
        "  --model cnn \\\n",
        "  --infile dataset/phpbb.txt dataset/myspace.txt \\\n",
        "  --outpath model/cnn"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-03-24 06:00:55.304675: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[1;37m2021-03-24 06:00:57 [INFO] \n",
            "##########################################################################################################\n",
            "# GENPass\n",
            "# 1 PL模型预测。预测密码中的下一个单元（unit）。\n",
            "# 2 权重选择。按照权重选择从3个PL模型的结果中选择权重最高的unit，并根据wordlist随机选择一个密码进行替换。\n",
            "# 3 分类器。使用CNN模型预测上一步生成的密码属于3个数据集的概率。\n",
            "# 4 判定器。选择出在3个数据集概率相差不大的密码作为结果输出。\n",
            "#\n",
            "##########################################################################################################\n",
            "\u001b[0m\n",
            "\u001b[1;37m2021-03-24 06:00:57 [INFO] Start...\u001b[0m\n",
            "\u001b[1;37m2021-03-24 06:00:57 [INFO] 开始加载数据...\u001b[0m\n",
            "\u001b[1;37m2021-03-24 06:00:57 [INFO] dataset/phpbb.txt 数据大小：184379\u001b[0m\n",
            "\u001b[1;37m2021-03-24 06:00:57 [INFO] dataset/myspace.txt 数据大小：37144\u001b[0m\n",
            "\u001b[1;37m2021-03-24 06:00:57 [INFO] 训练模型的总数据量：77144\u001b[0m\n",
            "\u001b[1;37m2021-03-24 06:00:57 [INFO] 划分验证集和测试集\u001b[0m\n",
            "\u001b[1;37m2021-03-24 06:00:57 [INFO] x_val Shape: (15428, 100), y_val Shape: (15428, 2)\u001b[0m\n",
            "\u001b[1;37m2021-03-24 06:00:57 [INFO] x_test Shape: (15428, 100), y_test Shape: (15428, 2)\u001b[0m\n",
            "\u001b[1;37m2021-03-24 06:00:57 [INFO] 创建CNN模型...\u001b[0m\n",
            "2021-03-24 06:00:57.783737: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2021-03-24 06:00:57.789928: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
            "2021-03-24 06:00:57.804085: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2021-03-24 06:00:57.804149: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (137a59ef31cc): /proc/driver/nvidia/version does not exist\n",
            "2021-03-24 06:00:57.804695: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "\u001b[1;37m2021-03-24 06:00:58 [INFO] 创建模型：\u001b[0m\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 100, 50)           3550      \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 100, 256)          89856     \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 33, 256)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 33, 256)           459008    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 11, 256)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 11, 256)           196864    \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 11, 256)           196864    \n",
            "_________________________________________________________________\n",
            "conv1d_4 (Conv1D)            (None, 11, 256)           196864    \n",
            "_________________________________________________________________\n",
            "conv1d_5 (Conv1D)            (None, 11, 256)           196864    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 3, 256)            0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 768)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1024)              787456    \n",
            "_________________________________________________________________\n",
            "alpha_dropout (AlphaDropout) (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1024)              1049600   \n",
            "_________________________________________________________________\n",
            "alpha_dropout_1 (AlphaDropou (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 2)                 2050      \n",
            "=================================================================\n",
            "Total params: 3,178,976\n",
            "Trainable params: 3,178,976\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\u001b[1;37m2021-03-24 06:00:58 [INFO] 开始训练CNN模型\u001b[0m\n",
            "\u001b[1;37m2021-03-24 06:00:58 [INFO] 训练日志文件：logs/cnn/cnn210324060058\u001b[0m\n",
            "2021-03-24 06:00:58.038410: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.\n",
            "2021-03-24 06:00:58.038458: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.\n",
            "2021-03-24 06:00:58.048181: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.\n",
            "\u001b[1;37m2021-03-24 06:00:58 [INFO] 生成数据...\u001b[0m\n",
            "2021-03-24 06:00:58.111226: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
            "2021-03-24 06:00:58.111712: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2299995000 Hz\n",
            "Epoch 1/10\n",
            "  1/602 [..............................] - ETA: 20:42 - loss: 1.1666 - accuracy: 0.51562021-03-24 06:01:00.212728: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.\n",
            "2021-03-24 06:01:00.212794: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.\n",
            "  2/602 [..............................] - ETA: 9:09 - loss: 1.1238 - accuracy: 0.5312 2021-03-24 06:01:01.103974: I tensorflow/core/profiler/lib/profiler_session.cc:71] Profiler session collecting data.\n",
            "2021-03-24 06:01:01.105702: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.\n",
            "602/602 [==============================] - 349s 577ms/step - loss: 0.6681 - accuracy: 0.6939 - val_loss: 2.6509 - val_accuracy: 0.7844\n",
            "Epoch 2/10\n",
            "602/602 [==============================] - 336s 558ms/step - loss: 0.4101 - accuracy: 0.8429 - val_loss: 2.3257 - val_accuracy: 0.8200\n",
            "Epoch 3/10\n",
            "602/602 [==============================] - 339s 562ms/step - loss: 0.3947 - accuracy: 0.8535 - val_loss: 4.7274 - val_accuracy: 0.7586\n",
            "Epoch 4/10\n",
            "602/602 [==============================] - 330s 548ms/step - loss: 0.3937 - accuracy: 0.8525 - val_loss: 1.5394 - val_accuracy: 0.8440\n",
            "Epoch 5/10\n",
            "602/602 [==============================] - 332s 551ms/step - loss: 0.3761 - accuracy: 0.8600 - val_loss: 4.6043 - val_accuracy: 0.7029\n",
            "Epoch 6/10\n",
            "602/602 [==============================] - 332s 551ms/step - loss: 0.3861 - accuracy: 0.8562 - val_loss: 1.3875 - val_accuracy: 0.8579\n",
            "Epoch 7/10\n",
            "602/602 [==============================] - 337s 559ms/step - loss: 0.3613 - accuracy: 0.8652 - val_loss: 2.0178 - val_accuracy: 0.8361\n",
            "Epoch 8/10\n",
            "602/602 [==============================] - 339s 562ms/step - loss: 0.3608 - accuracy: 0.8645 - val_loss: 3.9154 - val_accuracy: 0.7582\n",
            "Epoch 9/10\n",
            "602/602 [==============================] - 338s 560ms/step - loss: 0.3544 - accuracy: 0.8680 - val_loss: 1.7475 - val_accuracy: 0.8606\n",
            "Epoch 10/10\n",
            "602/602 [==============================] - 336s 558ms/step - loss: 0.3345 - accuracy: 0.8739 - val_loss: 3.5739 - val_accuracy: 0.8012\n",
            "\u001b[1;37m2021-03-24 06:57:25 [INFO] Model Accuracy on test: 80.04%, Loss: 3.54\u001b[0m\n",
            "\u001b[1;37m2021-03-24 06:57:25 [INFO] 保存模型：model/cnn/cnn.h5\u001b[0m\n",
            "\u001b[1;37m2021-03-24 06:57:25 [INFO] End...\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}